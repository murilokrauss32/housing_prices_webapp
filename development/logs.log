2024-05-27 11:55:30,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 11:55:30,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 11:55:30,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 11:55:30,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 11:58:08,649:INFO:PyCaret RegressionExperiment
2024-05-27 11:58:08,649:INFO:Logging name: reg-default-name
2024-05-27 11:58:08,649:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-27 11:58:08,650:INFO:version 3.3.0
2024-05-27 11:58:08,650:INFO:Initializing setup()
2024-05-27 11:58:08,650:INFO:self.USI: dbde
2024-05-27 11:58:08,650:INFO:self._variable_keys: {'pipeline', '_ml_usecase', 'X', 'exp_id', 'idx', 'html_param', 'memory', 'logging_param', 'X_train', 'n_jobs_param', 'fold_shuffle_param', 'y_test', 'fold_generator', 'exp_name_log', 'gpu_n_jobs_param', 'USI', 'data', 'X_test', 'transform_target_param', 'y', 'gpu_param', 'fold_groups_param', '_available_plots', 'target_param', 'seed', 'log_plots_param', 'y_train'}
2024-05-27 11:58:08,650:INFO:Checking environment
2024-05-27 11:58:08,650:INFO:python_version: 3.11.5
2024-05-27 11:58:08,650:INFO:python_build: ('tags/v3.11.5:cce6ba9', 'Aug 24 2023 14:38:34')
2024-05-27 11:58:08,650:INFO:machine: AMD64
2024-05-27 11:58:08,651:INFO:platform: Windows-10-10.0.22631-SP0
2024-05-27 11:58:08,658:INFO:Memory: svmem(total=8459792384, available=1173405696, percent=86.1, used=7286386688, free=1173405696)
2024-05-27 11:58:08,659:INFO:Physical Core: 4
2024-05-27 11:58:08,659:INFO:Logical Core: 8
2024-05-27 11:58:08,659:INFO:Checking libraries
2024-05-27 11:58:08,659:INFO:System:
2024-05-27 11:58:08,659:INFO:    python: 3.11.5 (tags/v3.11.5:cce6ba9, Aug 24 2023, 14:38:34) [MSC v.1936 64 bit (AMD64)]
2024-05-27 11:58:08,659:INFO:executable: c:\Users\muril\AppData\Local\Programs\Python\Python311\python.exe
2024-05-27 11:58:08,659:INFO:   machine: Windows-10-10.0.22631-SP0
2024-05-27 11:58:08,659:INFO:PyCaret required dependencies:
2024-05-27 11:58:08,665:INFO:                 pip: 24.0
2024-05-27 11:58:08,665:INFO:          setuptools: 68.1.2
2024-05-27 11:58:08,665:INFO:             pycaret: 3.3.0
2024-05-27 11:58:08,665:INFO:             IPython: 8.14.0
2024-05-27 11:58:08,665:INFO:          ipywidgets: 8.1.0
2024-05-27 11:58:08,666:INFO:                tqdm: 4.66.1
2024-05-27 11:58:08,666:INFO:               numpy: 1.26.4
2024-05-27 11:58:08,666:INFO:              pandas: 2.0.2
2024-05-27 11:58:08,666:INFO:              jinja2: 3.1.2
2024-05-27 11:58:08,666:INFO:               scipy: 1.10.1
2024-05-27 11:58:08,666:INFO:              joblib: 1.2.0
2024-05-27 11:58:08,666:INFO:             sklearn: 1.4.1.post1
2024-05-27 11:58:08,666:INFO:                pyod: 1.1.3
2024-05-27 11:58:08,666:INFO:            imblearn: 0.12.1
2024-05-27 11:58:08,667:INFO:   category_encoders: 2.6.3
2024-05-27 11:58:08,667:INFO:            lightgbm: 4.3.0
2024-05-27 11:58:08,667:INFO:               numba: 0.59.1
2024-05-27 11:58:08,667:INFO:            requests: 2.31.0
2024-05-27 11:58:08,667:INFO:          matplotlib: 3.7.1
2024-05-27 11:58:08,667:INFO:          scikitplot: 0.3.7
2024-05-27 11:58:08,667:INFO:         yellowbrick: 1.5
2024-05-27 11:58:08,667:INFO:              plotly: 5.18.0
2024-05-27 11:58:08,667:INFO:    plotly-resampler: Not installed
2024-05-27 11:58:08,667:INFO:             kaleido: 0.2.1
2024-05-27 11:58:08,667:INFO:           schemdraw: 0.15
2024-05-27 11:58:08,668:INFO:         statsmodels: 0.14.1
2024-05-27 11:58:08,668:INFO:              sktime: 0.28.0
2024-05-27 11:58:08,668:INFO:               tbats: 1.1.3
2024-05-27 11:58:08,668:INFO:            pmdarima: 2.0.4
2024-05-27 11:58:08,668:INFO:              psutil: 5.9.5
2024-05-27 11:58:08,668:INFO:          markupsafe: 2.1.2
2024-05-27 11:58:08,668:INFO:             pickle5: Not installed
2024-05-27 11:58:08,668:INFO:         cloudpickle: 3.0.0
2024-05-27 11:58:08,668:INFO:         deprecation: 2.1.0
2024-05-27 11:58:08,669:INFO:              xxhash: 3.4.1
2024-05-27 11:58:08,669:INFO:           wurlitzer: Not installed
2024-05-27 11:58:08,669:INFO:PyCaret optional dependencies:
2024-05-27 11:58:08,702:INFO:                shap: Not installed
2024-05-27 11:58:08,702:INFO:           interpret: Not installed
2024-05-27 11:58:08,702:INFO:                umap: Not installed
2024-05-27 11:58:08,702:INFO:     ydata_profiling: Not installed
2024-05-27 11:58:08,702:INFO:  explainerdashboard: Not installed
2024-05-27 11:58:08,702:INFO:             autoviz: Not installed
2024-05-27 11:58:08,702:INFO:           fairlearn: Not installed
2024-05-27 11:58:08,702:INFO:          deepchecks: Not installed
2024-05-27 11:58:08,702:INFO:             xgboost: Not installed
2024-05-27 11:58:08,702:INFO:            catboost: Not installed
2024-05-27 11:58:08,702:INFO:              kmodes: Not installed
2024-05-27 11:58:08,702:INFO:             mlxtend: Not installed
2024-05-27 11:58:08,702:INFO:       statsforecast: Not installed
2024-05-27 11:58:08,702:INFO:        tune_sklearn: Not installed
2024-05-27 11:58:08,702:INFO:                 ray: Not installed
2024-05-27 11:58:08,702:INFO:            hyperopt: Not installed
2024-05-27 11:58:08,702:INFO:              optuna: Not installed
2024-05-27 11:58:08,703:INFO:               skopt: Not installed
2024-05-27 11:58:08,703:INFO:              mlflow: Not installed
2024-05-27 11:58:08,703:INFO:              gradio: Not installed
2024-05-27 11:58:08,703:INFO:             fastapi: Not installed
2024-05-27 11:58:08,703:INFO:             uvicorn: Not installed
2024-05-27 11:58:08,703:INFO:              m2cgen: Not installed
2024-05-27 11:58:08,703:INFO:           evidently: Not installed
2024-05-27 11:58:08,703:INFO:               fugue: Not installed
2024-05-27 11:58:08,703:INFO:           streamlit: 1.28.1
2024-05-27 11:58:08,703:INFO:             prophet: Not installed
2024-05-27 11:58:08,703:INFO:None
2024-05-27 11:58:08,703:INFO:Set up data.
2024-05-27 11:58:08,798:INFO:Set up folding strategy.
2024-05-27 11:58:08,798:INFO:Set up train/test split.
2024-05-27 11:58:08,824:INFO:Set up index.
2024-05-27 11:58:08,824:INFO:Assigning column types.
2024-05-27 11:58:08,839:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-27 11:58:08,840:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-27 11:58:08,849:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-27 11:58:08,857:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 11:58:08,967:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 11:58:09,034:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 11:58:09,037:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:09,038:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:09,038:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-27 11:58:09,045:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-27 11:58:09,052:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 11:58:09,135:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 11:58:09,200:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 11:58:09,201:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:09,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:09,202:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-27 11:58:09,207:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-27 11:58:09,214:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 11:58:09,286:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 11:58:09,356:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 11:58:09,356:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:09,357:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:09,363:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-27 11:58:09,367:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 11:58:09,436:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 11:58:09,487:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 11:58:09,488:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:09,488:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:09,488:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-27 11:58:09,498:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 11:58:09,579:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 11:58:09,631:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 11:58:09,631:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:09,631:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:09,641:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 11:58:09,707:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 11:58:09,761:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 11:58:09,762:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:09,762:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:09,763:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-27 11:58:10,054:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 11:58:10,114:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 11:58:10,115:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:10,117:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:10,198:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 11:58:10,245:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 11:58:10,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:10,246:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:10,247:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-27 11:58:10,325:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 11:58:10,372:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:10,373:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:10,450:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 11:58:10,499:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:10,500:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:10,500:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-27 11:58:10,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:10,637:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:10,762:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:10,762:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:10,781:INFO:Preparing preprocessing pipeline...
2024-05-27 11:58:10,782:INFO:Set up simple imputation.
2024-05-27 11:58:10,782:INFO:Set up removing outliers.
2024-05-27 11:58:10,782:INFO:Set up feature normalization.
2024-05-27 11:58:11,255:INFO:Finished creating preprocessing pipeline.
2024-05-27 11:58:11,268:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\muril\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['num_bed', 'num_bath',
                                             'size_house', 'size_lot',
                                             'num_floors', 'is_waterfront',
                                             'condition', 'size_basement',
                                             'year_built', 'renovation_date',
                                             'zip', 'latitude', 'longitude',
                                             'avg_size_neighbor_houses',
                                             'avg_size_neighbor_lot',
                                             'zip_prefix_3', 'zip_prefix_4'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2024-05-27 11:58:11,268:INFO:Creating final display dataframe.
2024-05-27 11:58:11,941:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target             price
2                   Target type        Regression
3           Original data shape        (1370, 18)
4        Transformed data shape        (1322, 18)
5   Transformed train set shape         (910, 18)
6    Transformed test set shape         (412, 18)
7              Numeric features                17
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12              Remove outliers              True
13           Outliers threshold              0.05
14                    Normalize              True
15             Normalize method            zscore
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              dbde
2024-05-27 11:58:12,131:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:12,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:12,271:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:12,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 11:58:12,275:WARNING:c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-05-27 11:58:12,276:INFO:setup() successfully completed in 3.64s...............
2024-05-27 11:58:40,752:INFO:Initializing compare_models()
2024-05-27 11:58:40,752:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-05-27 11:58:40,752:INFO:Checking exceptions
2024-05-27 11:58:40,759:INFO:Preparing display monitor
2024-05-27 11:58:40,836:INFO:Initializing Linear Regression
2024-05-27 11:58:40,837:INFO:Total runtime is 1.6717116038004556e-05 minutes
2024-05-27 11:58:40,844:INFO:SubProcess create_model() called ==================================
2024-05-27 11:58:40,847:INFO:Initializing create_model()
2024-05-27 11:58:40,847:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEB778F750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 11:58:40,847:INFO:Checking exceptions
2024-05-27 11:58:40,847:INFO:Importing libraries
2024-05-27 11:58:40,847:INFO:Copying training dataset
2024-05-27 11:58:40,856:INFO:Defining folds
2024-05-27 11:58:40,856:INFO:Declaring metric variables
2024-05-27 11:58:40,860:INFO:Importing untrained model
2024-05-27 11:58:40,868:INFO:Linear Regression Imported successfully
2024-05-27 11:58:40,878:INFO:Starting cross validation
2024-05-27 11:58:40,935:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 11:58:54,681:INFO:Calculating mean and std
2024-05-27 11:58:54,691:INFO:Creating metrics dataframe
2024-05-27 11:58:54,722:INFO:Uploading results into container
2024-05-27 11:58:54,727:INFO:Uploading model into container now
2024-05-27 11:58:54,730:INFO:_master_model_container: 1
2024-05-27 11:58:54,731:INFO:_display_container: 2
2024-05-27 11:58:54,731:INFO:LinearRegression(n_jobs=-1)
2024-05-27 11:58:54,731:INFO:create_model() successfully completed......................................
2024-05-27 11:59:00,181:INFO:SubProcess create_model() end ==================================
2024-05-27 11:59:00,182:INFO:Creating metrics dataframe
2024-05-27 11:59:00,194:INFO:Initializing Lasso Regression
2024-05-27 11:59:00,194:INFO:Total runtime is 0.3226267695426941 minutes
2024-05-27 11:59:00,198:INFO:SubProcess create_model() called ==================================
2024-05-27 11:59:00,199:INFO:Initializing create_model()
2024-05-27 11:59:00,199:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEB778F750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 11:59:00,199:INFO:Checking exceptions
2024-05-27 11:59:00,200:INFO:Importing libraries
2024-05-27 11:59:00,200:INFO:Copying training dataset
2024-05-27 11:59:00,208:INFO:Defining folds
2024-05-27 11:59:00,208:INFO:Declaring metric variables
2024-05-27 11:59:00,212:INFO:Importing untrained model
2024-05-27 11:59:00,217:INFO:Lasso Regression Imported successfully
2024-05-27 11:59:00,228:INFO:Starting cross validation
2024-05-27 11:59:00,248:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 11:59:01,015:INFO:Calculating mean and std
2024-05-27 11:59:01,017:INFO:Creating metrics dataframe
2024-05-27 11:59:01,019:INFO:Uploading results into container
2024-05-27 11:59:01,020:INFO:Uploading model into container now
2024-05-27 11:59:01,020:INFO:_master_model_container: 2
2024-05-27 11:59:01,020:INFO:_display_container: 2
2024-05-27 11:59:01,020:INFO:Lasso(random_state=42)
2024-05-27 11:59:01,021:INFO:create_model() successfully completed......................................
2024-05-27 11:59:01,138:INFO:SubProcess create_model() end ==================================
2024-05-27 11:59:01,138:INFO:Creating metrics dataframe
2024-05-27 11:59:01,152:INFO:Initializing Ridge Regression
2024-05-27 11:59:01,152:INFO:Total runtime is 0.3385864416758219 minutes
2024-05-27 11:59:01,159:INFO:SubProcess create_model() called ==================================
2024-05-27 11:59:01,160:INFO:Initializing create_model()
2024-05-27 11:59:01,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEB778F750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 11:59:01,160:INFO:Checking exceptions
2024-05-27 11:59:01,160:INFO:Importing libraries
2024-05-27 11:59:01,161:INFO:Copying training dataset
2024-05-27 11:59:01,171:INFO:Defining folds
2024-05-27 11:59:01,172:INFO:Declaring metric variables
2024-05-27 11:59:01,178:INFO:Importing untrained model
2024-05-27 11:59:01,183:INFO:Ridge Regression Imported successfully
2024-05-27 11:59:01,195:INFO:Starting cross validation
2024-05-27 11:59:01,212:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 11:59:01,947:INFO:Calculating mean and std
2024-05-27 11:59:01,948:INFO:Creating metrics dataframe
2024-05-27 11:59:01,950:INFO:Uploading results into container
2024-05-27 11:59:01,951:INFO:Uploading model into container now
2024-05-27 11:59:01,951:INFO:_master_model_container: 3
2024-05-27 11:59:01,951:INFO:_display_container: 2
2024-05-27 11:59:01,952:INFO:Ridge(random_state=42)
2024-05-27 11:59:01,952:INFO:create_model() successfully completed......................................
2024-05-27 11:59:02,059:INFO:SubProcess create_model() end ==================================
2024-05-27 11:59:02,059:INFO:Creating metrics dataframe
2024-05-27 11:59:02,071:INFO:Initializing Elastic Net
2024-05-27 11:59:02,071:INFO:Total runtime is 0.35390187104543047 minutes
2024-05-27 11:59:02,076:INFO:SubProcess create_model() called ==================================
2024-05-27 11:59:02,076:INFO:Initializing create_model()
2024-05-27 11:59:02,077:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEB778F750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 11:59:02,077:INFO:Checking exceptions
2024-05-27 11:59:02,077:INFO:Importing libraries
2024-05-27 11:59:02,077:INFO:Copying training dataset
2024-05-27 11:59:02,087:INFO:Defining folds
2024-05-27 11:59:02,087:INFO:Declaring metric variables
2024-05-27 11:59:02,093:INFO:Importing untrained model
2024-05-27 11:59:02,098:INFO:Elastic Net Imported successfully
2024-05-27 11:59:02,110:INFO:Starting cross validation
2024-05-27 11:59:02,125:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 11:59:02,816:INFO:Calculating mean and std
2024-05-27 11:59:02,817:INFO:Creating metrics dataframe
2024-05-27 11:59:02,820:INFO:Uploading results into container
2024-05-27 11:59:02,820:INFO:Uploading model into container now
2024-05-27 11:59:02,820:INFO:_master_model_container: 4
2024-05-27 11:59:02,820:INFO:_display_container: 2
2024-05-27 11:59:02,822:INFO:ElasticNet(random_state=42)
2024-05-27 11:59:02,822:INFO:create_model() successfully completed......................................
2024-05-27 11:59:02,932:INFO:SubProcess create_model() end ==================================
2024-05-27 11:59:02,932:INFO:Creating metrics dataframe
2024-05-27 11:59:02,945:INFO:Initializing Least Angle Regression
2024-05-27 11:59:02,945:INFO:Total runtime is 0.3684818347295125 minutes
2024-05-27 11:59:02,949:INFO:SubProcess create_model() called ==================================
2024-05-27 11:59:02,950:INFO:Initializing create_model()
2024-05-27 11:59:02,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEB778F750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 11:59:02,950:INFO:Checking exceptions
2024-05-27 11:59:02,950:INFO:Importing libraries
2024-05-27 11:59:02,951:INFO:Copying training dataset
2024-05-27 11:59:02,958:INFO:Defining folds
2024-05-27 11:59:02,958:INFO:Declaring metric variables
2024-05-27 11:59:02,963:INFO:Importing untrained model
2024-05-27 11:59:02,969:INFO:Least Angle Regression Imported successfully
2024-05-27 11:59:02,980:INFO:Starting cross validation
2024-05-27 11:59:02,994:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 11:59:03,683:INFO:Calculating mean and std
2024-05-27 11:59:03,685:INFO:Creating metrics dataframe
2024-05-27 11:59:03,687:INFO:Uploading results into container
2024-05-27 11:59:03,687:INFO:Uploading model into container now
2024-05-27 11:59:03,688:INFO:_master_model_container: 5
2024-05-27 11:59:03,688:INFO:_display_container: 2
2024-05-27 11:59:03,690:INFO:Lars(random_state=42)
2024-05-27 11:59:03,691:INFO:create_model() successfully completed......................................
2024-05-27 11:59:03,801:INFO:SubProcess create_model() end ==================================
2024-05-27 11:59:03,801:INFO:Creating metrics dataframe
2024-05-27 11:59:03,815:INFO:Initializing Lasso Least Angle Regression
2024-05-27 11:59:03,815:INFO:Total runtime is 0.3829725623130798 minutes
2024-05-27 11:59:03,820:INFO:SubProcess create_model() called ==================================
2024-05-27 11:59:03,820:INFO:Initializing create_model()
2024-05-27 11:59:03,821:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEB778F750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 11:59:03,821:INFO:Checking exceptions
2024-05-27 11:59:03,821:INFO:Importing libraries
2024-05-27 11:59:03,821:INFO:Copying training dataset
2024-05-27 11:59:03,829:INFO:Defining folds
2024-05-27 11:59:03,830:INFO:Declaring metric variables
2024-05-27 11:59:03,837:INFO:Importing untrained model
2024-05-27 11:59:03,841:INFO:Lasso Least Angle Regression Imported successfully
2024-05-27 11:59:03,853:INFO:Starting cross validation
2024-05-27 11:59:03,873:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 11:59:04,548:INFO:Calculating mean and std
2024-05-27 11:59:04,549:INFO:Creating metrics dataframe
2024-05-27 11:59:04,551:INFO:Uploading results into container
2024-05-27 11:59:04,551:INFO:Uploading model into container now
2024-05-27 11:59:04,552:INFO:_master_model_container: 6
2024-05-27 11:59:04,552:INFO:_display_container: 2
2024-05-27 11:59:04,552:INFO:LassoLars(random_state=42)
2024-05-27 11:59:04,552:INFO:create_model() successfully completed......................................
2024-05-27 11:59:04,655:INFO:SubProcess create_model() end ==================================
2024-05-27 11:59:04,655:INFO:Creating metrics dataframe
2024-05-27 11:59:04,669:INFO:Initializing Orthogonal Matching Pursuit
2024-05-27 11:59:04,669:INFO:Total runtime is 0.397207494576772 minutes
2024-05-27 11:59:04,674:INFO:SubProcess create_model() called ==================================
2024-05-27 11:59:04,674:INFO:Initializing create_model()
2024-05-27 11:59:04,674:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEB778F750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 11:59:04,674:INFO:Checking exceptions
2024-05-27 11:59:04,674:INFO:Importing libraries
2024-05-27 11:59:04,674:INFO:Copying training dataset
2024-05-27 11:59:04,686:INFO:Defining folds
2024-05-27 11:59:04,686:INFO:Declaring metric variables
2024-05-27 11:59:04,691:INFO:Importing untrained model
2024-05-27 11:59:04,696:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-27 11:59:04,708:INFO:Starting cross validation
2024-05-27 11:59:04,723:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 11:59:05,410:INFO:Calculating mean and std
2024-05-27 11:59:05,412:INFO:Creating metrics dataframe
2024-05-27 11:59:05,414:INFO:Uploading results into container
2024-05-27 11:59:05,414:INFO:Uploading model into container now
2024-05-27 11:59:05,415:INFO:_master_model_container: 7
2024-05-27 11:59:05,415:INFO:_display_container: 2
2024-05-27 11:59:05,415:INFO:OrthogonalMatchingPursuit()
2024-05-27 11:59:05,415:INFO:create_model() successfully completed......................................
2024-05-27 11:59:05,519:INFO:SubProcess create_model() end ==================================
2024-05-27 11:59:05,519:INFO:Creating metrics dataframe
2024-05-27 11:59:05,533:INFO:Initializing Bayesian Ridge
2024-05-27 11:59:05,533:INFO:Total runtime is 0.4116142749786377 minutes
2024-05-27 11:59:05,540:INFO:SubProcess create_model() called ==================================
2024-05-27 11:59:05,540:INFO:Initializing create_model()
2024-05-27 11:59:05,540:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEB778F750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 11:59:05,540:INFO:Checking exceptions
2024-05-27 11:59:05,540:INFO:Importing libraries
2024-05-27 11:59:05,540:INFO:Copying training dataset
2024-05-27 11:59:05,550:INFO:Defining folds
2024-05-27 11:59:05,550:INFO:Declaring metric variables
2024-05-27 11:59:05,557:INFO:Importing untrained model
2024-05-27 11:59:05,564:INFO:Bayesian Ridge Imported successfully
2024-05-27 11:59:05,576:INFO:Starting cross validation
2024-05-27 11:59:05,591:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 11:59:06,270:INFO:Calculating mean and std
2024-05-27 11:59:06,271:INFO:Creating metrics dataframe
2024-05-27 11:59:06,273:INFO:Uploading results into container
2024-05-27 11:59:06,274:INFO:Uploading model into container now
2024-05-27 11:59:06,275:INFO:_master_model_container: 8
2024-05-27 11:59:06,275:INFO:_display_container: 2
2024-05-27 11:59:06,276:INFO:BayesianRidge()
2024-05-27 11:59:06,276:INFO:create_model() successfully completed......................................
2024-05-27 11:59:06,388:INFO:SubProcess create_model() end ==================================
2024-05-27 11:59:06,388:INFO:Creating metrics dataframe
2024-05-27 11:59:06,399:INFO:Initializing Passive Aggressive Regressor
2024-05-27 11:59:06,404:INFO:Total runtime is 0.4261212309201558 minutes
2024-05-27 11:59:06,407:INFO:SubProcess create_model() called ==================================
2024-05-27 11:59:06,407:INFO:Initializing create_model()
2024-05-27 11:59:06,407:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEB778F750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 11:59:06,407:INFO:Checking exceptions
2024-05-27 11:59:06,408:INFO:Importing libraries
2024-05-27 11:59:06,408:INFO:Copying training dataset
2024-05-27 11:59:06,416:INFO:Defining folds
2024-05-27 11:59:06,416:INFO:Declaring metric variables
2024-05-27 11:59:06,421:INFO:Importing untrained model
2024-05-27 11:59:06,427:INFO:Passive Aggressive Regressor Imported successfully
2024-05-27 11:59:06,439:INFO:Starting cross validation
2024-05-27 11:59:06,454:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 11:59:07,124:INFO:Calculating mean and std
2024-05-27 11:59:07,125:INFO:Creating metrics dataframe
2024-05-27 11:59:07,128:INFO:Uploading results into container
2024-05-27 11:59:07,128:INFO:Uploading model into container now
2024-05-27 11:59:07,129:INFO:_master_model_container: 9
2024-05-27 11:59:07,129:INFO:_display_container: 2
2024-05-27 11:59:07,130:INFO:PassiveAggressiveRegressor(random_state=42)
2024-05-27 11:59:07,130:INFO:create_model() successfully completed......................................
2024-05-27 11:59:07,239:INFO:SubProcess create_model() end ==================================
2024-05-27 11:59:07,240:INFO:Creating metrics dataframe
2024-05-27 11:59:07,252:INFO:Initializing Huber Regressor
2024-05-27 11:59:07,252:INFO:Total runtime is 0.4402644395828247 minutes
2024-05-27 11:59:07,257:INFO:SubProcess create_model() called ==================================
2024-05-27 11:59:07,257:INFO:Initializing create_model()
2024-05-27 11:59:07,258:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEB778F750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 11:59:07,258:INFO:Checking exceptions
2024-05-27 11:59:07,258:INFO:Importing libraries
2024-05-27 11:59:07,258:INFO:Copying training dataset
2024-05-27 11:59:07,267:INFO:Defining folds
2024-05-27 11:59:07,267:INFO:Declaring metric variables
2024-05-27 11:59:07,271:INFO:Importing untrained model
2024-05-27 11:59:07,277:INFO:Huber Regressor Imported successfully
2024-05-27 11:59:07,286:INFO:Starting cross validation
2024-05-27 11:59:07,341:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 11:59:08,152:INFO:Calculating mean and std
2024-05-27 11:59:08,154:INFO:Creating metrics dataframe
2024-05-27 11:59:08,157:INFO:Uploading results into container
2024-05-27 11:59:08,158:INFO:Uploading model into container now
2024-05-27 11:59:08,159:INFO:_master_model_container: 10
2024-05-27 11:59:08,159:INFO:_display_container: 2
2024-05-27 11:59:08,159:INFO:HuberRegressor()
2024-05-27 11:59:08,160:INFO:create_model() successfully completed......................................
2024-05-27 11:59:08,272:INFO:SubProcess create_model() end ==================================
2024-05-27 11:59:08,272:INFO:Creating metrics dataframe
2024-05-27 11:59:08,286:INFO:Initializing K Neighbors Regressor
2024-05-27 11:59:08,286:INFO:Total runtime is 0.45749135812123615 minutes
2024-05-27 11:59:08,290:INFO:SubProcess create_model() called ==================================
2024-05-27 11:59:08,290:INFO:Initializing create_model()
2024-05-27 11:59:08,290:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEB778F750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 11:59:08,291:INFO:Checking exceptions
2024-05-27 11:59:08,291:INFO:Importing libraries
2024-05-27 11:59:08,291:INFO:Copying training dataset
2024-05-27 11:59:08,299:INFO:Defining folds
2024-05-27 11:59:08,300:INFO:Declaring metric variables
2024-05-27 11:59:08,303:INFO:Importing untrained model
2024-05-27 11:59:08,309:INFO:K Neighbors Regressor Imported successfully
2024-05-27 11:59:08,319:INFO:Starting cross validation
2024-05-27 11:59:08,361:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 11:59:09,309:INFO:Calculating mean and std
2024-05-27 11:59:09,311:INFO:Creating metrics dataframe
2024-05-27 11:59:09,314:INFO:Uploading results into container
2024-05-27 11:59:09,315:INFO:Uploading model into container now
2024-05-27 11:59:09,316:INFO:_master_model_container: 11
2024-05-27 11:59:09,316:INFO:_display_container: 2
2024-05-27 11:59:09,317:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-27 11:59:09,317:INFO:create_model() successfully completed......................................
2024-05-27 11:59:09,438:INFO:SubProcess create_model() end ==================================
2024-05-27 11:59:09,438:INFO:Creating metrics dataframe
2024-05-27 11:59:09,453:INFO:Initializing Decision Tree Regressor
2024-05-27 11:59:09,453:INFO:Total runtime is 0.4769369006156921 minutes
2024-05-27 11:59:09,458:INFO:SubProcess create_model() called ==================================
2024-05-27 11:59:09,458:INFO:Initializing create_model()
2024-05-27 11:59:09,458:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEB778F750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 11:59:09,459:INFO:Checking exceptions
2024-05-27 11:59:09,459:INFO:Importing libraries
2024-05-27 11:59:09,459:INFO:Copying training dataset
2024-05-27 11:59:09,471:INFO:Defining folds
2024-05-27 11:59:09,471:INFO:Declaring metric variables
2024-05-27 11:59:09,478:INFO:Importing untrained model
2024-05-27 11:59:09,484:INFO:Decision Tree Regressor Imported successfully
2024-05-27 11:59:09,497:INFO:Starting cross validation
2024-05-27 11:59:09,515:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 11:59:10,458:INFO:Calculating mean and std
2024-05-27 11:59:10,459:INFO:Creating metrics dataframe
2024-05-27 11:59:10,463:INFO:Uploading results into container
2024-05-27 11:59:10,464:INFO:Uploading model into container now
2024-05-27 11:59:10,464:INFO:_master_model_container: 12
2024-05-27 11:59:10,465:INFO:_display_container: 2
2024-05-27 11:59:10,465:INFO:DecisionTreeRegressor(random_state=42)
2024-05-27 11:59:10,466:INFO:create_model() successfully completed......................................
2024-05-27 11:59:10,586:INFO:SubProcess create_model() end ==================================
2024-05-27 11:59:10,587:INFO:Creating metrics dataframe
2024-05-27 11:59:10,602:INFO:Initializing Random Forest Regressor
2024-05-27 11:59:10,602:INFO:Total runtime is 0.49609560966491695 minutes
2024-05-27 11:59:10,606:INFO:SubProcess create_model() called ==================================
2024-05-27 11:59:10,606:INFO:Initializing create_model()
2024-05-27 11:59:10,607:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEB778F750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 11:59:10,607:INFO:Checking exceptions
2024-05-27 11:59:10,607:INFO:Importing libraries
2024-05-27 11:59:10,607:INFO:Copying training dataset
2024-05-27 11:59:10,620:INFO:Defining folds
2024-05-27 11:59:10,620:INFO:Declaring metric variables
2024-05-27 11:59:10,625:INFO:Importing untrained model
2024-05-27 11:59:10,634:INFO:Random Forest Regressor Imported successfully
2024-05-27 11:59:10,644:INFO:Starting cross validation
2024-05-27 11:59:10,662:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 11:59:13,759:INFO:Calculating mean and std
2024-05-27 11:59:13,761:INFO:Creating metrics dataframe
2024-05-27 11:59:13,765:INFO:Uploading results into container
2024-05-27 11:59:13,766:INFO:Uploading model into container now
2024-05-27 11:59:13,767:INFO:_master_model_container: 13
2024-05-27 11:59:13,767:INFO:_display_container: 2
2024-05-27 11:59:13,767:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2024-05-27 11:59:13,768:INFO:create_model() successfully completed......................................
2024-05-27 11:59:13,880:INFO:SubProcess create_model() end ==================================
2024-05-27 11:59:13,880:INFO:Creating metrics dataframe
2024-05-27 11:59:13,894:INFO:Initializing Extra Trees Regressor
2024-05-27 11:59:13,895:INFO:Total runtime is 0.5509690682093302 minutes
2024-05-27 11:59:13,900:INFO:SubProcess create_model() called ==================================
2024-05-27 11:59:13,900:INFO:Initializing create_model()
2024-05-27 11:59:13,901:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEB778F750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 11:59:13,901:INFO:Checking exceptions
2024-05-27 11:59:13,901:INFO:Importing libraries
2024-05-27 11:59:13,901:INFO:Copying training dataset
2024-05-27 11:59:13,908:INFO:Defining folds
2024-05-27 11:59:13,909:INFO:Declaring metric variables
2024-05-27 11:59:13,914:INFO:Importing untrained model
2024-05-27 11:59:13,921:INFO:Extra Trees Regressor Imported successfully
2024-05-27 11:59:13,932:INFO:Starting cross validation
2024-05-27 11:59:13,949:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 11:59:16,251:INFO:Calculating mean and std
2024-05-27 11:59:16,255:INFO:Creating metrics dataframe
2024-05-27 11:59:16,260:INFO:Uploading results into container
2024-05-27 11:59:16,261:INFO:Uploading model into container now
2024-05-27 11:59:16,263:INFO:_master_model_container: 14
2024-05-27 11:59:16,263:INFO:_display_container: 2
2024-05-27 11:59:16,264:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-05-27 11:59:16,264:INFO:create_model() successfully completed......................................
2024-05-27 11:59:16,388:INFO:SubProcess create_model() end ==================================
2024-05-27 11:59:16,388:INFO:Creating metrics dataframe
2024-05-27 11:59:16,406:INFO:Initializing AdaBoost Regressor
2024-05-27 11:59:16,406:INFO:Total runtime is 0.592819857597351 minutes
2024-05-27 11:59:16,410:INFO:SubProcess create_model() called ==================================
2024-05-27 11:59:16,410:INFO:Initializing create_model()
2024-05-27 11:59:16,411:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEB778F750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 11:59:16,412:INFO:Checking exceptions
2024-05-27 11:59:16,412:INFO:Importing libraries
2024-05-27 11:59:16,412:INFO:Copying training dataset
2024-05-27 11:59:16,420:INFO:Defining folds
2024-05-27 11:59:16,421:INFO:Declaring metric variables
2024-05-27 11:59:16,424:INFO:Importing untrained model
2024-05-27 11:59:16,433:INFO:AdaBoost Regressor Imported successfully
2024-05-27 11:59:16,443:INFO:Starting cross validation
2024-05-27 11:59:16,458:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 11:59:17,892:INFO:Calculating mean and std
2024-05-27 11:59:17,895:INFO:Creating metrics dataframe
2024-05-27 11:59:17,898:INFO:Uploading results into container
2024-05-27 11:59:17,900:INFO:Uploading model into container now
2024-05-27 11:59:17,900:INFO:_master_model_container: 15
2024-05-27 11:59:17,901:INFO:_display_container: 2
2024-05-27 11:59:17,901:INFO:AdaBoostRegressor(random_state=42)
2024-05-27 11:59:17,902:INFO:create_model() successfully completed......................................
2024-05-27 11:59:18,091:INFO:SubProcess create_model() end ==================================
2024-05-27 11:59:18,091:INFO:Creating metrics dataframe
2024-05-27 11:59:18,109:INFO:Initializing Gradient Boosting Regressor
2024-05-27 11:59:18,109:INFO:Total runtime is 0.6212052504221598 minutes
2024-05-27 11:59:18,116:INFO:SubProcess create_model() called ==================================
2024-05-27 11:59:18,116:INFO:Initializing create_model()
2024-05-27 11:59:18,116:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEB778F750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 11:59:18,116:INFO:Checking exceptions
2024-05-27 11:59:18,117:INFO:Importing libraries
2024-05-27 11:59:18,117:INFO:Copying training dataset
2024-05-27 11:59:18,125:INFO:Defining folds
2024-05-27 11:59:18,125:INFO:Declaring metric variables
2024-05-27 11:59:18,136:INFO:Importing untrained model
2024-05-27 11:59:18,141:INFO:Gradient Boosting Regressor Imported successfully
2024-05-27 11:59:18,155:INFO:Starting cross validation
2024-05-27 11:59:18,171:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 11:59:20,110:INFO:Calculating mean and std
2024-05-27 11:59:20,112:INFO:Creating metrics dataframe
2024-05-27 11:59:20,117:INFO:Uploading results into container
2024-05-27 11:59:20,118:INFO:Uploading model into container now
2024-05-27 11:59:20,120:INFO:_master_model_container: 16
2024-05-27 11:59:20,120:INFO:_display_container: 2
2024-05-27 11:59:20,120:INFO:GradientBoostingRegressor(random_state=42)
2024-05-27 11:59:20,120:INFO:create_model() successfully completed......................................
2024-05-27 11:59:20,235:INFO:SubProcess create_model() end ==================================
2024-05-27 11:59:20,235:INFO:Creating metrics dataframe
2024-05-27 11:59:20,251:INFO:Initializing Light Gradient Boosting Machine
2024-05-27 11:59:20,251:INFO:Total runtime is 0.6569017688433328 minutes
2024-05-27 11:59:20,254:INFO:SubProcess create_model() called ==================================
2024-05-27 11:59:20,255:INFO:Initializing create_model()
2024-05-27 11:59:20,255:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEB778F750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 11:59:20,255:INFO:Checking exceptions
2024-05-27 11:59:20,255:INFO:Importing libraries
2024-05-27 11:59:20,255:INFO:Copying training dataset
2024-05-27 11:59:20,266:INFO:Defining folds
2024-05-27 11:59:20,266:INFO:Declaring metric variables
2024-05-27 11:59:20,270:INFO:Importing untrained model
2024-05-27 11:59:20,276:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 11:59:20,286:INFO:Starting cross validation
2024-05-27 11:59:20,303:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 11:59:22,465:INFO:Calculating mean and std
2024-05-27 11:59:22,467:INFO:Creating metrics dataframe
2024-05-27 11:59:22,470:INFO:Uploading results into container
2024-05-27 11:59:22,471:INFO:Uploading model into container now
2024-05-27 11:59:22,472:INFO:_master_model_container: 17
2024-05-27 11:59:22,472:INFO:_display_container: 2
2024-05-27 11:59:22,473:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 11:59:22,473:INFO:create_model() successfully completed......................................
2024-05-27 11:59:22,611:INFO:SubProcess create_model() end ==================================
2024-05-27 11:59:22,613:INFO:Creating metrics dataframe
2024-05-27 11:59:22,629:INFO:Initializing Dummy Regressor
2024-05-27 11:59:22,629:INFO:Total runtime is 0.6965505321820576 minutes
2024-05-27 11:59:22,633:INFO:SubProcess create_model() called ==================================
2024-05-27 11:59:22,634:INFO:Initializing create_model()
2024-05-27 11:59:22,634:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEB778F750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 11:59:22,634:INFO:Checking exceptions
2024-05-27 11:59:22,634:INFO:Importing libraries
2024-05-27 11:59:22,634:INFO:Copying training dataset
2024-05-27 11:59:22,642:INFO:Defining folds
2024-05-27 11:59:22,643:INFO:Declaring metric variables
2024-05-27 11:59:22,646:INFO:Importing untrained model
2024-05-27 11:59:22,652:INFO:Dummy Regressor Imported successfully
2024-05-27 11:59:22,660:INFO:Starting cross validation
2024-05-27 11:59:22,684:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 11:59:23,457:INFO:Calculating mean and std
2024-05-27 11:59:23,459:INFO:Creating metrics dataframe
2024-05-27 11:59:23,463:INFO:Uploading results into container
2024-05-27 11:59:23,464:INFO:Uploading model into container now
2024-05-27 11:59:23,465:INFO:_master_model_container: 18
2024-05-27 11:59:23,466:INFO:_display_container: 2
2024-05-27 11:59:23,466:INFO:DummyRegressor()
2024-05-27 11:59:23,466:INFO:create_model() successfully completed......................................
2024-05-27 11:59:23,579:INFO:SubProcess create_model() end ==================================
2024-05-27 11:59:23,579:INFO:Creating metrics dataframe
2024-05-27 11:59:23,608:INFO:Initializing create_model()
2024-05-27 11:59:23,608:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 11:59:23,608:INFO:Checking exceptions
2024-05-27 11:59:23,612:INFO:Importing libraries
2024-05-27 11:59:23,613:INFO:Copying training dataset
2024-05-27 11:59:23,623:INFO:Defining folds
2024-05-27 11:59:23,623:INFO:Declaring metric variables
2024-05-27 11:59:23,624:INFO:Importing untrained model
2024-05-27 11:59:23,624:INFO:Declaring custom model
2024-05-27 11:59:23,625:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 11:59:23,638:INFO:Cross validation set to False
2024-05-27 11:59:23,639:INFO:Fitting Model
2024-05-27 11:59:23,856:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001120 seconds.
2024-05-27 11:59:23,856:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-27 11:59:23,856:INFO:[LightGBM] [Info] Total Bins 1660
2024-05-27 11:59:23,857:INFO:[LightGBM] [Info] Number of data points in the train set: 910, number of used features: 15
2024-05-27 11:59:23,858:INFO:[LightGBM] [Info] Start training from score -0.029448
2024-05-27 11:59:23,992:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 11:59:23,992:INFO:create_model() successfully completed......................................
2024-05-27 11:59:24,207:INFO:_master_model_container: 18
2024-05-27 11:59:24,207:INFO:_display_container: 2
2024-05-27 11:59:24,208:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 11:59:24,208:INFO:compare_models() successfully completed......................................
2024-05-27 11:59:51,727:INFO:Initializing tune_model()
2024-05-27 11:59:51,727:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-05-27 11:59:51,729:INFO:Checking exceptions
2024-05-27 11:59:51,765:INFO:Copying training dataset
2024-05-27 11:59:51,774:INFO:Checking base model
2024-05-27 11:59:51,775:INFO:Base model : Light Gradient Boosting Machine
2024-05-27 11:59:51,785:INFO:Declaring metric variables
2024-05-27 11:59:51,794:INFO:Defining Hyperparameters
2024-05-27 11:59:51,983:INFO:Tuning with n_jobs=-1
2024-05-27 11:59:51,983:INFO:Initializing RandomizedSearchCV
2024-05-27 12:00:05,945:INFO:best_params: {'actual_estimator__reg_lambda': 5, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 100, 'actual_estimator__min_split_gain': 0.6, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.8}
2024-05-27 12:00:05,947:INFO:Hyperparameter search completed
2024-05-27 12:00:05,947:INFO:SubProcess create_model() called ==================================
2024-05-27 12:00:05,948:INFO:Initializing create_model()
2024-05-27 12:00:05,949:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEB79F2C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 5, 'reg_alpha': 0.001, 'num_leaves': 30, 'n_estimators': 100, 'min_split_gain': 0.6, 'min_child_samples': 6, 'learning_rate': 0.2, 'feature_fraction': 0.8, 'bagging_freq': 3, 'bagging_fraction': 0.8})
2024-05-27 12:00:05,949:INFO:Checking exceptions
2024-05-27 12:00:05,949:INFO:Importing libraries
2024-05-27 12:00:05,950:INFO:Copying training dataset
2024-05-27 12:00:05,965:INFO:Defining folds
2024-05-27 12:00:05,965:INFO:Declaring metric variables
2024-05-27 12:00:05,971:INFO:Importing untrained model
2024-05-27 12:00:05,971:INFO:Declaring custom model
2024-05-27 12:00:05,978:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 12:00:05,991:INFO:Starting cross validation
2024-05-27 12:00:06,015:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:00:07,101:INFO:Calculating mean and std
2024-05-27 12:00:07,103:INFO:Creating metrics dataframe
2024-05-27 12:00:07,113:INFO:Finalizing model
2024-05-27 12:00:07,535:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-05-27 12:00:07,536:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-05-27 12:00:07,536:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-05-27 12:00:07,539:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-05-27 12:00:07,539:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-05-27 12:00:07,539:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-05-27 12:00:07,540:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000483 seconds.
2024-05-27 12:00:07,540:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-27 12:00:07,540:INFO:[LightGBM] [Info] Total Bins 1660
2024-05-27 12:00:07,546:INFO:[LightGBM] [Info] Number of data points in the train set: 910, number of used features: 15
2024-05-27 12:00:07,547:INFO:[LightGBM] [Info] Start training from score -0.029448
2024-05-27 12:00:07,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,563:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,567:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,567:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,567:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,568:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,568:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,568:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,569:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,569:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,569:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,570:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,570:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,571:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,571:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,571:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,571:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,572:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,572:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,572:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,573:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,573:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,573:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,574:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,574:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,574:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,575:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,575:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,575:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,576:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,576:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,576:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,576:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,577:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,577:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,578:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,578:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,578:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,579:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,579:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,579:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,580:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,580:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,580:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,581:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,581:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,581:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,581:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,582:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,582:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,582:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,583:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,583:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,583:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,584:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,584:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,584:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,585:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,585:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,585:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,586:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,586:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,586:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,586:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,587:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,587:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,587:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,588:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,588:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:00:07,588:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:00:07,602:INFO:Uploading results into container
2024-05-27 12:00:07,604:INFO:Uploading model into container now
2024-05-27 12:00:07,605:INFO:_master_model_container: 19
2024-05-27 12:00:07,605:INFO:_display_container: 3
2024-05-27 12:00:07,607:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=3, feature_fraction=0.8,
              learning_rate=0.2, min_child_samples=6, min_split_gain=0.6,
              n_jobs=-1, num_leaves=30, random_state=42, reg_alpha=0.001,
              reg_lambda=5)
2024-05-27 12:00:07,607:INFO:create_model() successfully completed......................................
2024-05-27 12:00:07,745:INFO:SubProcess create_model() end ==================================
2024-05-27 12:00:07,745:INFO:choose_better activated
2024-05-27 12:00:07,751:INFO:SubProcess create_model() called ==================================
2024-05-27 12:00:07,752:INFO:Initializing create_model()
2024-05-27 12:00:07,752:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:00:07,752:INFO:Checking exceptions
2024-05-27 12:00:07,754:INFO:Importing libraries
2024-05-27 12:00:07,754:INFO:Copying training dataset
2024-05-27 12:00:07,761:INFO:Defining folds
2024-05-27 12:00:07,762:INFO:Declaring metric variables
2024-05-27 12:00:07,762:INFO:Importing untrained model
2024-05-27 12:00:07,762:INFO:Declaring custom model
2024-05-27 12:00:07,763:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 12:00:07,763:INFO:Starting cross validation
2024-05-27 12:00:07,774:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:00:10,313:INFO:Calculating mean and std
2024-05-27 12:00:10,314:INFO:Creating metrics dataframe
2024-05-27 12:00:10,317:INFO:Finalizing model
2024-05-27 12:00:10,617:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000341 seconds.
2024-05-27 12:00:10,617:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-27 12:00:10,618:INFO:[LightGBM] [Info] Total Bins 1660
2024-05-27 12:00:10,618:INFO:[LightGBM] [Info] Number of data points in the train set: 910, number of used features: 15
2024-05-27 12:00:10,618:INFO:[LightGBM] [Info] Start training from score -0.029448
2024-05-27 12:00:10,718:INFO:Uploading results into container
2024-05-27 12:00:10,719:INFO:Uploading model into container now
2024-05-27 12:00:10,719:INFO:_master_model_container: 20
2024-05-27 12:00:10,720:INFO:_display_container: 4
2024-05-27 12:00:10,720:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:00:10,720:INFO:create_model() successfully completed......................................
2024-05-27 12:00:10,859:INFO:SubProcess create_model() end ==================================
2024-05-27 12:00:10,860:INFO:LGBMRegressor(n_jobs=-1, random_state=42) result for R2 is 0.8022
2024-05-27 12:00:10,861:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=3, feature_fraction=0.8,
              learning_rate=0.2, min_child_samples=6, min_split_gain=0.6,
              n_jobs=-1, num_leaves=30, random_state=42, reg_alpha=0.001,
              reg_lambda=5) result for R2 is 0.7718
2024-05-27 12:00:10,862:INFO:LGBMRegressor(n_jobs=-1, random_state=42) is best model
2024-05-27 12:00:10,863:INFO:choose_better completed
2024-05-27 12:00:10,863:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-27 12:00:10,881:INFO:_master_model_container: 20
2024-05-27 12:00:10,881:INFO:_display_container: 3
2024-05-27 12:00:10,882:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:00:10,882:INFO:tune_model() successfully completed......................................
2024-05-27 12:00:31,689:INFO:Initializing plot_model()
2024-05-27 12:00:31,690:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:00:31,690:INFO:Checking exceptions
2024-05-27 12:00:31,698:INFO:Preloading libraries
2024-05-27 12:00:31,709:INFO:Copying training dataset
2024-05-27 12:00:31,709:INFO:Plot type: feature
2024-05-27 12:00:31,710:WARNING:No coef_ found. Trying feature_importances_
2024-05-27 12:00:32,086:INFO:Visual Rendered Successfully
2024-05-27 12:00:32,199:INFO:plot_model() successfully completed......................................
2024-05-27 12:00:32,200:INFO:Initializing plot_model()
2024-05-27 12:00:32,200:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=error, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:00:32,201:INFO:Checking exceptions
2024-05-27 12:00:32,206:INFO:Preloading libraries
2024-05-27 12:00:32,216:INFO:Copying training dataset
2024-05-27 12:00:32,217:INFO:Plot type: error
2024-05-27 12:00:32,589:INFO:Fitting Model
2024-05-27 12:00:32,589:INFO:Scoring test/hold-out set
2024-05-27 12:00:33,171:INFO:Visual Rendered Successfully
2024-05-27 12:00:33,317:INFO:plot_model() successfully completed......................................
2024-05-27 12:00:33,318:INFO:Initializing plot_model()
2024-05-27 12:00:33,319:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=residuals, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:00:33,319:INFO:Checking exceptions
2024-05-27 12:00:33,324:INFO:Preloading libraries
2024-05-27 12:00:33,335:INFO:Copying training dataset
2024-05-27 12:00:33,335:INFO:Plot type: residuals
2024-05-27 12:00:33,696:INFO:Fitting Model
2024-05-27 12:00:33,789:INFO:Scoring test/hold-out set
2024-05-27 12:00:34,250:INFO:Visual Rendered Successfully
2024-05-27 12:00:34,378:INFO:plot_model() successfully completed......................................
2024-05-27 12:00:56,379:INFO:Initializing plot_model()
2024-05-27 12:00:56,380:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:00:56,380:INFO:Checking exceptions
2024-05-27 12:00:56,388:INFO:Preloading libraries
2024-05-27 12:00:56,400:INFO:Copying training dataset
2024-05-27 12:00:56,400:INFO:Plot type: feature
2024-05-27 12:00:56,401:WARNING:No coef_ found. Trying feature_importances_
2024-05-27 12:00:56,736:INFO:Visual Rendered Successfully
2024-05-27 12:00:56,851:INFO:plot_model() successfully completed......................................
2024-05-27 12:00:56,852:INFO:Initializing plot_model()
2024-05-27 12:00:56,852:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=error, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:00:56,852:INFO:Checking exceptions
2024-05-27 12:00:56,858:INFO:Preloading libraries
2024-05-27 12:00:56,867:INFO:Copying training dataset
2024-05-27 12:00:56,867:INFO:Plot type: error
2024-05-27 12:00:57,171:INFO:Fitting Model
2024-05-27 12:00:57,171:INFO:Scoring test/hold-out set
2024-05-27 12:00:57,455:INFO:Visual Rendered Successfully
2024-05-27 12:00:57,572:INFO:plot_model() successfully completed......................................
2024-05-27 12:00:57,574:INFO:Initializing plot_model()
2024-05-27 12:00:57,574:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=residuals, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:00:57,574:INFO:Checking exceptions
2024-05-27 12:00:57,580:INFO:Preloading libraries
2024-05-27 12:00:57,592:INFO:Copying training dataset
2024-05-27 12:00:57,592:INFO:Plot type: residuals
2024-05-27 12:00:57,909:INFO:Fitting Model
2024-05-27 12:00:58,001:INFO:Scoring test/hold-out set
2024-05-27 12:00:58,452:INFO:Visual Rendered Successfully
2024-05-27 12:00:58,594:INFO:plot_model() successfully completed......................................
2024-05-27 12:01:30,846:INFO:Initializing evaluate_model()
2024-05-27 12:01:30,848:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-27 12:01:30,908:INFO:Initializing plot_model()
2024-05-27 12:01:30,909:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-27 12:01:30,909:INFO:Checking exceptions
2024-05-27 12:01:30,914:INFO:Preloading libraries
2024-05-27 12:01:30,926:INFO:Copying training dataset
2024-05-27 12:01:30,926:INFO:Plot type: pipeline
2024-05-27 12:01:31,266:INFO:Visual Rendered Successfully
2024-05-27 12:01:31,380:INFO:plot_model() successfully completed......................................
2024-05-27 12:01:37,363:INFO:Initializing plot_model()
2024-05-27 12:01:37,363:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=residuals, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-27 12:01:37,363:INFO:Checking exceptions
2024-05-27 12:01:37,368:INFO:Preloading libraries
2024-05-27 12:01:37,379:INFO:Copying training dataset
2024-05-27 12:01:37,380:INFO:Plot type: residuals
2024-05-27 12:01:37,715:INFO:Fitting Model
2024-05-27 12:01:37,798:INFO:Scoring test/hold-out set
2024-05-27 12:01:38,223:INFO:Visual Rendered Successfully
2024-05-27 12:01:38,393:INFO:plot_model() successfully completed......................................
2024-05-27 12:01:46,648:INFO:Initializing plot_model()
2024-05-27 12:01:46,648:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=error, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-27 12:01:46,648:INFO:Checking exceptions
2024-05-27 12:01:46,653:INFO:Preloading libraries
2024-05-27 12:01:46,667:INFO:Copying training dataset
2024-05-27 12:01:46,667:INFO:Plot type: error
2024-05-27 12:01:46,980:INFO:Fitting Model
2024-05-27 12:01:46,980:INFO:Scoring test/hold-out set
2024-05-27 12:01:47,266:INFO:Visual Rendered Successfully
2024-05-27 12:01:47,375:INFO:plot_model() successfully completed......................................
2024-05-27 12:01:51,602:INFO:Initializing plot_model()
2024-05-27 12:01:51,602:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=feature, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-27 12:01:51,602:INFO:Checking exceptions
2024-05-27 12:01:51,607:INFO:Preloading libraries
2024-05-27 12:01:51,620:INFO:Copying training dataset
2024-05-27 12:01:51,620:INFO:Plot type: feature
2024-05-27 12:01:51,621:WARNING:No coef_ found. Trying feature_importances_
2024-05-27 12:01:51,905:INFO:Visual Rendered Successfully
2024-05-27 12:01:52,014:INFO:plot_model() successfully completed......................................
2024-05-27 12:01:54,388:INFO:Initializing plot_model()
2024-05-27 12:01:54,389:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=feature_all, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-27 12:01:54,389:INFO:Checking exceptions
2024-05-27 12:01:54,395:INFO:Preloading libraries
2024-05-27 12:01:54,408:INFO:Copying training dataset
2024-05-27 12:01:54,408:INFO:Plot type: feature_all
2024-05-27 12:01:54,520:WARNING:No coef_ found. Trying feature_importances_
2024-05-27 12:01:54,807:INFO:Visual Rendered Successfully
2024-05-27 12:01:54,914:INFO:plot_model() successfully completed......................................
2024-05-27 12:01:59,591:INFO:Initializing plot_model()
2024-05-27 12:01:59,592:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=tree, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-27 12:01:59,592:INFO:Checking exceptions
2024-05-27 12:02:03,309:INFO:Initializing plot_model()
2024-05-27 12:02:03,309:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=learning, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-27 12:02:03,309:INFO:Checking exceptions
2024-05-27 12:02:03,317:INFO:Preloading libraries
2024-05-27 12:02:03,329:INFO:Copying training dataset
2024-05-27 12:02:03,329:INFO:Plot type: learning
2024-05-27 12:02:03,679:INFO:Fitting Model
2024-05-27 12:02:13,058:INFO:Visual Rendered Successfully
2024-05-27 12:02:13,224:INFO:plot_model() successfully completed......................................
2024-05-27 12:03:03,883:INFO:Initializing evaluate_model()
2024-05-27 12:03:03,883:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-27 12:03:03,897:INFO:Initializing plot_model()
2024-05-27 12:03:03,898:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-27 12:03:03,898:INFO:Checking exceptions
2024-05-27 12:03:03,904:INFO:Preloading libraries
2024-05-27 12:03:03,919:INFO:Copying training dataset
2024-05-27 12:03:03,919:INFO:Plot type: pipeline
2024-05-27 12:03:04,121:INFO:Visual Rendered Successfully
2024-05-27 12:03:04,262:INFO:plot_model() successfully completed......................................
2024-05-27 12:03:07,798:INFO:Initializing plot_model()
2024-05-27 12:03:07,798:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=learning, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-27 12:03:07,798:INFO:Checking exceptions
2024-05-27 12:03:07,803:INFO:Preloading libraries
2024-05-27 12:03:07,814:INFO:Copying training dataset
2024-05-27 12:03:07,815:INFO:Plot type: learning
2024-05-27 12:03:08,140:INFO:Fitting Model
2024-05-27 12:03:18,380:INFO:Visual Rendered Successfully
2024-05-27 12:03:18,535:INFO:plot_model() successfully completed......................................
2024-05-27 12:03:26,134:INFO:Initializing plot_model()
2024-05-27 12:03:26,134:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=residuals, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-27 12:03:26,134:INFO:Checking exceptions
2024-05-27 12:03:26,139:INFO:Preloading libraries
2024-05-27 12:03:26,150:INFO:Copying training dataset
2024-05-27 12:03:26,151:INFO:Plot type: residuals
2024-05-27 12:03:26,535:INFO:Fitting Model
2024-05-27 12:03:26,620:INFO:Scoring test/hold-out set
2024-05-27 12:03:27,051:INFO:Visual Rendered Successfully
2024-05-27 12:03:27,181:INFO:plot_model() successfully completed......................................
2024-05-27 12:03:38,259:INFO:Initializing plot_model()
2024-05-27 12:03:38,260:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC35C8E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=residuals, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-27 12:03:38,260:INFO:Checking exceptions
2024-05-27 12:03:38,264:INFO:Preloading libraries
2024-05-27 12:03:38,276:INFO:Copying training dataset
2024-05-27 12:03:38,277:INFO:Plot type: residuals
2024-05-27 12:03:38,629:INFO:Fitting Model
2024-05-27 12:03:38,714:INFO:Scoring test/hold-out set
2024-05-27 12:03:39,180:INFO:Visual Rendered Successfully
2024-05-27 12:03:39,310:INFO:plot_model() successfully completed......................................
2024-05-27 12:29:30,042:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 12:29:30,042:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 12:29:30,042:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 12:29:30,043:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 12:29:30,619:WARNING:C:\Users\muril\AppData\Local\Temp\ipykernel_8820\4212681043.py:2: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
  plt.style.use('seaborn-darkgrid')

2024-05-27 12:31:00,791:WARNING:C:\Users\muril\AppData\Local\Temp\ipykernel_8820\1066813642.py:3: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_clean[numeric_columns] = scaler.fit_transform(df_clean[numeric_columns])

2024-05-27 12:31:44,030:WARNING:c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
141 fits failed out of a total of 300.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
98 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 1467, in wrapper
    estimator._validate_params()
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.

--------------------------------------------------------------------------------
43 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 1467, in wrapper
    estimator._validate_params()
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-27 12:31:44,039:WARNING:c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.73690131 0.7723179  0.76899183        nan        nan 0.70603466
 0.76899183        nan 0.72649309 0.77494848        nan        nan
        nan 0.76775927 0.70724616 0.64097707        nan 0.7714591
        nan        nan 0.69886104        nan        nan        nan
 0.69316    0.74093953        nan        nan        nan 0.77852071
        nan 0.72663432 0.73795808 0.69886104        nan        nan
        nan        nan 0.77254916        nan 0.6953924         nan
        nan        nan 0.76856778 0.69167232        nan 0.70716815
 0.77776253 0.77140226 0.75186111        nan 0.74493442        nan
        nan 0.70455147 0.72045513        nan        nan        nan
        nan        nan 0.70401667        nan        nan 0.77201249
        nan        nan 0.77220018        nan 0.72675909 0.74093953
 0.77889893        nan        nan 0.70631594        nan 0.74838051
 0.66321771 0.70773896 0.72697562 0.72675909 0.69642805        nan
 0.72045513 0.69886104        nan        nan 0.74838051 0.76027421
 0.75135719 0.70628675        nan 0.72663432        nan 0.77178874
 0.72663432 0.7723179  0.75135616        nan]
  warnings.warn(

2024-05-27 12:32:22,822:WARNING:c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
141 fits failed out of a total of 300.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
40 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 1467, in wrapper
    estimator._validate_params()
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.

--------------------------------------------------------------------------------
101 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 1467, in wrapper
    estimator._validate_params()
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-27 12:32:22,826:WARNING:c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.75585937 0.79038632 0.77436615        nan        nan 0.74595153
 0.77436615        nan 0.76142618 0.78462259        nan        nan
        nan 0.78063503 0.74489877 0.72712048        nan 0.78613949
        nan        nan 0.74547562        nan        nan        nan
 0.73151238 0.77264907        nan        nan        nan 0.79116805
        nan 0.76059954 0.75986035 0.74547562        nan        nan
        nan        nan 0.78932932        nan 0.73916425        nan
        nan        nan 0.7793353  0.7253631         nan 0.74008125
 0.79189862 0.78684028 0.77842616        nan 0.75567687        nan
        nan 0.74347782 0.75170118        nan        nan        nan
        nan        nan 0.73945853        nan        nan 0.78938319
        nan        nan 0.78975469        nan 0.76005707 0.77264907
 0.790783          nan        nan 0.74597706        nan 0.77582515
 0.73262594 0.74496854 0.75984297 0.76005707 0.7397241         nan
 0.75170118 0.74547562        nan        nan 0.77582515 0.77261023
 0.778412   0.74471839        nan 0.76059954        nan 0.78365244
 0.76059954 0.79038632 0.77840329        nan]
  warnings.warn(

2024-05-27 12:33:40,291:INFO:PyCaret RegressionExperiment
2024-05-27 12:33:40,292:INFO:Logging name: reg-default-name
2024-05-27 12:33:40,292:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-27 12:33:40,292:INFO:version 3.3.0
2024-05-27 12:33:40,293:INFO:Initializing setup()
2024-05-27 12:33:40,293:INFO:self.USI: eab5
2024-05-27 12:33:40,293:INFO:self._variable_keys: {'exp_name_log', 'X_train', 'logging_param', 'gpu_n_jobs_param', 'y_train', 'idx', 'gpu_param', 'y', '_ml_usecase', 'html_param', 'fold_generator', 'n_jobs_param', 'exp_id', 'fold_groups_param', 'data', 'seed', 'X', 'y_test', 'target_param', 'pipeline', '_available_plots', 'fold_shuffle_param', 'transform_target_param', 'log_plots_param', 'X_test', 'memory', 'USI'}
2024-05-27 12:33:40,293:INFO:Checking environment
2024-05-27 12:33:40,294:INFO:python_version: 3.11.5
2024-05-27 12:33:40,294:INFO:python_build: ('tags/v3.11.5:cce6ba9', 'Aug 24 2023 14:38:34')
2024-05-27 12:33:40,294:INFO:machine: AMD64
2024-05-27 12:33:40,294:INFO:platform: Windows-10-10.0.22631-SP0
2024-05-27 12:33:40,312:INFO:Memory: svmem(total=8459792384, available=694624256, percent=91.8, used=7765168128, free=694624256)
2024-05-27 12:33:40,313:INFO:Physical Core: 4
2024-05-27 12:33:40,313:INFO:Logical Core: 8
2024-05-27 12:33:40,313:INFO:Checking libraries
2024-05-27 12:33:40,313:INFO:System:
2024-05-27 12:33:40,314:INFO:    python: 3.11.5 (tags/v3.11.5:cce6ba9, Aug 24 2023, 14:38:34) [MSC v.1936 64 bit (AMD64)]
2024-05-27 12:33:40,314:INFO:executable: c:\Users\muril\AppData\Local\Programs\Python\Python311\python.exe
2024-05-27 12:33:40,314:INFO:   machine: Windows-10-10.0.22631-SP0
2024-05-27 12:33:40,314:INFO:PyCaret required dependencies:
2024-05-27 12:33:40,322:INFO:                 pip: 24.0
2024-05-27 12:33:40,322:INFO:          setuptools: 68.1.2
2024-05-27 12:33:40,322:INFO:             pycaret: 3.3.0
2024-05-27 12:33:40,322:INFO:             IPython: 8.14.0
2024-05-27 12:33:40,322:INFO:          ipywidgets: 8.1.0
2024-05-27 12:33:40,322:INFO:                tqdm: 4.66.1
2024-05-27 12:33:40,322:INFO:               numpy: 1.26.4
2024-05-27 12:33:40,322:INFO:              pandas: 2.0.2
2024-05-27 12:33:40,323:INFO:              jinja2: 3.1.2
2024-05-27 12:33:40,323:INFO:               scipy: 1.10.1
2024-05-27 12:33:40,323:INFO:              joblib: 1.2.0
2024-05-27 12:33:40,323:INFO:             sklearn: 1.4.1.post1
2024-05-27 12:33:40,323:INFO:                pyod: 1.1.3
2024-05-27 12:33:40,323:INFO:            imblearn: 0.12.1
2024-05-27 12:33:40,323:INFO:   category_encoders: 2.6.3
2024-05-27 12:33:40,323:INFO:            lightgbm: 4.3.0
2024-05-27 12:33:40,323:INFO:               numba: 0.59.1
2024-05-27 12:33:40,323:INFO:            requests: 2.31.0
2024-05-27 12:33:40,324:INFO:          matplotlib: 3.7.1
2024-05-27 12:33:40,324:INFO:          scikitplot: 0.3.7
2024-05-27 12:33:40,324:INFO:         yellowbrick: 1.5
2024-05-27 12:33:40,324:INFO:              plotly: 5.18.0
2024-05-27 12:33:40,324:INFO:    plotly-resampler: Not installed
2024-05-27 12:33:40,324:INFO:             kaleido: 0.2.1
2024-05-27 12:33:40,324:INFO:           schemdraw: 0.15
2024-05-27 12:33:40,324:INFO:         statsmodels: 0.14.1
2024-05-27 12:33:40,324:INFO:              sktime: 0.28.0
2024-05-27 12:33:40,324:INFO:               tbats: 1.1.3
2024-05-27 12:33:40,324:INFO:            pmdarima: 2.0.4
2024-05-27 12:33:40,324:INFO:              psutil: 5.9.5
2024-05-27 12:33:40,324:INFO:          markupsafe: 2.1.2
2024-05-27 12:33:40,324:INFO:             pickle5: Not installed
2024-05-27 12:33:40,324:INFO:         cloudpickle: 3.0.0
2024-05-27 12:33:40,325:INFO:         deprecation: 2.1.0
2024-05-27 12:33:40,325:INFO:              xxhash: 3.4.1
2024-05-27 12:33:40,325:INFO:           wurlitzer: Not installed
2024-05-27 12:33:40,325:INFO:PyCaret optional dependencies:
2024-05-27 12:33:40,359:INFO:                shap: Not installed
2024-05-27 12:33:40,359:INFO:           interpret: Not installed
2024-05-27 12:33:40,360:INFO:                umap: Not installed
2024-05-27 12:33:40,360:INFO:     ydata_profiling: Not installed
2024-05-27 12:33:40,360:INFO:  explainerdashboard: Not installed
2024-05-27 12:33:40,360:INFO:             autoviz: Not installed
2024-05-27 12:33:40,360:INFO:           fairlearn: Not installed
2024-05-27 12:33:40,360:INFO:          deepchecks: Not installed
2024-05-27 12:33:40,360:INFO:             xgboost: Not installed
2024-05-27 12:33:40,360:INFO:            catboost: Not installed
2024-05-27 12:33:40,360:INFO:              kmodes: Not installed
2024-05-27 12:33:40,360:INFO:             mlxtend: Not installed
2024-05-27 12:33:40,360:INFO:       statsforecast: Not installed
2024-05-27 12:33:40,360:INFO:        tune_sklearn: Not installed
2024-05-27 12:33:40,360:INFO:                 ray: Not installed
2024-05-27 12:33:40,360:INFO:            hyperopt: Not installed
2024-05-27 12:33:40,360:INFO:              optuna: Not installed
2024-05-27 12:33:40,360:INFO:               skopt: Not installed
2024-05-27 12:33:40,360:INFO:              mlflow: Not installed
2024-05-27 12:33:40,360:INFO:              gradio: Not installed
2024-05-27 12:33:40,360:INFO:             fastapi: Not installed
2024-05-27 12:33:40,360:INFO:             uvicorn: Not installed
2024-05-27 12:33:40,361:INFO:              m2cgen: Not installed
2024-05-27 12:33:40,361:INFO:           evidently: Not installed
2024-05-27 12:33:40,361:INFO:               fugue: Not installed
2024-05-27 12:33:40,361:INFO:           streamlit: 1.28.1
2024-05-27 12:33:40,361:INFO:             prophet: Not installed
2024-05-27 12:33:40,361:INFO:None
2024-05-27 12:33:40,361:INFO:Set up data.
2024-05-27 12:33:40,378:INFO:Set up folding strategy.
2024-05-27 12:33:40,378:INFO:Set up train/test split.
2024-05-27 12:33:40,388:INFO:Set up index.
2024-05-27 12:33:40,388:INFO:Assigning column types.
2024-05-27 12:33:40,399:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-27 12:33:40,401:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-27 12:33:40,408:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-27 12:33:40,417:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 12:33:40,508:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 12:33:40,573:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 12:33:40,573:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:40,574:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:40,575:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-27 12:33:40,581:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-27 12:33:40,588:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 12:33:40,676:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 12:33:40,737:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 12:33:40,739:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:40,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:40,740:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-27 12:33:40,748:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-27 12:33:40,753:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 12:33:40,838:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 12:33:40,900:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 12:33:40,903:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:40,903:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:40,909:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-27 12:33:40,916:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 12:33:41,017:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 12:33:41,092:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 12:33:41,093:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:41,093:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:41,093:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-27 12:33:41,111:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 12:33:41,198:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 12:33:41,268:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 12:33:41,269:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:41,270:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:41,283:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 12:33:41,373:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 12:33:41,471:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 12:33:41,473:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:41,474:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:41,475:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-27 12:33:41,860:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 12:33:41,948:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 12:33:41,949:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:41,949:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:42,064:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 12:33:42,136:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 12:33:42,137:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:42,137:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:42,137:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-27 12:33:42,241:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 12:33:42,313:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:42,313:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:42,410:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 12:33:42,473:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:42,474:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:42,474:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-27 12:33:42,645:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:42,645:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:42,850:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:42,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:42,865:INFO:Preparing preprocessing pipeline...
2024-05-27 12:33:42,865:INFO:Set up simple imputation.
2024-05-27 12:33:42,865:INFO:Set up removing outliers.
2024-05-27 12:33:42,867:INFO:Set up feature normalization.
2024-05-27 12:33:42,944:INFO:Finished creating preprocessing pipeline.
2024-05-27 12:33:42,956:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\muril\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['num_bed', 'num_bath',
                                             'size_house', 'size_lot',
                                             'num_floors', 'is_waterfront',
                                             'condition', 'size_basement',
                                             'year_built', 'renovation_date',
                                             'zip', 'latitude', 'longitude',
                                             'avg_size_neighbor_houses',
                                             'avg_size_neighbor_lot',
                                             'zip_prefix_3', 'zip_prefix_4'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2024-05-27 12:33:42,956:INFO:Creating final display dataframe.
2024-05-27 12:33:43,162:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target             price
2                   Target type        Regression
3           Original data shape        (1370, 18)
4        Transformed data shape        (1322, 18)
5   Transformed train set shape         (910, 18)
6    Transformed test set shape         (412, 18)
7              Numeric features                17
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12              Remove outliers              True
13           Outliers threshold              0.05
14                    Normalize              True
15             Normalize method            zscore
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              eab5
2024-05-27 12:33:43,372:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:43,373:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:43,534:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:43,534:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:33:43,538:WARNING:c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-05-27 12:33:43,538:INFO:setup() successfully completed in 3.27s...............
2024-05-27 12:33:43,550:INFO:Initializing compare_models()
2024-05-27 12:33:43,550:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-05-27 12:33:43,551:INFO:Checking exceptions
2024-05-27 12:33:43,558:INFO:Preparing display monitor
2024-05-27 12:33:43,594:INFO:Initializing Linear Regression
2024-05-27 12:33:43,594:INFO:Total runtime is 0.0 minutes
2024-05-27 12:33:43,601:INFO:SubProcess create_model() called ==================================
2024-05-27 12:33:43,602:INFO:Initializing create_model()
2024-05-27 12:33:43,602:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B12A8CC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:33:43,602:INFO:Checking exceptions
2024-05-27 12:33:43,602:INFO:Importing libraries
2024-05-27 12:33:43,602:INFO:Copying training dataset
2024-05-27 12:33:43,609:INFO:Defining folds
2024-05-27 12:33:43,610:INFO:Declaring metric variables
2024-05-27 12:33:43,614:INFO:Importing untrained model
2024-05-27 12:33:43,619:INFO:Linear Regression Imported successfully
2024-05-27 12:33:43,630:INFO:Starting cross validation
2024-05-27 12:33:43,649:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:33:47,352:INFO:Calculating mean and std
2024-05-27 12:33:47,354:INFO:Creating metrics dataframe
2024-05-27 12:33:47,361:INFO:Uploading results into container
2024-05-27 12:33:47,362:INFO:Uploading model into container now
2024-05-27 12:33:47,363:INFO:_master_model_container: 1
2024-05-27 12:33:47,364:INFO:_display_container: 2
2024-05-27 12:33:47,364:INFO:LinearRegression(n_jobs=-1)
2024-05-27 12:33:47,365:INFO:create_model() successfully completed......................................
2024-05-27 12:33:48,156:INFO:SubProcess create_model() end ==================================
2024-05-27 12:33:48,157:INFO:Creating metrics dataframe
2024-05-27 12:33:48,166:INFO:Initializing Lasso Regression
2024-05-27 12:33:48,166:INFO:Total runtime is 0.07619152466456096 minutes
2024-05-27 12:33:48,170:INFO:SubProcess create_model() called ==================================
2024-05-27 12:33:48,171:INFO:Initializing create_model()
2024-05-27 12:33:48,171:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B12A8CC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:33:48,172:INFO:Checking exceptions
2024-05-27 12:33:48,172:INFO:Importing libraries
2024-05-27 12:33:48,172:INFO:Copying training dataset
2024-05-27 12:33:48,191:INFO:Defining folds
2024-05-27 12:33:48,192:INFO:Declaring metric variables
2024-05-27 12:33:48,202:INFO:Importing untrained model
2024-05-27 12:33:48,209:INFO:Lasso Regression Imported successfully
2024-05-27 12:33:48,227:INFO:Starting cross validation
2024-05-27 12:33:48,230:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:33:49,255:INFO:Calculating mean and std
2024-05-27 12:33:49,257:INFO:Creating metrics dataframe
2024-05-27 12:33:49,260:INFO:Uploading results into container
2024-05-27 12:33:49,261:INFO:Uploading model into container now
2024-05-27 12:33:49,263:INFO:_master_model_container: 2
2024-05-27 12:33:49,263:INFO:_display_container: 2
2024-05-27 12:33:49,264:INFO:Lasso(random_state=42)
2024-05-27 12:33:49,264:INFO:create_model() successfully completed......................................
2024-05-27 12:33:49,371:INFO:SubProcess create_model() end ==================================
2024-05-27 12:33:49,372:INFO:Creating metrics dataframe
2024-05-27 12:33:49,381:INFO:Initializing Ridge Regression
2024-05-27 12:33:49,381:INFO:Total runtime is 0.09645317792892456 minutes
2024-05-27 12:33:49,385:INFO:SubProcess create_model() called ==================================
2024-05-27 12:33:49,385:INFO:Initializing create_model()
2024-05-27 12:33:49,387:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B12A8CC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:33:49,387:INFO:Checking exceptions
2024-05-27 12:33:49,387:INFO:Importing libraries
2024-05-27 12:33:49,387:INFO:Copying training dataset
2024-05-27 12:33:49,396:INFO:Defining folds
2024-05-27 12:33:49,397:INFO:Declaring metric variables
2024-05-27 12:33:49,401:INFO:Importing untrained model
2024-05-27 12:33:49,407:INFO:Ridge Regression Imported successfully
2024-05-27 12:33:49,419:INFO:Starting cross validation
2024-05-27 12:33:49,421:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:33:50,718:INFO:Calculating mean and std
2024-05-27 12:33:50,721:INFO:Creating metrics dataframe
2024-05-27 12:33:50,725:INFO:Uploading results into container
2024-05-27 12:33:50,727:INFO:Uploading model into container now
2024-05-27 12:33:50,728:INFO:_master_model_container: 3
2024-05-27 12:33:50,729:INFO:_display_container: 2
2024-05-27 12:33:50,729:INFO:Ridge(random_state=42)
2024-05-27 12:33:50,730:INFO:create_model() successfully completed......................................
2024-05-27 12:33:50,976:INFO:SubProcess create_model() end ==================================
2024-05-27 12:33:50,976:INFO:Creating metrics dataframe
2024-05-27 12:33:50,991:INFO:Initializing Elastic Net
2024-05-27 12:33:50,991:INFO:Total runtime is 0.12327645619710287 minutes
2024-05-27 12:33:50,998:INFO:SubProcess create_model() called ==================================
2024-05-27 12:33:50,998:INFO:Initializing create_model()
2024-05-27 12:33:50,999:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B12A8CC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:33:50,999:INFO:Checking exceptions
2024-05-27 12:33:50,999:INFO:Importing libraries
2024-05-27 12:33:50,999:INFO:Copying training dataset
2024-05-27 12:33:51,010:INFO:Defining folds
2024-05-27 12:33:51,010:INFO:Declaring metric variables
2024-05-27 12:33:51,017:INFO:Importing untrained model
2024-05-27 12:33:51,025:INFO:Elastic Net Imported successfully
2024-05-27 12:33:51,038:INFO:Starting cross validation
2024-05-27 12:33:51,041:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:33:51,847:INFO:Calculating mean and std
2024-05-27 12:33:51,849:INFO:Creating metrics dataframe
2024-05-27 12:33:51,851:INFO:Uploading results into container
2024-05-27 12:33:51,852:INFO:Uploading model into container now
2024-05-27 12:33:51,852:INFO:_master_model_container: 4
2024-05-27 12:33:51,852:INFO:_display_container: 2
2024-05-27 12:33:51,853:INFO:ElasticNet(random_state=42)
2024-05-27 12:33:51,853:INFO:create_model() successfully completed......................................
2024-05-27 12:33:51,968:INFO:SubProcess create_model() end ==================================
2024-05-27 12:33:51,968:INFO:Creating metrics dataframe
2024-05-27 12:33:51,982:INFO:Initializing Least Angle Regression
2024-05-27 12:33:51,983:INFO:Total runtime is 0.13981252113978068 minutes
2024-05-27 12:33:51,988:INFO:SubProcess create_model() called ==================================
2024-05-27 12:33:51,989:INFO:Initializing create_model()
2024-05-27 12:33:51,989:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B12A8CC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:33:51,989:INFO:Checking exceptions
2024-05-27 12:33:51,989:INFO:Importing libraries
2024-05-27 12:33:51,989:INFO:Copying training dataset
2024-05-27 12:33:51,999:INFO:Defining folds
2024-05-27 12:33:51,999:INFO:Declaring metric variables
2024-05-27 12:33:52,005:INFO:Importing untrained model
2024-05-27 12:33:52,011:INFO:Least Angle Regression Imported successfully
2024-05-27 12:33:52,020:INFO:Starting cross validation
2024-05-27 12:33:52,022:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:33:52,783:INFO:Calculating mean and std
2024-05-27 12:33:52,784:INFO:Creating metrics dataframe
2024-05-27 12:33:52,786:INFO:Uploading results into container
2024-05-27 12:33:52,787:INFO:Uploading model into container now
2024-05-27 12:33:52,787:INFO:_master_model_container: 5
2024-05-27 12:33:52,787:INFO:_display_container: 2
2024-05-27 12:33:52,788:INFO:Lars(random_state=42)
2024-05-27 12:33:52,788:INFO:create_model() successfully completed......................................
2024-05-27 12:33:52,899:INFO:SubProcess create_model() end ==================================
2024-05-27 12:33:52,899:INFO:Creating metrics dataframe
2024-05-27 12:33:52,915:INFO:Initializing Lasso Least Angle Regression
2024-05-27 12:33:52,916:INFO:Total runtime is 0.15536214907964072 minutes
2024-05-27 12:33:52,921:INFO:SubProcess create_model() called ==================================
2024-05-27 12:33:52,921:INFO:Initializing create_model()
2024-05-27 12:33:52,922:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B12A8CC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:33:52,922:INFO:Checking exceptions
2024-05-27 12:33:52,922:INFO:Importing libraries
2024-05-27 12:33:52,922:INFO:Copying training dataset
2024-05-27 12:33:52,932:INFO:Defining folds
2024-05-27 12:33:52,932:INFO:Declaring metric variables
2024-05-27 12:33:52,936:INFO:Importing untrained model
2024-05-27 12:33:52,941:INFO:Lasso Least Angle Regression Imported successfully
2024-05-27 12:33:52,949:INFO:Starting cross validation
2024-05-27 12:33:52,950:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:33:53,701:INFO:Calculating mean and std
2024-05-27 12:33:53,702:INFO:Creating metrics dataframe
2024-05-27 12:33:53,704:INFO:Uploading results into container
2024-05-27 12:33:53,705:INFO:Uploading model into container now
2024-05-27 12:33:53,705:INFO:_master_model_container: 6
2024-05-27 12:33:53,706:INFO:_display_container: 2
2024-05-27 12:33:53,706:INFO:LassoLars(random_state=42)
2024-05-27 12:33:53,706:INFO:create_model() successfully completed......................................
2024-05-27 12:33:53,818:INFO:SubProcess create_model() end ==================================
2024-05-27 12:33:53,818:INFO:Creating metrics dataframe
2024-05-27 12:33:53,834:INFO:Initializing Orthogonal Matching Pursuit
2024-05-27 12:33:53,834:INFO:Total runtime is 0.17065495649973553 minutes
2024-05-27 12:33:53,839:INFO:SubProcess create_model() called ==================================
2024-05-27 12:33:53,840:INFO:Initializing create_model()
2024-05-27 12:33:53,840:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B12A8CC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:33:53,840:INFO:Checking exceptions
2024-05-27 12:33:53,840:INFO:Importing libraries
2024-05-27 12:33:53,840:INFO:Copying training dataset
2024-05-27 12:33:53,850:INFO:Defining folds
2024-05-27 12:33:53,850:INFO:Declaring metric variables
2024-05-27 12:33:53,854:INFO:Importing untrained model
2024-05-27 12:33:53,859:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-27 12:33:53,867:INFO:Starting cross validation
2024-05-27 12:33:53,868:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:33:54,633:INFO:Calculating mean and std
2024-05-27 12:33:54,634:INFO:Creating metrics dataframe
2024-05-27 12:33:54,636:INFO:Uploading results into container
2024-05-27 12:33:54,637:INFO:Uploading model into container now
2024-05-27 12:33:54,638:INFO:_master_model_container: 7
2024-05-27 12:33:54,638:INFO:_display_container: 2
2024-05-27 12:33:54,638:INFO:OrthogonalMatchingPursuit()
2024-05-27 12:33:54,638:INFO:create_model() successfully completed......................................
2024-05-27 12:33:54,749:INFO:SubProcess create_model() end ==================================
2024-05-27 12:33:54,749:INFO:Creating metrics dataframe
2024-05-27 12:33:54,764:INFO:Initializing Bayesian Ridge
2024-05-27 12:33:54,764:INFO:Total runtime is 0.18617045879364014 minutes
2024-05-27 12:33:54,770:INFO:SubProcess create_model() called ==================================
2024-05-27 12:33:54,771:INFO:Initializing create_model()
2024-05-27 12:33:54,771:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B12A8CC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:33:54,771:INFO:Checking exceptions
2024-05-27 12:33:54,771:INFO:Importing libraries
2024-05-27 12:33:54,771:INFO:Copying training dataset
2024-05-27 12:33:54,783:INFO:Defining folds
2024-05-27 12:33:54,783:INFO:Declaring metric variables
2024-05-27 12:33:54,790:INFO:Importing untrained model
2024-05-27 12:33:54,797:INFO:Bayesian Ridge Imported successfully
2024-05-27 12:33:54,807:INFO:Starting cross validation
2024-05-27 12:33:54,809:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:33:55,735:INFO:Calculating mean and std
2024-05-27 12:33:55,737:INFO:Creating metrics dataframe
2024-05-27 12:33:55,739:INFO:Uploading results into container
2024-05-27 12:33:55,739:INFO:Uploading model into container now
2024-05-27 12:33:55,740:INFO:_master_model_container: 8
2024-05-27 12:33:55,740:INFO:_display_container: 2
2024-05-27 12:33:55,740:INFO:BayesianRidge()
2024-05-27 12:33:55,740:INFO:create_model() successfully completed......................................
2024-05-27 12:33:55,859:INFO:SubProcess create_model() end ==================================
2024-05-27 12:33:55,860:INFO:Creating metrics dataframe
2024-05-27 12:33:55,915:INFO:Initializing Passive Aggressive Regressor
2024-05-27 12:33:55,916:INFO:Total runtime is 0.20535600980122884 minutes
2024-05-27 12:33:55,925:INFO:SubProcess create_model() called ==================================
2024-05-27 12:33:55,926:INFO:Initializing create_model()
2024-05-27 12:33:55,926:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B12A8CC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:33:55,926:INFO:Checking exceptions
2024-05-27 12:33:55,926:INFO:Importing libraries
2024-05-27 12:33:55,926:INFO:Copying training dataset
2024-05-27 12:33:55,941:INFO:Defining folds
2024-05-27 12:33:55,942:INFO:Declaring metric variables
2024-05-27 12:33:55,983:INFO:Importing untrained model
2024-05-27 12:33:55,992:INFO:Passive Aggressive Regressor Imported successfully
2024-05-27 12:33:56,006:INFO:Starting cross validation
2024-05-27 12:33:56,008:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:33:57,226:INFO:Calculating mean and std
2024-05-27 12:33:57,228:INFO:Creating metrics dataframe
2024-05-27 12:33:57,231:INFO:Uploading results into container
2024-05-27 12:33:57,233:INFO:Uploading model into container now
2024-05-27 12:33:57,234:INFO:_master_model_container: 9
2024-05-27 12:33:57,234:INFO:_display_container: 2
2024-05-27 12:33:57,234:INFO:PassiveAggressiveRegressor(random_state=42)
2024-05-27 12:33:57,235:INFO:create_model() successfully completed......................................
2024-05-27 12:33:57,363:INFO:SubProcess create_model() end ==================================
2024-05-27 12:33:57,363:INFO:Creating metrics dataframe
2024-05-27 12:33:57,377:INFO:Initializing Huber Regressor
2024-05-27 12:33:57,377:INFO:Total runtime is 0.22972005605697632 minutes
2024-05-27 12:33:57,384:INFO:SubProcess create_model() called ==================================
2024-05-27 12:33:57,384:INFO:Initializing create_model()
2024-05-27 12:33:57,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B12A8CC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:33:57,385:INFO:Checking exceptions
2024-05-27 12:33:57,385:INFO:Importing libraries
2024-05-27 12:33:57,385:INFO:Copying training dataset
2024-05-27 12:33:57,394:INFO:Defining folds
2024-05-27 12:33:57,394:INFO:Declaring metric variables
2024-05-27 12:33:57,400:INFO:Importing untrained model
2024-05-27 12:33:57,406:INFO:Huber Regressor Imported successfully
2024-05-27 12:33:57,416:INFO:Starting cross validation
2024-05-27 12:33:57,418:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:33:58,699:INFO:Calculating mean and std
2024-05-27 12:33:58,700:INFO:Creating metrics dataframe
2024-05-27 12:33:58,703:INFO:Uploading results into container
2024-05-27 12:33:58,704:INFO:Uploading model into container now
2024-05-27 12:33:58,705:INFO:_master_model_container: 10
2024-05-27 12:33:58,706:INFO:_display_container: 2
2024-05-27 12:33:58,706:INFO:HuberRegressor()
2024-05-27 12:33:58,706:INFO:create_model() successfully completed......................................
2024-05-27 12:33:58,818:INFO:SubProcess create_model() end ==================================
2024-05-27 12:33:58,818:INFO:Creating metrics dataframe
2024-05-27 12:33:58,835:INFO:Initializing K Neighbors Regressor
2024-05-27 12:33:58,836:INFO:Total runtime is 0.25402485132217406 minutes
2024-05-27 12:33:58,841:INFO:SubProcess create_model() called ==================================
2024-05-27 12:33:58,842:INFO:Initializing create_model()
2024-05-27 12:33:58,842:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B12A8CC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:33:58,842:INFO:Checking exceptions
2024-05-27 12:33:58,842:INFO:Importing libraries
2024-05-27 12:33:58,842:INFO:Copying training dataset
2024-05-27 12:33:58,850:INFO:Defining folds
2024-05-27 12:33:58,850:INFO:Declaring metric variables
2024-05-27 12:33:58,856:INFO:Importing untrained model
2024-05-27 12:33:58,861:INFO:K Neighbors Regressor Imported successfully
2024-05-27 12:33:58,871:INFO:Starting cross validation
2024-05-27 12:33:58,873:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:34:00,151:INFO:Calculating mean and std
2024-05-27 12:34:00,152:INFO:Creating metrics dataframe
2024-05-27 12:34:00,156:INFO:Uploading results into container
2024-05-27 12:34:00,157:INFO:Uploading model into container now
2024-05-27 12:34:00,158:INFO:_master_model_container: 11
2024-05-27 12:34:00,158:INFO:_display_container: 2
2024-05-27 12:34:00,162:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-27 12:34:00,162:INFO:create_model() successfully completed......................................
2024-05-27 12:34:00,314:INFO:SubProcess create_model() end ==================================
2024-05-27 12:34:00,315:INFO:Creating metrics dataframe
2024-05-27 12:34:00,332:INFO:Initializing Decision Tree Regressor
2024-05-27 12:34:00,332:INFO:Total runtime is 0.2789603590965271 minutes
2024-05-27 12:34:00,338:INFO:SubProcess create_model() called ==================================
2024-05-27 12:34:00,339:INFO:Initializing create_model()
2024-05-27 12:34:00,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B12A8CC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:34:00,339:INFO:Checking exceptions
2024-05-27 12:34:00,339:INFO:Importing libraries
2024-05-27 12:34:00,339:INFO:Copying training dataset
2024-05-27 12:34:00,386:INFO:Defining folds
2024-05-27 12:34:00,386:INFO:Declaring metric variables
2024-05-27 12:34:00,393:INFO:Importing untrained model
2024-05-27 12:34:00,398:INFO:Decision Tree Regressor Imported successfully
2024-05-27 12:34:00,437:INFO:Starting cross validation
2024-05-27 12:34:00,439:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:34:01,853:INFO:Calculating mean and std
2024-05-27 12:34:01,858:INFO:Creating metrics dataframe
2024-05-27 12:34:01,864:INFO:Uploading results into container
2024-05-27 12:34:01,867:INFO:Uploading model into container now
2024-05-27 12:34:01,867:INFO:_master_model_container: 12
2024-05-27 12:34:01,869:INFO:_display_container: 2
2024-05-27 12:34:01,870:INFO:DecisionTreeRegressor(random_state=42)
2024-05-27 12:34:01,870:INFO:create_model() successfully completed......................................
2024-05-27 12:34:02,049:INFO:SubProcess create_model() end ==================================
2024-05-27 12:34:02,049:INFO:Creating metrics dataframe
2024-05-27 12:34:02,066:INFO:Initializing Random Forest Regressor
2024-05-27 12:34:02,066:INFO:Total runtime is 0.30785747766494753 minutes
2024-05-27 12:34:02,072:INFO:SubProcess create_model() called ==================================
2024-05-27 12:34:02,072:INFO:Initializing create_model()
2024-05-27 12:34:02,072:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B12A8CC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:34:02,072:INFO:Checking exceptions
2024-05-27 12:34:02,073:INFO:Importing libraries
2024-05-27 12:34:02,073:INFO:Copying training dataset
2024-05-27 12:34:02,081:INFO:Defining folds
2024-05-27 12:34:02,082:INFO:Declaring metric variables
2024-05-27 12:34:02,087:INFO:Importing untrained model
2024-05-27 12:34:02,092:INFO:Random Forest Regressor Imported successfully
2024-05-27 12:34:02,101:INFO:Starting cross validation
2024-05-27 12:34:02,103:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:34:05,517:INFO:Calculating mean and std
2024-05-27 12:34:05,519:INFO:Creating metrics dataframe
2024-05-27 12:34:05,522:INFO:Uploading results into container
2024-05-27 12:34:05,522:INFO:Uploading model into container now
2024-05-27 12:34:05,523:INFO:_master_model_container: 13
2024-05-27 12:34:05,523:INFO:_display_container: 2
2024-05-27 12:34:05,524:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:34:05,524:INFO:create_model() successfully completed......................................
2024-05-27 12:34:05,640:INFO:SubProcess create_model() end ==================================
2024-05-27 12:34:05,641:INFO:Creating metrics dataframe
2024-05-27 12:34:05,665:INFO:Initializing Extra Trees Regressor
2024-05-27 12:34:05,665:INFO:Total runtime is 0.3678491592407227 minutes
2024-05-27 12:34:05,671:INFO:SubProcess create_model() called ==================================
2024-05-27 12:34:05,671:INFO:Initializing create_model()
2024-05-27 12:34:05,671:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B12A8CC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:34:05,671:INFO:Checking exceptions
2024-05-27 12:34:05,671:INFO:Importing libraries
2024-05-27 12:34:05,671:INFO:Copying training dataset
2024-05-27 12:34:05,684:INFO:Defining folds
2024-05-27 12:34:05,685:INFO:Declaring metric variables
2024-05-27 12:34:05,691:INFO:Importing untrained model
2024-05-27 12:34:05,698:INFO:Extra Trees Regressor Imported successfully
2024-05-27 12:34:05,711:INFO:Starting cross validation
2024-05-27 12:34:05,712:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:34:08,478:INFO:Calculating mean and std
2024-05-27 12:34:08,480:INFO:Creating metrics dataframe
2024-05-27 12:34:08,483:INFO:Uploading results into container
2024-05-27 12:34:08,484:INFO:Uploading model into container now
2024-05-27 12:34:08,484:INFO:_master_model_container: 14
2024-05-27 12:34:08,485:INFO:_display_container: 2
2024-05-27 12:34:08,485:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:34:08,485:INFO:create_model() successfully completed......................................
2024-05-27 12:34:08,599:INFO:SubProcess create_model() end ==================================
2024-05-27 12:34:08,600:INFO:Creating metrics dataframe
2024-05-27 12:34:08,619:INFO:Initializing AdaBoost Regressor
2024-05-27 12:34:08,620:INFO:Total runtime is 0.4170889655749004 minutes
2024-05-27 12:34:08,626:INFO:SubProcess create_model() called ==================================
2024-05-27 12:34:08,626:INFO:Initializing create_model()
2024-05-27 12:34:08,627:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B12A8CC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:34:08,627:INFO:Checking exceptions
2024-05-27 12:34:08,627:INFO:Importing libraries
2024-05-27 12:34:08,627:INFO:Copying training dataset
2024-05-27 12:34:08,640:INFO:Defining folds
2024-05-27 12:34:08,641:INFO:Declaring metric variables
2024-05-27 12:34:08,646:INFO:Importing untrained model
2024-05-27 12:34:08,650:INFO:AdaBoost Regressor Imported successfully
2024-05-27 12:34:08,660:INFO:Starting cross validation
2024-05-27 12:34:08,661:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:34:10,407:INFO:Calculating mean and std
2024-05-27 12:34:10,408:INFO:Creating metrics dataframe
2024-05-27 12:34:10,411:INFO:Uploading results into container
2024-05-27 12:34:10,413:INFO:Uploading model into container now
2024-05-27 12:34:10,414:INFO:_master_model_container: 15
2024-05-27 12:34:10,415:INFO:_display_container: 2
2024-05-27 12:34:10,415:INFO:AdaBoostRegressor(random_state=42)
2024-05-27 12:34:10,415:INFO:create_model() successfully completed......................................
2024-05-27 12:34:10,549:INFO:SubProcess create_model() end ==================================
2024-05-27 12:34:10,549:INFO:Creating metrics dataframe
2024-05-27 12:34:10,574:INFO:Initializing Gradient Boosting Regressor
2024-05-27 12:34:10,574:INFO:Total runtime is 0.4496668020884197 minutes
2024-05-27 12:34:10,586:INFO:SubProcess create_model() called ==================================
2024-05-27 12:34:10,587:INFO:Initializing create_model()
2024-05-27 12:34:10,587:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B12A8CC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:34:10,587:INFO:Checking exceptions
2024-05-27 12:34:10,587:INFO:Importing libraries
2024-05-27 12:34:10,587:INFO:Copying training dataset
2024-05-27 12:34:10,600:INFO:Defining folds
2024-05-27 12:34:10,600:INFO:Declaring metric variables
2024-05-27 12:34:10,606:INFO:Importing untrained model
2024-05-27 12:34:10,618:INFO:Gradient Boosting Regressor Imported successfully
2024-05-27 12:34:10,637:INFO:Starting cross validation
2024-05-27 12:34:10,640:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:34:12,728:INFO:Calculating mean and std
2024-05-27 12:34:12,730:INFO:Creating metrics dataframe
2024-05-27 12:34:12,733:INFO:Uploading results into container
2024-05-27 12:34:12,734:INFO:Uploading model into container now
2024-05-27 12:34:12,735:INFO:_master_model_container: 16
2024-05-27 12:34:12,735:INFO:_display_container: 2
2024-05-27 12:34:12,736:INFO:GradientBoostingRegressor(random_state=42)
2024-05-27 12:34:12,736:INFO:create_model() successfully completed......................................
2024-05-27 12:34:12,850:INFO:SubProcess create_model() end ==================================
2024-05-27 12:34:12,850:INFO:Creating metrics dataframe
2024-05-27 12:34:12,869:INFO:Initializing Light Gradient Boosting Machine
2024-05-27 12:34:12,869:INFO:Total runtime is 0.487919851144155 minutes
2024-05-27 12:34:12,875:INFO:SubProcess create_model() called ==================================
2024-05-27 12:34:12,875:INFO:Initializing create_model()
2024-05-27 12:34:12,875:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B12A8CC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:34:12,876:INFO:Checking exceptions
2024-05-27 12:34:12,876:INFO:Importing libraries
2024-05-27 12:34:12,876:INFO:Copying training dataset
2024-05-27 12:34:12,886:INFO:Defining folds
2024-05-27 12:34:12,887:INFO:Declaring metric variables
2024-05-27 12:34:12,892:INFO:Importing untrained model
2024-05-27 12:34:12,898:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 12:34:12,911:INFO:Starting cross validation
2024-05-27 12:34:12,913:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:34:15,621:INFO:Calculating mean and std
2024-05-27 12:34:15,624:INFO:Creating metrics dataframe
2024-05-27 12:34:15,628:INFO:Uploading results into container
2024-05-27 12:34:15,629:INFO:Uploading model into container now
2024-05-27 12:34:15,630:INFO:_master_model_container: 17
2024-05-27 12:34:15,630:INFO:_display_container: 2
2024-05-27 12:34:15,631:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:34:15,632:INFO:create_model() successfully completed......................................
2024-05-27 12:34:15,766:INFO:SubProcess create_model() end ==================================
2024-05-27 12:34:15,766:INFO:Creating metrics dataframe
2024-05-27 12:34:15,785:INFO:Initializing Dummy Regressor
2024-05-27 12:34:15,785:INFO:Total runtime is 0.5365172028541566 minutes
2024-05-27 12:34:15,790:INFO:SubProcess create_model() called ==================================
2024-05-27 12:34:15,791:INFO:Initializing create_model()
2024-05-27 12:34:15,791:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B12A8CC3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:34:15,791:INFO:Checking exceptions
2024-05-27 12:34:15,791:INFO:Importing libraries
2024-05-27 12:34:15,792:INFO:Copying training dataset
2024-05-27 12:34:15,802:INFO:Defining folds
2024-05-27 12:34:15,802:INFO:Declaring metric variables
2024-05-27 12:34:15,807:INFO:Importing untrained model
2024-05-27 12:34:15,812:INFO:Dummy Regressor Imported successfully
2024-05-27 12:34:15,822:INFO:Starting cross validation
2024-05-27 12:34:15,825:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:34:16,666:INFO:Calculating mean and std
2024-05-27 12:34:16,667:INFO:Creating metrics dataframe
2024-05-27 12:34:16,669:INFO:Uploading results into container
2024-05-27 12:34:16,670:INFO:Uploading model into container now
2024-05-27 12:34:16,670:INFO:_master_model_container: 18
2024-05-27 12:34:16,671:INFO:_display_container: 2
2024-05-27 12:34:16,671:INFO:DummyRegressor()
2024-05-27 12:34:16,671:INFO:create_model() successfully completed......................................
2024-05-27 12:34:16,784:INFO:SubProcess create_model() end ==================================
2024-05-27 12:34:16,784:INFO:Creating metrics dataframe
2024-05-27 12:34:16,818:INFO:Initializing create_model()
2024-05-27 12:34:16,818:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:34:16,818:INFO:Checking exceptions
2024-05-27 12:34:16,821:INFO:Importing libraries
2024-05-27 12:34:16,821:INFO:Copying training dataset
2024-05-27 12:34:16,827:INFO:Defining folds
2024-05-27 12:34:16,827:INFO:Declaring metric variables
2024-05-27 12:34:16,827:INFO:Importing untrained model
2024-05-27 12:34:16,827:INFO:Declaring custom model
2024-05-27 12:34:16,828:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 12:34:16,829:INFO:Cross validation set to False
2024-05-27 12:34:16,829:INFO:Fitting Model
2024-05-27 12:34:17,055:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000456 seconds.
2024-05-27 12:34:17,055:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-27 12:34:17,056:INFO:[LightGBM] [Info] Total Bins 1660
2024-05-27 12:34:17,056:INFO:[LightGBM] [Info] Number of data points in the train set: 910, number of used features: 15
2024-05-27 12:34:17,056:INFO:[LightGBM] [Info] Start training from score -0.029448
2024-05-27 12:34:17,145:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:34:17,145:INFO:create_model() successfully completed......................................
2024-05-27 12:34:17,335:INFO:_master_model_container: 18
2024-05-27 12:34:17,336:INFO:_display_container: 2
2024-05-27 12:34:17,336:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:34:17,336:INFO:compare_models() successfully completed......................................
2024-05-27 12:34:17,390:INFO:Initializing plot_model()
2024-05-27 12:34:17,391:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:34:17,391:INFO:Checking exceptions
2024-05-27 12:34:17,403:INFO:Preloading libraries
2024-05-27 12:34:17,417:INFO:Copying training dataset
2024-05-27 12:34:17,417:INFO:Plot type: feature
2024-05-27 12:34:17,419:WARNING:No coef_ found. Trying feature_importances_
2024-05-27 12:34:17,699:INFO:Visual Rendered Successfully
2024-05-27 12:34:17,807:INFO:plot_model() successfully completed......................................
2024-05-27 12:34:17,808:INFO:Initializing plot_model()
2024-05-27 12:34:17,808:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=error, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:34:17,808:INFO:Checking exceptions
2024-05-27 12:34:17,816:INFO:Preloading libraries
2024-05-27 12:34:17,828:INFO:Copying training dataset
2024-05-27 12:34:17,828:INFO:Plot type: error
2024-05-27 12:34:18,050:INFO:Fitting Model
2024-05-27 12:34:18,050:INFO:Scoring test/hold-out set
2024-05-27 12:34:18,557:INFO:Visual Rendered Successfully
2024-05-27 12:34:18,669:INFO:plot_model() successfully completed......................................
2024-05-27 12:34:18,670:INFO:Initializing plot_model()
2024-05-27 12:34:18,670:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=residuals, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:34:18,670:INFO:Checking exceptions
2024-05-27 12:34:18,678:INFO:Preloading libraries
2024-05-27 12:34:18,691:INFO:Copying training dataset
2024-05-27 12:34:18,691:INFO:Plot type: residuals
2024-05-27 12:34:18,910:INFO:Fitting Model
2024-05-27 12:34:18,989:INFO:Scoring test/hold-out set
2024-05-27 12:34:19,504:INFO:Visual Rendered Successfully
2024-05-27 12:34:19,627:INFO:plot_model() successfully completed......................................
2024-05-27 12:34:19,691:INFO:Initializing evaluate_model()
2024-05-27 12:34:19,691:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-27 12:34:19,752:INFO:Initializing plot_model()
2024-05-27 12:34:19,752:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-27 12:34:19,754:INFO:Checking exceptions
2024-05-27 12:34:19,759:INFO:Preloading libraries
2024-05-27 12:34:19,776:INFO:Copying training dataset
2024-05-27 12:34:19,776:INFO:Plot type: pipeline
2024-05-27 12:34:20,116:INFO:Visual Rendered Successfully
2024-05-27 12:34:20,224:INFO:plot_model() successfully completed......................................
2024-05-27 12:34:20,250:INFO:Initializing tune_model()
2024-05-27 12:34:20,250:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-05-27 12:34:20,251:INFO:Checking exceptions
2024-05-27 12:34:20,279:INFO:Copying training dataset
2024-05-27 12:34:20,287:INFO:Checking base model
2024-05-27 12:34:20,288:INFO:Base model : Light Gradient Boosting Machine
2024-05-27 12:34:20,297:INFO:Declaring metric variables
2024-05-27 12:34:20,305:INFO:Defining Hyperparameters
2024-05-27 12:34:20,445:INFO:Tuning with n_jobs=-1
2024-05-27 12:34:20,445:INFO:Initializing RandomizedSearchCV
2024-05-27 12:34:37,412:INFO:best_params: {'actual_estimator__reg_lambda': 5, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 100, 'actual_estimator__min_split_gain': 0.6, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.8}
2024-05-27 12:34:37,414:INFO:Hyperparameter search completed
2024-05-27 12:34:37,414:INFO:SubProcess create_model() called ==================================
2024-05-27 12:34:37,416:INFO:Initializing create_model()
2024-05-27 12:34:37,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11A337A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 5, 'reg_alpha': 0.001, 'num_leaves': 30, 'n_estimators': 100, 'min_split_gain': 0.6, 'min_child_samples': 6, 'learning_rate': 0.2, 'feature_fraction': 0.8, 'bagging_freq': 3, 'bagging_fraction': 0.8})
2024-05-27 12:34:37,416:INFO:Checking exceptions
2024-05-27 12:34:37,417:INFO:Importing libraries
2024-05-27 12:34:37,417:INFO:Copying training dataset
2024-05-27 12:34:37,432:INFO:Defining folds
2024-05-27 12:34:37,432:INFO:Declaring metric variables
2024-05-27 12:34:37,440:INFO:Importing untrained model
2024-05-27 12:34:37,440:INFO:Declaring custom model
2024-05-27 12:34:37,450:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 12:34:37,465:INFO:Starting cross validation
2024-05-27 12:34:37,468:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:34:39,203:INFO:Calculating mean and std
2024-05-27 12:34:39,205:INFO:Creating metrics dataframe
2024-05-27 12:34:39,216:INFO:Finalizing model
2024-05-27 12:34:39,502:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-05-27 12:34:39,502:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-05-27 12:34:39,502:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-05-27 12:34:39,504:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-05-27 12:34:39,504:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-05-27 12:34:39,504:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-05-27 12:34:39,505:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000477 seconds.
2024-05-27 12:34:39,505:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-27 12:34:39,506:INFO:[LightGBM] [Info] Total Bins 1660
2024-05-27 12:34:39,506:INFO:[LightGBM] [Info] Number of data points in the train set: 910, number of used features: 15
2024-05-27 12:34:39,506:INFO:[LightGBM] [Info] Start training from score -0.029448
2024-05-27 12:34:39,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,524:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,528:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,529:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,530:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,530:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,530:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,531:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,531:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,531:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,532:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,532:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,532:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,533:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,533:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,533:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,534:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,534:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,534:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,535:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,535:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,538:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,538:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,538:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,539:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,539:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,539:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,540:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,540:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,540:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,541:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,541:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,542:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,542:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,542:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,543:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,543:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,544:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,544:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,544:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,545:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,545:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,545:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,546:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,546:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,547:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,547:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,548:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,548:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,548:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,549:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,549:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,549:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,550:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,550:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,550:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,551:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,551:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,551:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,552:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,552:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,553:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:34:39,553:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:34:39,612:INFO:Uploading results into container
2024-05-27 12:34:39,614:INFO:Uploading model into container now
2024-05-27 12:34:39,617:INFO:_master_model_container: 19
2024-05-27 12:34:39,617:INFO:_display_container: 3
2024-05-27 12:34:39,618:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=3, feature_fraction=0.8,
              learning_rate=0.2, min_child_samples=6, min_split_gain=0.6,
              n_jobs=-1, num_leaves=30, random_state=42, reg_alpha=0.001,
              reg_lambda=5)
2024-05-27 12:34:39,619:INFO:create_model() successfully completed......................................
2024-05-27 12:34:39,765:INFO:SubProcess create_model() end ==================================
2024-05-27 12:34:39,765:INFO:choose_better activated
2024-05-27 12:34:39,771:INFO:SubProcess create_model() called ==================================
2024-05-27 12:34:39,772:INFO:Initializing create_model()
2024-05-27 12:34:39,772:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:34:39,772:INFO:Checking exceptions
2024-05-27 12:34:39,775:INFO:Importing libraries
2024-05-27 12:34:39,775:INFO:Copying training dataset
2024-05-27 12:34:39,786:INFO:Defining folds
2024-05-27 12:34:39,786:INFO:Declaring metric variables
2024-05-27 12:34:39,787:INFO:Importing untrained model
2024-05-27 12:34:39,787:INFO:Declaring custom model
2024-05-27 12:34:39,788:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 12:34:39,788:INFO:Starting cross validation
2024-05-27 12:34:39,789:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:34:42,276:INFO:Calculating mean and std
2024-05-27 12:34:42,277:INFO:Creating metrics dataframe
2024-05-27 12:34:42,281:INFO:Finalizing model
2024-05-27 12:34:42,566:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000332 seconds.
2024-05-27 12:34:42,566:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-27 12:34:42,566:INFO:[LightGBM] [Info] Total Bins 1660
2024-05-27 12:34:42,566:INFO:[LightGBM] [Info] Number of data points in the train set: 910, number of used features: 15
2024-05-27 12:34:42,567:INFO:[LightGBM] [Info] Start training from score -0.029448
2024-05-27 12:34:42,671:INFO:Uploading results into container
2024-05-27 12:34:42,673:INFO:Uploading model into container now
2024-05-27 12:34:42,673:INFO:_master_model_container: 20
2024-05-27 12:34:42,674:INFO:_display_container: 4
2024-05-27 12:34:42,674:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:34:42,674:INFO:create_model() successfully completed......................................
2024-05-27 12:34:42,812:INFO:SubProcess create_model() end ==================================
2024-05-27 12:34:42,813:INFO:LGBMRegressor(n_jobs=-1, random_state=42) result for R2 is 0.8022
2024-05-27 12:34:42,814:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=3, feature_fraction=0.8,
              learning_rate=0.2, min_child_samples=6, min_split_gain=0.6,
              n_jobs=-1, num_leaves=30, random_state=42, reg_alpha=0.001,
              reg_lambda=5) result for R2 is 0.7718
2024-05-27 12:34:42,815:INFO:LGBMRegressor(n_jobs=-1, random_state=42) is best model
2024-05-27 12:34:42,815:INFO:choose_better completed
2024-05-27 12:34:42,815:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-27 12:34:42,836:INFO:_master_model_container: 20
2024-05-27 12:34:42,836:INFO:_display_container: 3
2024-05-27 12:34:42,837:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:34:42,837:INFO:tune_model() successfully completed......................................
2024-05-27 12:34:43,069:INFO:Initializing plot_model()
2024-05-27 12:34:43,069:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:34:43,069:INFO:Checking exceptions
2024-05-27 12:34:43,078:INFO:Preloading libraries
2024-05-27 12:34:43,090:INFO:Copying training dataset
2024-05-27 12:34:43,090:INFO:Plot type: feature
2024-05-27 12:34:43,091:WARNING:No coef_ found. Trying feature_importances_
2024-05-27 12:34:43,362:INFO:Visual Rendered Successfully
2024-05-27 12:34:43,474:INFO:plot_model() successfully completed......................................
2024-05-27 12:34:43,475:INFO:Initializing plot_model()
2024-05-27 12:34:43,476:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=error, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:34:43,476:INFO:Checking exceptions
2024-05-27 12:34:43,486:INFO:Preloading libraries
2024-05-27 12:34:43,498:INFO:Copying training dataset
2024-05-27 12:34:43,499:INFO:Plot type: error
2024-05-27 12:34:43,725:INFO:Fitting Model
2024-05-27 12:34:43,726:INFO:Scoring test/hold-out set
2024-05-27 12:34:44,076:INFO:Visual Rendered Successfully
2024-05-27 12:34:44,196:INFO:plot_model() successfully completed......................................
2024-05-27 12:34:44,198:INFO:Initializing plot_model()
2024-05-27 12:34:44,199:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=residuals, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:34:44,199:INFO:Checking exceptions
2024-05-27 12:34:44,207:INFO:Preloading libraries
2024-05-27 12:34:44,219:INFO:Copying training dataset
2024-05-27 12:34:44,219:INFO:Plot type: residuals
2024-05-27 12:34:44,428:INFO:Fitting Model
2024-05-27 12:34:44,512:INFO:Scoring test/hold-out set
2024-05-27 12:34:45,009:INFO:Visual Rendered Successfully
2024-05-27 12:34:45,134:INFO:plot_model() successfully completed......................................
2024-05-27 12:34:45,168:INFO:Initializing evaluate_model()
2024-05-27 12:34:45,168:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-27 12:34:45,182:INFO:Initializing plot_model()
2024-05-27 12:34:45,182:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-27 12:34:45,183:INFO:Checking exceptions
2024-05-27 12:34:45,187:INFO:Preloading libraries
2024-05-27 12:34:45,197:INFO:Copying training dataset
2024-05-27 12:34:45,197:INFO:Plot type: pipeline
2024-05-27 12:34:45,479:INFO:Visual Rendered Successfully
2024-05-27 12:34:45,596:INFO:plot_model() successfully completed......................................
2024-05-27 12:36:45,842:INFO:Initializing compare_models()
2024-05-27 12:36:45,842:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-05-27 12:36:45,843:INFO:Checking exceptions
2024-05-27 12:36:45,847:INFO:Preparing display monitor
2024-05-27 12:36:45,888:INFO:Initializing Linear Regression
2024-05-27 12:36:45,888:INFO:Total runtime is 0.0 minutes
2024-05-27 12:36:45,892:INFO:SubProcess create_model() called ==================================
2024-05-27 12:36:45,893:INFO:Initializing create_model()
2024-05-27 12:36:45,893:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11701A710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:36:45,894:INFO:Checking exceptions
2024-05-27 12:36:45,894:INFO:Importing libraries
2024-05-27 12:36:45,894:INFO:Copying training dataset
2024-05-27 12:36:45,904:INFO:Defining folds
2024-05-27 12:36:45,904:INFO:Declaring metric variables
2024-05-27 12:36:45,907:INFO:Importing untrained model
2024-05-27 12:36:45,913:INFO:Linear Regression Imported successfully
2024-05-27 12:36:45,923:INFO:Starting cross validation
2024-05-27 12:36:45,926:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:36:46,705:INFO:Calculating mean and std
2024-05-27 12:36:46,705:INFO:Creating metrics dataframe
2024-05-27 12:36:46,707:INFO:Uploading results into container
2024-05-27 12:36:46,707:INFO:Uploading model into container now
2024-05-27 12:36:46,707:INFO:_master_model_container: 21
2024-05-27 12:36:46,707:INFO:_display_container: 1
2024-05-27 12:36:46,708:INFO:LinearRegression(n_jobs=-1)
2024-05-27 12:36:46,708:INFO:create_model() successfully completed......................................
2024-05-27 12:36:46,887:INFO:SubProcess create_model() end ==================================
2024-05-27 12:36:46,887:INFO:Creating metrics dataframe
2024-05-27 12:36:46,899:INFO:Initializing Lasso Regression
2024-05-27 12:36:46,899:INFO:Total runtime is 0.016856805483500163 minutes
2024-05-27 12:36:46,906:INFO:SubProcess create_model() called ==================================
2024-05-27 12:36:46,907:INFO:Initializing create_model()
2024-05-27 12:36:46,907:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11701A710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:36:46,907:INFO:Checking exceptions
2024-05-27 12:36:46,907:INFO:Importing libraries
2024-05-27 12:36:46,908:INFO:Copying training dataset
2024-05-27 12:36:46,918:INFO:Defining folds
2024-05-27 12:36:46,918:INFO:Declaring metric variables
2024-05-27 12:36:46,925:INFO:Importing untrained model
2024-05-27 12:36:46,932:INFO:Lasso Regression Imported successfully
2024-05-27 12:36:46,942:INFO:Starting cross validation
2024-05-27 12:36:46,943:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:36:47,548:INFO:Calculating mean and std
2024-05-27 12:36:47,549:INFO:Creating metrics dataframe
2024-05-27 12:36:47,551:INFO:Uploading results into container
2024-05-27 12:36:47,552:INFO:Uploading model into container now
2024-05-27 12:36:47,553:INFO:_master_model_container: 22
2024-05-27 12:36:47,554:INFO:_display_container: 1
2024-05-27 12:36:47,554:INFO:Lasso(random_state=42)
2024-05-27 12:36:47,555:INFO:create_model() successfully completed......................................
2024-05-27 12:36:47,737:INFO:SubProcess create_model() end ==================================
2024-05-27 12:36:47,737:INFO:Creating metrics dataframe
2024-05-27 12:36:47,749:INFO:Initializing Ridge Regression
2024-05-27 12:36:47,749:INFO:Total runtime is 0.031014088789621988 minutes
2024-05-27 12:36:47,755:INFO:SubProcess create_model() called ==================================
2024-05-27 12:36:47,755:INFO:Initializing create_model()
2024-05-27 12:36:47,755:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11701A710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:36:47,755:INFO:Checking exceptions
2024-05-27 12:36:47,756:INFO:Importing libraries
2024-05-27 12:36:47,756:INFO:Copying training dataset
2024-05-27 12:36:47,765:INFO:Defining folds
2024-05-27 12:36:47,765:INFO:Declaring metric variables
2024-05-27 12:36:47,771:INFO:Importing untrained model
2024-05-27 12:36:47,778:INFO:Ridge Regression Imported successfully
2024-05-27 12:36:47,788:INFO:Starting cross validation
2024-05-27 12:36:47,790:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:36:48,353:INFO:Calculating mean and std
2024-05-27 12:36:48,354:INFO:Creating metrics dataframe
2024-05-27 12:36:48,356:INFO:Uploading results into container
2024-05-27 12:36:48,356:INFO:Uploading model into container now
2024-05-27 12:36:48,356:INFO:_master_model_container: 23
2024-05-27 12:36:48,356:INFO:_display_container: 1
2024-05-27 12:36:48,357:INFO:Ridge(random_state=42)
2024-05-27 12:36:48,357:INFO:create_model() successfully completed......................................
2024-05-27 12:36:48,527:INFO:SubProcess create_model() end ==================================
2024-05-27 12:36:48,527:INFO:Creating metrics dataframe
2024-05-27 12:36:48,542:INFO:Initializing Elastic Net
2024-05-27 12:36:48,542:INFO:Total runtime is 0.04422684510548909 minutes
2024-05-27 12:36:48,548:INFO:SubProcess create_model() called ==================================
2024-05-27 12:36:48,548:INFO:Initializing create_model()
2024-05-27 12:36:48,548:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11701A710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:36:48,548:INFO:Checking exceptions
2024-05-27 12:36:48,549:INFO:Importing libraries
2024-05-27 12:36:48,549:INFO:Copying training dataset
2024-05-27 12:36:48,560:INFO:Defining folds
2024-05-27 12:36:48,560:INFO:Declaring metric variables
2024-05-27 12:36:48,565:INFO:Importing untrained model
2024-05-27 12:36:48,573:INFO:Elastic Net Imported successfully
2024-05-27 12:36:48,581:INFO:Starting cross validation
2024-05-27 12:36:48,583:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:36:49,147:INFO:Calculating mean and std
2024-05-27 12:36:49,149:INFO:Creating metrics dataframe
2024-05-27 12:36:49,151:INFO:Uploading results into container
2024-05-27 12:36:49,152:INFO:Uploading model into container now
2024-05-27 12:36:49,152:INFO:_master_model_container: 24
2024-05-27 12:36:49,153:INFO:_display_container: 1
2024-05-27 12:36:49,153:INFO:ElasticNet(random_state=42)
2024-05-27 12:36:49,153:INFO:create_model() successfully completed......................................
2024-05-27 12:36:49,322:INFO:SubProcess create_model() end ==================================
2024-05-27 12:36:49,323:INFO:Creating metrics dataframe
2024-05-27 12:36:49,341:INFO:Initializing Least Angle Regression
2024-05-27 12:36:49,341:INFO:Total runtime is 0.05755362113316853 minutes
2024-05-27 12:36:49,347:INFO:SubProcess create_model() called ==================================
2024-05-27 12:36:49,348:INFO:Initializing create_model()
2024-05-27 12:36:49,348:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11701A710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:36:49,348:INFO:Checking exceptions
2024-05-27 12:36:49,348:INFO:Importing libraries
2024-05-27 12:36:49,348:INFO:Copying training dataset
2024-05-27 12:36:49,357:INFO:Defining folds
2024-05-27 12:36:49,358:INFO:Declaring metric variables
2024-05-27 12:36:49,363:INFO:Importing untrained model
2024-05-27 12:36:49,368:INFO:Least Angle Regression Imported successfully
2024-05-27 12:36:49,377:INFO:Starting cross validation
2024-05-27 12:36:49,378:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:36:49,960:INFO:Calculating mean and std
2024-05-27 12:36:49,961:INFO:Creating metrics dataframe
2024-05-27 12:36:49,964:INFO:Uploading results into container
2024-05-27 12:36:49,964:INFO:Uploading model into container now
2024-05-27 12:36:49,965:INFO:_master_model_container: 25
2024-05-27 12:36:49,965:INFO:_display_container: 1
2024-05-27 12:36:49,966:INFO:Lars(random_state=42)
2024-05-27 12:36:49,966:INFO:create_model() successfully completed......................................
2024-05-27 12:36:50,139:INFO:SubProcess create_model() end ==================================
2024-05-27 12:36:50,139:INFO:Creating metrics dataframe
2024-05-27 12:36:50,154:INFO:Initializing Lasso Least Angle Regression
2024-05-27 12:36:50,154:INFO:Total runtime is 0.07109843492507933 minutes
2024-05-27 12:36:50,159:INFO:SubProcess create_model() called ==================================
2024-05-27 12:36:50,160:INFO:Initializing create_model()
2024-05-27 12:36:50,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11701A710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:36:50,161:INFO:Checking exceptions
2024-05-27 12:36:50,161:INFO:Importing libraries
2024-05-27 12:36:50,161:INFO:Copying training dataset
2024-05-27 12:36:50,172:INFO:Defining folds
2024-05-27 12:36:50,173:INFO:Declaring metric variables
2024-05-27 12:36:50,179:INFO:Importing untrained model
2024-05-27 12:36:50,184:INFO:Lasso Least Angle Regression Imported successfully
2024-05-27 12:36:50,192:INFO:Starting cross validation
2024-05-27 12:36:50,193:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:36:50,769:INFO:Calculating mean and std
2024-05-27 12:36:50,770:INFO:Creating metrics dataframe
2024-05-27 12:36:50,773:INFO:Uploading results into container
2024-05-27 12:36:50,774:INFO:Uploading model into container now
2024-05-27 12:36:50,774:INFO:_master_model_container: 26
2024-05-27 12:36:50,774:INFO:_display_container: 1
2024-05-27 12:36:50,775:INFO:LassoLars(random_state=42)
2024-05-27 12:36:50,775:INFO:create_model() successfully completed......................................
2024-05-27 12:36:50,946:INFO:SubProcess create_model() end ==================================
2024-05-27 12:36:50,946:INFO:Creating metrics dataframe
2024-05-27 12:36:50,966:INFO:Initializing Orthogonal Matching Pursuit
2024-05-27 12:36:50,967:INFO:Total runtime is 0.08463028271993 minutes
2024-05-27 12:36:50,973:INFO:SubProcess create_model() called ==================================
2024-05-27 12:36:50,973:INFO:Initializing create_model()
2024-05-27 12:36:50,973:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11701A710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:36:50,973:INFO:Checking exceptions
2024-05-27 12:36:50,973:INFO:Importing libraries
2024-05-27 12:36:50,974:INFO:Copying training dataset
2024-05-27 12:36:50,984:INFO:Defining folds
2024-05-27 12:36:50,984:INFO:Declaring metric variables
2024-05-27 12:36:50,991:INFO:Importing untrained model
2024-05-27 12:36:50,996:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-27 12:36:51,006:INFO:Starting cross validation
2024-05-27 12:36:51,008:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:36:51,570:INFO:Calculating mean and std
2024-05-27 12:36:51,571:INFO:Creating metrics dataframe
2024-05-27 12:36:51,573:INFO:Uploading results into container
2024-05-27 12:36:51,574:INFO:Uploading model into container now
2024-05-27 12:36:51,574:INFO:_master_model_container: 27
2024-05-27 12:36:51,574:INFO:_display_container: 1
2024-05-27 12:36:51,574:INFO:OrthogonalMatchingPursuit()
2024-05-27 12:36:51,574:INFO:create_model() successfully completed......................................
2024-05-27 12:36:51,747:INFO:SubProcess create_model() end ==================================
2024-05-27 12:36:51,747:INFO:Creating metrics dataframe
2024-05-27 12:36:51,765:INFO:Initializing Bayesian Ridge
2024-05-27 12:36:51,766:INFO:Total runtime is 0.097969647248586 minutes
2024-05-27 12:36:51,774:INFO:SubProcess create_model() called ==================================
2024-05-27 12:36:51,774:INFO:Initializing create_model()
2024-05-27 12:36:51,774:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11701A710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:36:51,775:INFO:Checking exceptions
2024-05-27 12:36:51,775:INFO:Importing libraries
2024-05-27 12:36:51,775:INFO:Copying training dataset
2024-05-27 12:36:51,786:INFO:Defining folds
2024-05-27 12:36:51,786:INFO:Declaring metric variables
2024-05-27 12:36:51,792:INFO:Importing untrained model
2024-05-27 12:36:51,796:INFO:Bayesian Ridge Imported successfully
2024-05-27 12:36:51,805:INFO:Starting cross validation
2024-05-27 12:36:51,807:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:36:52,377:INFO:Calculating mean and std
2024-05-27 12:36:52,378:INFO:Creating metrics dataframe
2024-05-27 12:36:52,380:INFO:Uploading results into container
2024-05-27 12:36:52,380:INFO:Uploading model into container now
2024-05-27 12:36:52,381:INFO:_master_model_container: 28
2024-05-27 12:36:52,381:INFO:_display_container: 1
2024-05-27 12:36:52,381:INFO:BayesianRidge()
2024-05-27 12:36:52,381:INFO:create_model() successfully completed......................................
2024-05-27 12:36:52,552:INFO:SubProcess create_model() end ==================================
2024-05-27 12:36:52,552:INFO:Creating metrics dataframe
2024-05-27 12:36:52,571:INFO:Initializing Passive Aggressive Regressor
2024-05-27 12:36:52,571:INFO:Total runtime is 0.11137554248174031 minutes
2024-05-27 12:36:52,575:INFO:SubProcess create_model() called ==================================
2024-05-27 12:36:52,575:INFO:Initializing create_model()
2024-05-27 12:36:52,575:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11701A710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:36:52,576:INFO:Checking exceptions
2024-05-27 12:36:52,576:INFO:Importing libraries
2024-05-27 12:36:52,576:INFO:Copying training dataset
2024-05-27 12:36:52,586:INFO:Defining folds
2024-05-27 12:36:52,586:INFO:Declaring metric variables
2024-05-27 12:36:52,591:INFO:Importing untrained model
2024-05-27 12:36:52,596:INFO:Passive Aggressive Regressor Imported successfully
2024-05-27 12:36:52,608:INFO:Starting cross validation
2024-05-27 12:36:52,609:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:36:53,189:INFO:Calculating mean and std
2024-05-27 12:36:53,190:INFO:Creating metrics dataframe
2024-05-27 12:36:53,192:INFO:Uploading results into container
2024-05-27 12:36:53,192:INFO:Uploading model into container now
2024-05-27 12:36:53,193:INFO:_master_model_container: 29
2024-05-27 12:36:53,193:INFO:_display_container: 1
2024-05-27 12:36:53,193:INFO:PassiveAggressiveRegressor(random_state=42)
2024-05-27 12:36:53,193:INFO:create_model() successfully completed......................................
2024-05-27 12:36:53,361:INFO:SubProcess create_model() end ==================================
2024-05-27 12:36:53,362:INFO:Creating metrics dataframe
2024-05-27 12:36:53,380:INFO:Initializing Huber Regressor
2024-05-27 12:36:53,380:INFO:Total runtime is 0.12486807902654011 minutes
2024-05-27 12:36:53,387:INFO:SubProcess create_model() called ==================================
2024-05-27 12:36:53,388:INFO:Initializing create_model()
2024-05-27 12:36:53,388:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11701A710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:36:53,389:INFO:Checking exceptions
2024-05-27 12:36:53,389:INFO:Importing libraries
2024-05-27 12:36:53,389:INFO:Copying training dataset
2024-05-27 12:36:53,397:INFO:Defining folds
2024-05-27 12:36:53,398:INFO:Declaring metric variables
2024-05-27 12:36:53,404:INFO:Importing untrained model
2024-05-27 12:36:53,410:INFO:Huber Regressor Imported successfully
2024-05-27 12:36:53,419:INFO:Starting cross validation
2024-05-27 12:36:53,421:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:36:54,195:INFO:Calculating mean and std
2024-05-27 12:36:54,196:INFO:Creating metrics dataframe
2024-05-27 12:36:54,198:INFO:Uploading results into container
2024-05-27 12:36:54,198:INFO:Uploading model into container now
2024-05-27 12:36:54,198:INFO:_master_model_container: 30
2024-05-27 12:36:54,198:INFO:_display_container: 1
2024-05-27 12:36:54,199:INFO:HuberRegressor()
2024-05-27 12:36:54,199:INFO:create_model() successfully completed......................................
2024-05-27 12:36:54,373:INFO:SubProcess create_model() end ==================================
2024-05-27 12:36:54,374:INFO:Creating metrics dataframe
2024-05-27 12:36:54,392:INFO:Initializing K Neighbors Regressor
2024-05-27 12:36:54,392:INFO:Total runtime is 0.1417383829752604 minutes
2024-05-27 12:36:54,398:INFO:SubProcess create_model() called ==================================
2024-05-27 12:36:54,398:INFO:Initializing create_model()
2024-05-27 12:36:54,398:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11701A710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:36:54,398:INFO:Checking exceptions
2024-05-27 12:36:54,399:INFO:Importing libraries
2024-05-27 12:36:54,399:INFO:Copying training dataset
2024-05-27 12:36:54,410:INFO:Defining folds
2024-05-27 12:36:54,410:INFO:Declaring metric variables
2024-05-27 12:36:54,417:INFO:Importing untrained model
2024-05-27 12:36:54,428:INFO:K Neighbors Regressor Imported successfully
2024-05-27 12:36:54,437:INFO:Starting cross validation
2024-05-27 12:36:54,439:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:36:55,043:INFO:Calculating mean and std
2024-05-27 12:36:55,044:INFO:Creating metrics dataframe
2024-05-27 12:36:55,045:INFO:Uploading results into container
2024-05-27 12:36:55,046:INFO:Uploading model into container now
2024-05-27 12:36:55,046:INFO:_master_model_container: 31
2024-05-27 12:36:55,046:INFO:_display_container: 1
2024-05-27 12:36:55,046:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-27 12:36:55,046:INFO:create_model() successfully completed......................................
2024-05-27 12:36:55,223:INFO:SubProcess create_model() end ==================================
2024-05-27 12:36:55,223:INFO:Creating metrics dataframe
2024-05-27 12:36:55,241:INFO:Initializing Decision Tree Regressor
2024-05-27 12:36:55,241:INFO:Total runtime is 0.1558786630630493 minutes
2024-05-27 12:36:55,247:INFO:SubProcess create_model() called ==================================
2024-05-27 12:36:55,248:INFO:Initializing create_model()
2024-05-27 12:36:55,248:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11701A710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:36:55,248:INFO:Checking exceptions
2024-05-27 12:36:55,248:INFO:Importing libraries
2024-05-27 12:36:55,248:INFO:Copying training dataset
2024-05-27 12:36:55,259:INFO:Defining folds
2024-05-27 12:36:55,259:INFO:Declaring metric variables
2024-05-27 12:36:55,263:INFO:Importing untrained model
2024-05-27 12:36:55,270:INFO:Decision Tree Regressor Imported successfully
2024-05-27 12:36:55,276:INFO:Starting cross validation
2024-05-27 12:36:55,277:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:36:55,894:INFO:Calculating mean and std
2024-05-27 12:36:55,895:INFO:Creating metrics dataframe
2024-05-27 12:36:55,896:INFO:Uploading results into container
2024-05-27 12:36:55,897:INFO:Uploading model into container now
2024-05-27 12:36:55,897:INFO:_master_model_container: 32
2024-05-27 12:36:55,897:INFO:_display_container: 1
2024-05-27 12:36:55,897:INFO:DecisionTreeRegressor(random_state=42)
2024-05-27 12:36:55,897:INFO:create_model() successfully completed......................................
2024-05-27 12:36:56,072:INFO:SubProcess create_model() end ==================================
2024-05-27 12:36:56,072:INFO:Creating metrics dataframe
2024-05-27 12:36:56,092:INFO:Initializing Random Forest Regressor
2024-05-27 12:36:56,093:INFO:Total runtime is 0.17009070316950478 minutes
2024-05-27 12:36:56,098:INFO:SubProcess create_model() called ==================================
2024-05-27 12:36:56,099:INFO:Initializing create_model()
2024-05-27 12:36:56,100:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11701A710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:36:56,100:INFO:Checking exceptions
2024-05-27 12:36:56,100:INFO:Importing libraries
2024-05-27 12:36:56,101:INFO:Copying training dataset
2024-05-27 12:36:56,112:INFO:Defining folds
2024-05-27 12:36:56,112:INFO:Declaring metric variables
2024-05-27 12:36:56,119:INFO:Importing untrained model
2024-05-27 12:36:56,125:INFO:Random Forest Regressor Imported successfully
2024-05-27 12:36:56,131:INFO:Starting cross validation
2024-05-27 12:36:56,133:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:36:58,737:INFO:Calculating mean and std
2024-05-27 12:36:58,738:INFO:Creating metrics dataframe
2024-05-27 12:36:58,740:INFO:Uploading results into container
2024-05-27 12:36:58,740:INFO:Uploading model into container now
2024-05-27 12:36:58,741:INFO:_master_model_container: 33
2024-05-27 12:36:58,741:INFO:_display_container: 1
2024-05-27 12:36:58,741:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:36:58,741:INFO:create_model() successfully completed......................................
2024-05-27 12:36:58,916:INFO:SubProcess create_model() end ==================================
2024-05-27 12:36:58,916:INFO:Creating metrics dataframe
2024-05-27 12:36:58,934:INFO:Initializing Extra Trees Regressor
2024-05-27 12:36:58,934:INFO:Total runtime is 0.21743804613749185 minutes
2024-05-27 12:36:58,940:INFO:SubProcess create_model() called ==================================
2024-05-27 12:36:58,941:INFO:Initializing create_model()
2024-05-27 12:36:58,941:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11701A710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:36:58,941:INFO:Checking exceptions
2024-05-27 12:36:58,942:INFO:Importing libraries
2024-05-27 12:36:58,942:INFO:Copying training dataset
2024-05-27 12:36:58,952:INFO:Defining folds
2024-05-27 12:36:58,952:INFO:Declaring metric variables
2024-05-27 12:36:58,960:INFO:Importing untrained model
2024-05-27 12:36:58,966:INFO:Extra Trees Regressor Imported successfully
2024-05-27 12:36:58,977:INFO:Starting cross validation
2024-05-27 12:36:58,978:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:37:00,922:INFO:Calculating mean and std
2024-05-27 12:37:00,923:INFO:Creating metrics dataframe
2024-05-27 12:37:00,925:INFO:Uploading results into container
2024-05-27 12:37:00,925:INFO:Uploading model into container now
2024-05-27 12:37:00,926:INFO:_master_model_container: 34
2024-05-27 12:37:00,926:INFO:_display_container: 1
2024-05-27 12:37:00,926:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:37:00,927:INFO:create_model() successfully completed......................................
2024-05-27 12:37:01,095:INFO:SubProcess create_model() end ==================================
2024-05-27 12:37:01,095:INFO:Creating metrics dataframe
2024-05-27 12:37:01,113:INFO:Initializing AdaBoost Regressor
2024-05-27 12:37:01,114:INFO:Total runtime is 0.2537686069806417 minutes
2024-05-27 12:37:01,119:INFO:SubProcess create_model() called ==================================
2024-05-27 12:37:01,121:INFO:Initializing create_model()
2024-05-27 12:37:01,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11701A710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:37:01,121:INFO:Checking exceptions
2024-05-27 12:37:01,122:INFO:Importing libraries
2024-05-27 12:37:01,122:INFO:Copying training dataset
2024-05-27 12:37:01,132:INFO:Defining folds
2024-05-27 12:37:01,132:INFO:Declaring metric variables
2024-05-27 12:37:01,139:INFO:Importing untrained model
2024-05-27 12:37:01,144:INFO:AdaBoost Regressor Imported successfully
2024-05-27 12:37:01,154:INFO:Starting cross validation
2024-05-27 12:37:01,157:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:37:02,182:INFO:Calculating mean and std
2024-05-27 12:37:02,183:INFO:Creating metrics dataframe
2024-05-27 12:37:02,185:INFO:Uploading results into container
2024-05-27 12:37:02,186:INFO:Uploading model into container now
2024-05-27 12:37:02,187:INFO:_master_model_container: 35
2024-05-27 12:37:02,187:INFO:_display_container: 1
2024-05-27 12:37:02,188:INFO:AdaBoostRegressor(random_state=42)
2024-05-27 12:37:02,188:INFO:create_model() successfully completed......................................
2024-05-27 12:37:02,442:INFO:SubProcess create_model() end ==================================
2024-05-27 12:37:02,443:INFO:Creating metrics dataframe
2024-05-27 12:37:02,541:INFO:Initializing Gradient Boosting Regressor
2024-05-27 12:37:02,542:INFO:Total runtime is 0.27756484349568683 minutes
2024-05-27 12:37:02,547:INFO:SubProcess create_model() called ==================================
2024-05-27 12:37:02,547:INFO:Initializing create_model()
2024-05-27 12:37:02,548:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11701A710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:37:02,548:INFO:Checking exceptions
2024-05-27 12:37:02,548:INFO:Importing libraries
2024-05-27 12:37:02,548:INFO:Copying training dataset
2024-05-27 12:37:02,570:INFO:Defining folds
2024-05-27 12:37:02,570:INFO:Declaring metric variables
2024-05-27 12:37:02,575:INFO:Importing untrained model
2024-05-27 12:37:02,581:INFO:Gradient Boosting Regressor Imported successfully
2024-05-27 12:37:02,598:INFO:Starting cross validation
2024-05-27 12:37:02,601:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:37:04,380:INFO:Calculating mean and std
2024-05-27 12:37:04,382:INFO:Creating metrics dataframe
2024-05-27 12:37:04,384:INFO:Uploading results into container
2024-05-27 12:37:04,385:INFO:Uploading model into container now
2024-05-27 12:37:04,385:INFO:_master_model_container: 36
2024-05-27 12:37:04,386:INFO:_display_container: 1
2024-05-27 12:37:04,386:INFO:GradientBoostingRegressor(random_state=42)
2024-05-27 12:37:04,386:INFO:create_model() successfully completed......................................
2024-05-27 12:37:04,560:INFO:SubProcess create_model() end ==================================
2024-05-27 12:37:04,560:INFO:Creating metrics dataframe
2024-05-27 12:37:04,582:INFO:Initializing Light Gradient Boosting Machine
2024-05-27 12:37:04,583:INFO:Total runtime is 0.3115914463996887 minutes
2024-05-27 12:37:04,590:INFO:SubProcess create_model() called ==================================
2024-05-27 12:37:04,590:INFO:Initializing create_model()
2024-05-27 12:37:04,590:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11701A710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:37:04,590:INFO:Checking exceptions
2024-05-27 12:37:04,590:INFO:Importing libraries
2024-05-27 12:37:04,590:INFO:Copying training dataset
2024-05-27 12:37:04,601:INFO:Defining folds
2024-05-27 12:37:04,601:INFO:Declaring metric variables
2024-05-27 12:37:04,607:INFO:Importing untrained model
2024-05-27 12:37:04,611:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 12:37:04,619:INFO:Starting cross validation
2024-05-27 12:37:04,621:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:37:06,897:INFO:Calculating mean and std
2024-05-27 12:37:06,900:INFO:Creating metrics dataframe
2024-05-27 12:37:06,904:INFO:Uploading results into container
2024-05-27 12:37:06,905:INFO:Uploading model into container now
2024-05-27 12:37:06,907:INFO:_master_model_container: 37
2024-05-27 12:37:06,907:INFO:_display_container: 1
2024-05-27 12:37:06,908:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:37:06,908:INFO:create_model() successfully completed......................................
2024-05-27 12:37:07,114:INFO:SubProcess create_model() end ==================================
2024-05-27 12:37:07,114:INFO:Creating metrics dataframe
2024-05-27 12:37:07,135:INFO:Initializing Dummy Regressor
2024-05-27 12:37:07,135:INFO:Total runtime is 0.3541178623835246 minutes
2024-05-27 12:37:07,140:INFO:SubProcess create_model() called ==================================
2024-05-27 12:37:07,141:INFO:Initializing create_model()
2024-05-27 12:37:07,141:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11701A710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:37:07,141:INFO:Checking exceptions
2024-05-27 12:37:07,141:INFO:Importing libraries
2024-05-27 12:37:07,141:INFO:Copying training dataset
2024-05-27 12:37:07,152:INFO:Defining folds
2024-05-27 12:37:07,153:INFO:Declaring metric variables
2024-05-27 12:37:07,157:INFO:Importing untrained model
2024-05-27 12:37:07,165:INFO:Dummy Regressor Imported successfully
2024-05-27 12:37:07,174:INFO:Starting cross validation
2024-05-27 12:37:07,176:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:37:07,940:INFO:Calculating mean and std
2024-05-27 12:37:07,941:INFO:Creating metrics dataframe
2024-05-27 12:37:07,943:INFO:Uploading results into container
2024-05-27 12:37:07,944:INFO:Uploading model into container now
2024-05-27 12:37:07,944:INFO:_master_model_container: 38
2024-05-27 12:37:07,945:INFO:_display_container: 1
2024-05-27 12:37:07,945:INFO:DummyRegressor()
2024-05-27 12:37:07,945:INFO:create_model() successfully completed......................................
2024-05-27 12:37:08,116:INFO:SubProcess create_model() end ==================================
2024-05-27 12:37:08,116:INFO:Creating metrics dataframe
2024-05-27 12:37:08,153:INFO:Initializing create_model()
2024-05-27 12:37:08,153:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:37:08,153:INFO:Checking exceptions
2024-05-27 12:37:08,156:INFO:Importing libraries
2024-05-27 12:37:08,156:INFO:Copying training dataset
2024-05-27 12:37:08,163:INFO:Defining folds
2024-05-27 12:37:08,163:INFO:Declaring metric variables
2024-05-27 12:37:08,163:INFO:Importing untrained model
2024-05-27 12:37:08,163:INFO:Declaring custom model
2024-05-27 12:37:08,165:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 12:37:08,166:INFO:Cross validation set to False
2024-05-27 12:37:08,166:INFO:Fitting Model
2024-05-27 12:37:08,354:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000297 seconds.
2024-05-27 12:37:08,355:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-27 12:37:08,355:INFO:[LightGBM] [Info] Total Bins 1660
2024-05-27 12:37:08,355:INFO:[LightGBM] [Info] Number of data points in the train set: 910, number of used features: 15
2024-05-27 12:37:08,356:INFO:[LightGBM] [Info] Start training from score -0.029448
2024-05-27 12:37:08,436:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:37:08,437:INFO:create_model() successfully completed......................................
2024-05-27 12:37:08,673:INFO:_master_model_container: 38
2024-05-27 12:37:08,676:INFO:_display_container: 1
2024-05-27 12:37:08,677:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:37:08,677:INFO:compare_models() successfully completed......................................
2024-05-27 12:37:20,814:INFO:Initializing plot_model()
2024-05-27 12:37:20,814:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:37:20,814:INFO:Checking exceptions
2024-05-27 12:37:20,821:INFO:Preloading libraries
2024-05-27 12:37:20,834:INFO:Copying training dataset
2024-05-27 12:37:20,834:INFO:Plot type: feature
2024-05-27 12:37:20,835:WARNING:No coef_ found. Trying feature_importances_
2024-05-27 12:37:21,153:INFO:Visual Rendered Successfully
2024-05-27 12:37:21,344:INFO:plot_model() successfully completed......................................
2024-05-27 12:37:21,345:INFO:Initializing plot_model()
2024-05-27 12:37:21,346:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=error, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:37:21,346:INFO:Checking exceptions
2024-05-27 12:37:21,353:INFO:Preloading libraries
2024-05-27 12:37:21,368:INFO:Copying training dataset
2024-05-27 12:37:21,368:INFO:Plot type: error
2024-05-27 12:37:21,526:INFO:Fitting Model
2024-05-27 12:37:21,526:INFO:Scoring test/hold-out set
2024-05-27 12:37:21,781:INFO:Visual Rendered Successfully
2024-05-27 12:37:21,960:INFO:plot_model() successfully completed......................................
2024-05-27 12:37:21,962:INFO:Initializing plot_model()
2024-05-27 12:37:21,962:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=residuals, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:37:21,962:INFO:Checking exceptions
2024-05-27 12:37:21,971:INFO:Preloading libraries
2024-05-27 12:37:21,982:INFO:Copying training dataset
2024-05-27 12:37:21,983:INFO:Plot type: residuals
2024-05-27 12:37:22,164:INFO:Fitting Model
2024-05-27 12:37:22,229:INFO:Scoring test/hold-out set
2024-05-27 12:37:22,665:INFO:Visual Rendered Successfully
2024-05-27 12:37:22,850:INFO:plot_model() successfully completed......................................
2024-05-27 12:37:33,300:INFO:Initializing evaluate_model()
2024-05-27 12:37:33,300:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-27 12:37:33,315:INFO:Initializing plot_model()
2024-05-27 12:37:33,315:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-27 12:37:33,316:INFO:Checking exceptions
2024-05-27 12:37:33,321:INFO:Preloading libraries
2024-05-27 12:37:33,332:INFO:Copying training dataset
2024-05-27 12:37:33,332:INFO:Plot type: pipeline
2024-05-27 12:37:33,507:INFO:Visual Rendered Successfully
2024-05-27 12:37:33,672:INFO:plot_model() successfully completed......................................
2024-05-27 12:37:36,241:INFO:Initializing tune_model()
2024-05-27 12:37:36,241:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-05-27 12:37:36,241:INFO:Checking exceptions
2024-05-27 12:37:36,266:INFO:Copying training dataset
2024-05-27 12:37:36,272:INFO:Checking base model
2024-05-27 12:37:36,272:INFO:Base model : Light Gradient Boosting Machine
2024-05-27 12:37:36,277:INFO:Declaring metric variables
2024-05-27 12:37:36,284:INFO:Defining Hyperparameters
2024-05-27 12:37:36,476:INFO:Tuning with n_jobs=-1
2024-05-27 12:37:36,476:INFO:Initializing RandomizedSearchCV
2024-05-27 12:37:50,073:INFO:best_params: {'actual_estimator__reg_lambda': 5, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 100, 'actual_estimator__min_split_gain': 0.6, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.8}
2024-05-27 12:37:50,074:INFO:Hyperparameter search completed
2024-05-27 12:37:50,075:INFO:SubProcess create_model() called ==================================
2024-05-27 12:37:50,076:INFO:Initializing create_model()
2024-05-27 12:37:50,076:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B16B4C8390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 5, 'reg_alpha': 0.001, 'num_leaves': 30, 'n_estimators': 100, 'min_split_gain': 0.6, 'min_child_samples': 6, 'learning_rate': 0.2, 'feature_fraction': 0.8, 'bagging_freq': 3, 'bagging_fraction': 0.8})
2024-05-27 12:37:50,076:INFO:Checking exceptions
2024-05-27 12:37:50,077:INFO:Importing libraries
2024-05-27 12:37:50,077:INFO:Copying training dataset
2024-05-27 12:37:50,093:INFO:Defining folds
2024-05-27 12:37:50,093:INFO:Declaring metric variables
2024-05-27 12:37:50,099:INFO:Importing untrained model
2024-05-27 12:37:50,100:INFO:Declaring custom model
2024-05-27 12:37:50,108:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 12:37:50,121:INFO:Starting cross validation
2024-05-27 12:37:50,124:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:37:51,935:INFO:Calculating mean and std
2024-05-27 12:37:51,938:INFO:Creating metrics dataframe
2024-05-27 12:37:51,948:INFO:Finalizing model
2024-05-27 12:37:52,288:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-05-27 12:37:52,288:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-05-27 12:37:52,288:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-05-27 12:37:52,291:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-05-27 12:37:52,291:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-05-27 12:37:52,291:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-05-27 12:37:52,292:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000362 seconds.
2024-05-27 12:37:52,292:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-27 12:37:52,292:INFO:[LightGBM] [Info] Total Bins 1660
2024-05-27 12:37:52,292:INFO:[LightGBM] [Info] Number of data points in the train set: 910, number of used features: 15
2024-05-27 12:37:52,293:INFO:[LightGBM] [Info] Start training from score -0.029448
2024-05-27 12:37:52,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,314:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,318:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,319:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,319:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,320:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,320:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,321:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,321:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,322:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,322:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,323:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,323:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,323:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,324:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,324:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,324:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,325:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,325:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,326:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,326:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,326:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,327:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,327:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,327:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,328:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,328:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,328:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,329:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,329:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,330:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,330:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,330:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,331:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,331:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,331:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,332:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,332:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,333:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,333:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,334:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,334:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,335:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,335:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,336:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,336:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,337:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,337:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,338:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,338:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,339:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,339:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,340:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,340:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,341:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,341:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,341:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,342:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,342:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,342:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,342:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,344:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,344:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,344:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,344:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,345:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,345:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,346:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,346:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:37:52,346:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:37:52,362:INFO:Uploading results into container
2024-05-27 12:37:52,364:INFO:Uploading model into container now
2024-05-27 12:37:52,365:INFO:_master_model_container: 39
2024-05-27 12:37:52,365:INFO:_display_container: 1
2024-05-27 12:37:52,366:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=3, feature_fraction=0.8,
              learning_rate=0.2, min_child_samples=6, min_split_gain=0.6,
              n_jobs=-1, num_leaves=30, random_state=42, reg_alpha=0.001,
              reg_lambda=5)
2024-05-27 12:37:52,367:INFO:create_model() successfully completed......................................
2024-05-27 12:37:52,574:INFO:SubProcess create_model() end ==================================
2024-05-27 12:37:52,574:INFO:choose_better activated
2024-05-27 12:37:52,580:INFO:SubProcess create_model() called ==================================
2024-05-27 12:37:52,581:INFO:Initializing create_model()
2024-05-27 12:37:52,581:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:37:52,581:INFO:Checking exceptions
2024-05-27 12:37:52,584:INFO:Importing libraries
2024-05-27 12:37:52,584:INFO:Copying training dataset
2024-05-27 12:37:52,596:INFO:Defining folds
2024-05-27 12:37:52,597:INFO:Declaring metric variables
2024-05-27 12:37:52,597:INFO:Importing untrained model
2024-05-27 12:37:52,597:INFO:Declaring custom model
2024-05-27 12:37:52,598:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 12:37:52,598:INFO:Starting cross validation
2024-05-27 12:37:52,600:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:37:55,057:INFO:Calculating mean and std
2024-05-27 12:37:55,058:INFO:Creating metrics dataframe
2024-05-27 12:37:55,061:INFO:Finalizing model
2024-05-27 12:37:55,340:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.
2024-05-27 12:37:55,340:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-27 12:37:55,340:INFO:[LightGBM] [Info] Total Bins 1660
2024-05-27 12:37:55,341:INFO:[LightGBM] [Info] Number of data points in the train set: 910, number of used features: 15
2024-05-27 12:37:55,341:INFO:[LightGBM] [Info] Start training from score -0.029448
2024-05-27 12:37:55,442:INFO:Uploading results into container
2024-05-27 12:37:55,443:INFO:Uploading model into container now
2024-05-27 12:37:55,444:INFO:_master_model_container: 40
2024-05-27 12:37:55,444:INFO:_display_container: 2
2024-05-27 12:37:55,445:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:37:55,445:INFO:create_model() successfully completed......................................
2024-05-27 12:37:55,640:INFO:SubProcess create_model() end ==================================
2024-05-27 12:37:55,641:INFO:LGBMRegressor(n_jobs=-1, random_state=42) result for R2 is 0.8022
2024-05-27 12:37:55,642:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=3, feature_fraction=0.8,
              learning_rate=0.2, min_child_samples=6, min_split_gain=0.6,
              n_jobs=-1, num_leaves=30, random_state=42, reg_alpha=0.001,
              reg_lambda=5) result for R2 is 0.7718
2024-05-27 12:37:55,642:INFO:LGBMRegressor(n_jobs=-1, random_state=42) is best model
2024-05-27 12:37:55,642:INFO:choose_better completed
2024-05-27 12:37:55,643:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-27 12:37:55,663:INFO:_master_model_container: 40
2024-05-27 12:37:55,663:INFO:_display_container: 1
2024-05-27 12:37:55,664:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:37:55,664:INFO:tune_model() successfully completed......................................
2024-05-27 12:37:59,777:INFO:Initializing plot_model()
2024-05-27 12:37:59,777:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:37:59,777:INFO:Checking exceptions
2024-05-27 12:37:59,783:INFO:Preloading libraries
2024-05-27 12:37:59,793:INFO:Copying training dataset
2024-05-27 12:37:59,793:INFO:Plot type: feature
2024-05-27 12:37:59,793:WARNING:No coef_ found. Trying feature_importances_
2024-05-27 12:38:00,036:INFO:Visual Rendered Successfully
2024-05-27 12:38:00,226:INFO:plot_model() successfully completed......................................
2024-05-27 12:38:00,227:INFO:Initializing plot_model()
2024-05-27 12:38:00,227:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=error, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:38:00,227:INFO:Checking exceptions
2024-05-27 12:38:00,236:INFO:Preloading libraries
2024-05-27 12:38:00,250:INFO:Copying training dataset
2024-05-27 12:38:00,251:INFO:Plot type: error
2024-05-27 12:38:00,416:INFO:Fitting Model
2024-05-27 12:38:00,416:INFO:Scoring test/hold-out set
2024-05-27 12:38:00,700:INFO:Visual Rendered Successfully
2024-05-27 12:38:00,896:INFO:plot_model() successfully completed......................................
2024-05-27 12:38:00,897:INFO:Initializing plot_model()
2024-05-27 12:38:00,897:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=residuals, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:38:00,897:INFO:Checking exceptions
2024-05-27 12:38:00,907:INFO:Preloading libraries
2024-05-27 12:38:00,918:INFO:Copying training dataset
2024-05-27 12:38:00,918:INFO:Plot type: residuals
2024-05-27 12:38:01,113:INFO:Fitting Model
2024-05-27 12:38:01,182:INFO:Scoring test/hold-out set
2024-05-27 12:38:01,817:INFO:Visual Rendered Successfully
2024-05-27 12:38:02,020:INFO:plot_model() successfully completed......................................
2024-05-27 12:38:10,298:INFO:Initializing evaluate_model()
2024-05-27 12:38:10,299:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-27 12:38:10,312:INFO:Initializing plot_model()
2024-05-27 12:38:10,312:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-27 12:38:10,313:INFO:Checking exceptions
2024-05-27 12:38:10,317:INFO:Preloading libraries
2024-05-27 12:38:10,327:INFO:Copying training dataset
2024-05-27 12:38:10,328:INFO:Plot type: pipeline
2024-05-27 12:38:10,501:INFO:Visual Rendered Successfully
2024-05-27 12:38:10,668:INFO:plot_model() successfully completed......................................
2024-05-27 12:45:21,107:INFO:Initializing compare_models()
2024-05-27 12:45:21,107:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-05-27 12:45:21,107:INFO:Checking exceptions
2024-05-27 12:45:21,112:INFO:Preparing display monitor
2024-05-27 12:45:21,142:INFO:Initializing Linear Regression
2024-05-27 12:45:21,143:INFO:Total runtime is 1.9705295562744142e-05 minutes
2024-05-27 12:45:21,148:INFO:SubProcess create_model() called ==================================
2024-05-27 12:45:21,149:INFO:Initializing create_model()
2024-05-27 12:45:21,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B121C42410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:45:21,149:INFO:Checking exceptions
2024-05-27 12:45:21,149:INFO:Importing libraries
2024-05-27 12:45:21,149:INFO:Copying training dataset
2024-05-27 12:45:21,157:INFO:Defining folds
2024-05-27 12:45:21,157:INFO:Declaring metric variables
2024-05-27 12:45:21,163:INFO:Importing untrained model
2024-05-27 12:45:21,167:INFO:Linear Regression Imported successfully
2024-05-27 12:45:21,179:INFO:Starting cross validation
2024-05-27 12:45:21,182:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:45:32,107:INFO:Calculating mean and std
2024-05-27 12:45:32,108:INFO:Creating metrics dataframe
2024-05-27 12:45:32,112:INFO:Uploading results into container
2024-05-27 12:45:32,114:INFO:Uploading model into container now
2024-05-27 12:45:32,115:INFO:_master_model_container: 41
2024-05-27 12:45:32,116:INFO:_display_container: 1
2024-05-27 12:45:32,117:INFO:LinearRegression(n_jobs=-1)
2024-05-27 12:45:32,118:INFO:create_model() successfully completed......................................
2024-05-27 12:45:32,388:INFO:SubProcess create_model() end ==================================
2024-05-27 12:45:32,389:INFO:Creating metrics dataframe
2024-05-27 12:45:32,406:INFO:Initializing Lasso Regression
2024-05-27 12:45:32,406:INFO:Total runtime is 0.1877351721127828 minutes
2024-05-27 12:45:32,414:INFO:SubProcess create_model() called ==================================
2024-05-27 12:45:32,415:INFO:Initializing create_model()
2024-05-27 12:45:32,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B121C42410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:45:32,416:INFO:Checking exceptions
2024-05-27 12:45:32,417:INFO:Importing libraries
2024-05-27 12:45:32,417:INFO:Copying training dataset
2024-05-27 12:45:32,427:INFO:Defining folds
2024-05-27 12:45:32,427:INFO:Declaring metric variables
2024-05-27 12:45:32,435:INFO:Importing untrained model
2024-05-27 12:45:32,442:INFO:Lasso Regression Imported successfully
2024-05-27 12:45:32,454:INFO:Starting cross validation
2024-05-27 12:45:32,455:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:45:33,143:INFO:Calculating mean and std
2024-05-27 12:45:33,145:INFO:Creating metrics dataframe
2024-05-27 12:45:33,148:INFO:Uploading results into container
2024-05-27 12:45:33,150:INFO:Uploading model into container now
2024-05-27 12:45:33,151:INFO:_master_model_container: 42
2024-05-27 12:45:33,151:INFO:_display_container: 1
2024-05-27 12:45:33,151:INFO:Lasso(random_state=42)
2024-05-27 12:45:33,152:INFO:create_model() successfully completed......................................
2024-05-27 12:45:33,322:INFO:SubProcess create_model() end ==================================
2024-05-27 12:45:33,322:INFO:Creating metrics dataframe
2024-05-27 12:45:33,336:INFO:Initializing Ridge Regression
2024-05-27 12:45:33,336:INFO:Total runtime is 0.2032449960708618 minutes
2024-05-27 12:45:33,342:INFO:SubProcess create_model() called ==================================
2024-05-27 12:45:33,342:INFO:Initializing create_model()
2024-05-27 12:45:33,342:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B121C42410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:45:33,343:INFO:Checking exceptions
2024-05-27 12:45:33,343:INFO:Importing libraries
2024-05-27 12:45:33,343:INFO:Copying training dataset
2024-05-27 12:45:33,354:INFO:Defining folds
2024-05-27 12:45:33,354:INFO:Declaring metric variables
2024-05-27 12:45:33,356:INFO:Importing untrained model
2024-05-27 12:45:33,363:INFO:Ridge Regression Imported successfully
2024-05-27 12:45:33,374:INFO:Starting cross validation
2024-05-27 12:45:33,375:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:45:34,028:INFO:Calculating mean and std
2024-05-27 12:45:34,030:INFO:Creating metrics dataframe
2024-05-27 12:45:34,032:INFO:Uploading results into container
2024-05-27 12:45:34,033:INFO:Uploading model into container now
2024-05-27 12:45:34,033:INFO:_master_model_container: 43
2024-05-27 12:45:34,033:INFO:_display_container: 1
2024-05-27 12:45:34,034:INFO:Ridge(random_state=42)
2024-05-27 12:45:34,034:INFO:create_model() successfully completed......................................
2024-05-27 12:45:34,205:INFO:SubProcess create_model() end ==================================
2024-05-27 12:45:34,205:INFO:Creating metrics dataframe
2024-05-27 12:45:34,226:INFO:Initializing Elastic Net
2024-05-27 12:45:34,226:INFO:Total runtime is 0.21807286341985066 minutes
2024-05-27 12:45:34,232:INFO:SubProcess create_model() called ==================================
2024-05-27 12:45:34,232:INFO:Initializing create_model()
2024-05-27 12:45:34,234:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B121C42410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:45:34,234:INFO:Checking exceptions
2024-05-27 12:45:34,234:INFO:Importing libraries
2024-05-27 12:45:34,234:INFO:Copying training dataset
2024-05-27 12:45:34,244:INFO:Defining folds
2024-05-27 12:45:34,244:INFO:Declaring metric variables
2024-05-27 12:45:34,251:INFO:Importing untrained model
2024-05-27 12:45:34,256:INFO:Elastic Net Imported successfully
2024-05-27 12:45:34,265:INFO:Starting cross validation
2024-05-27 12:45:34,267:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:45:34,882:INFO:Calculating mean and std
2024-05-27 12:45:34,883:INFO:Creating metrics dataframe
2024-05-27 12:45:34,885:INFO:Uploading results into container
2024-05-27 12:45:34,885:INFO:Uploading model into container now
2024-05-27 12:45:34,886:INFO:_master_model_container: 44
2024-05-27 12:45:34,886:INFO:_display_container: 1
2024-05-27 12:45:34,886:INFO:ElasticNet(random_state=42)
2024-05-27 12:45:34,886:INFO:create_model() successfully completed......................................
2024-05-27 12:45:35,059:INFO:SubProcess create_model() end ==================================
2024-05-27 12:45:35,059:INFO:Creating metrics dataframe
2024-05-27 12:45:35,080:INFO:Initializing Least Angle Regression
2024-05-27 12:45:35,081:INFO:Total runtime is 0.23231575886408487 minutes
2024-05-27 12:45:35,086:INFO:SubProcess create_model() called ==================================
2024-05-27 12:45:35,087:INFO:Initializing create_model()
2024-05-27 12:45:35,087:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B121C42410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:45:35,087:INFO:Checking exceptions
2024-05-27 12:45:35,087:INFO:Importing libraries
2024-05-27 12:45:35,088:INFO:Copying training dataset
2024-05-27 12:45:35,099:INFO:Defining folds
2024-05-27 12:45:35,099:INFO:Declaring metric variables
2024-05-27 12:45:35,104:INFO:Importing untrained model
2024-05-27 12:45:35,111:INFO:Least Angle Regression Imported successfully
2024-05-27 12:45:35,122:INFO:Starting cross validation
2024-05-27 12:45:35,124:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:45:35,751:INFO:Calculating mean and std
2024-05-27 12:45:35,752:INFO:Creating metrics dataframe
2024-05-27 12:45:35,753:INFO:Uploading results into container
2024-05-27 12:45:35,754:INFO:Uploading model into container now
2024-05-27 12:45:35,754:INFO:_master_model_container: 45
2024-05-27 12:45:35,754:INFO:_display_container: 1
2024-05-27 12:45:35,754:INFO:Lars(random_state=42)
2024-05-27 12:45:35,754:INFO:create_model() successfully completed......................................
2024-05-27 12:45:35,931:INFO:SubProcess create_model() end ==================================
2024-05-27 12:45:35,931:INFO:Creating metrics dataframe
2024-05-27 12:45:35,949:INFO:Initializing Lasso Least Angle Regression
2024-05-27 12:45:35,950:INFO:Total runtime is 0.24680884679158527 minutes
2024-05-27 12:45:35,956:INFO:SubProcess create_model() called ==================================
2024-05-27 12:45:35,957:INFO:Initializing create_model()
2024-05-27 12:45:35,957:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B121C42410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:45:35,957:INFO:Checking exceptions
2024-05-27 12:45:35,957:INFO:Importing libraries
2024-05-27 12:45:35,957:INFO:Copying training dataset
2024-05-27 12:45:35,969:INFO:Defining folds
2024-05-27 12:45:35,970:INFO:Declaring metric variables
2024-05-27 12:45:35,975:INFO:Importing untrained model
2024-05-27 12:45:35,983:INFO:Lasso Least Angle Regression Imported successfully
2024-05-27 12:45:35,991:INFO:Starting cross validation
2024-05-27 12:45:35,992:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:45:36,611:INFO:Calculating mean and std
2024-05-27 12:45:36,612:INFO:Creating metrics dataframe
2024-05-27 12:45:36,614:INFO:Uploading results into container
2024-05-27 12:45:36,615:INFO:Uploading model into container now
2024-05-27 12:45:36,615:INFO:_master_model_container: 46
2024-05-27 12:45:36,616:INFO:_display_container: 1
2024-05-27 12:45:36,616:INFO:LassoLars(random_state=42)
2024-05-27 12:45:36,617:INFO:create_model() successfully completed......................................
2024-05-27 12:45:36,792:INFO:SubProcess create_model() end ==================================
2024-05-27 12:45:36,792:INFO:Creating metrics dataframe
2024-05-27 12:45:36,809:INFO:Initializing Orthogonal Matching Pursuit
2024-05-27 12:45:36,809:INFO:Total runtime is 0.26111708879470824 minutes
2024-05-27 12:45:36,815:INFO:SubProcess create_model() called ==================================
2024-05-27 12:45:36,816:INFO:Initializing create_model()
2024-05-27 12:45:36,816:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B121C42410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:45:36,816:INFO:Checking exceptions
2024-05-27 12:45:36,817:INFO:Importing libraries
2024-05-27 12:45:36,817:INFO:Copying training dataset
2024-05-27 12:45:36,827:INFO:Defining folds
2024-05-27 12:45:36,828:INFO:Declaring metric variables
2024-05-27 12:45:36,836:INFO:Importing untrained model
2024-05-27 12:45:36,840:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-27 12:45:36,850:INFO:Starting cross validation
2024-05-27 12:45:36,852:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:45:37,459:INFO:Calculating mean and std
2024-05-27 12:45:37,460:INFO:Creating metrics dataframe
2024-05-27 12:45:37,462:INFO:Uploading results into container
2024-05-27 12:45:37,462:INFO:Uploading model into container now
2024-05-27 12:45:37,463:INFO:_master_model_container: 47
2024-05-27 12:45:37,463:INFO:_display_container: 1
2024-05-27 12:45:37,464:INFO:OrthogonalMatchingPursuit()
2024-05-27 12:45:37,464:INFO:create_model() successfully completed......................................
2024-05-27 12:45:37,637:INFO:SubProcess create_model() end ==================================
2024-05-27 12:45:37,638:INFO:Creating metrics dataframe
2024-05-27 12:45:37,655:INFO:Initializing Bayesian Ridge
2024-05-27 12:45:37,656:INFO:Total runtime is 0.27523502508799236 minutes
2024-05-27 12:45:37,661:INFO:SubProcess create_model() called ==================================
2024-05-27 12:45:37,662:INFO:Initializing create_model()
2024-05-27 12:45:37,662:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B121C42410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:45:37,662:INFO:Checking exceptions
2024-05-27 12:45:37,662:INFO:Importing libraries
2024-05-27 12:45:37,662:INFO:Copying training dataset
2024-05-27 12:45:37,672:INFO:Defining folds
2024-05-27 12:45:37,673:INFO:Declaring metric variables
2024-05-27 12:45:37,678:INFO:Importing untrained model
2024-05-27 12:45:37,685:INFO:Bayesian Ridge Imported successfully
2024-05-27 12:45:37,692:INFO:Starting cross validation
2024-05-27 12:45:37,695:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:45:38,320:INFO:Calculating mean and std
2024-05-27 12:45:38,321:INFO:Creating metrics dataframe
2024-05-27 12:45:38,323:INFO:Uploading results into container
2024-05-27 12:45:38,323:INFO:Uploading model into container now
2024-05-27 12:45:38,324:INFO:_master_model_container: 48
2024-05-27 12:45:38,324:INFO:_display_container: 1
2024-05-27 12:45:38,324:INFO:BayesianRidge()
2024-05-27 12:45:38,324:INFO:create_model() successfully completed......................................
2024-05-27 12:45:38,498:INFO:SubProcess create_model() end ==================================
2024-05-27 12:45:38,498:INFO:Creating metrics dataframe
2024-05-27 12:45:38,521:INFO:Initializing Passive Aggressive Regressor
2024-05-27 12:45:38,521:INFO:Total runtime is 0.28964913288752236 minutes
2024-05-27 12:45:38,526:INFO:SubProcess create_model() called ==================================
2024-05-27 12:45:38,526:INFO:Initializing create_model()
2024-05-27 12:45:38,526:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B121C42410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:45:38,528:INFO:Checking exceptions
2024-05-27 12:45:38,528:INFO:Importing libraries
2024-05-27 12:45:38,528:INFO:Copying training dataset
2024-05-27 12:45:38,538:INFO:Defining folds
2024-05-27 12:45:38,538:INFO:Declaring metric variables
2024-05-27 12:45:38,543:INFO:Importing untrained model
2024-05-27 12:45:38,549:INFO:Passive Aggressive Regressor Imported successfully
2024-05-27 12:45:38,557:INFO:Starting cross validation
2024-05-27 12:45:38,558:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:45:39,181:INFO:Calculating mean and std
2024-05-27 12:45:39,183:INFO:Creating metrics dataframe
2024-05-27 12:45:39,185:INFO:Uploading results into container
2024-05-27 12:45:39,186:INFO:Uploading model into container now
2024-05-27 12:45:39,187:INFO:_master_model_container: 49
2024-05-27 12:45:39,187:INFO:_display_container: 1
2024-05-27 12:45:39,187:INFO:PassiveAggressiveRegressor(random_state=42)
2024-05-27 12:45:39,187:INFO:create_model() successfully completed......................................
2024-05-27 12:45:39,366:INFO:SubProcess create_model() end ==================================
2024-05-27 12:45:39,366:INFO:Creating metrics dataframe
2024-05-27 12:45:39,383:INFO:Initializing Huber Regressor
2024-05-27 12:45:39,383:INFO:Total runtime is 0.30401925245920813 minutes
2024-05-27 12:45:39,388:INFO:SubProcess create_model() called ==================================
2024-05-27 12:45:39,389:INFO:Initializing create_model()
2024-05-27 12:45:39,389:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B121C42410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:45:39,389:INFO:Checking exceptions
2024-05-27 12:45:39,389:INFO:Importing libraries
2024-05-27 12:45:39,390:INFO:Copying training dataset
2024-05-27 12:45:39,399:INFO:Defining folds
2024-05-27 12:45:39,399:INFO:Declaring metric variables
2024-05-27 12:45:39,405:INFO:Importing untrained model
2024-05-27 12:45:39,412:INFO:Huber Regressor Imported successfully
2024-05-27 12:45:39,424:INFO:Starting cross validation
2024-05-27 12:45:39,425:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:45:40,094:INFO:Calculating mean and std
2024-05-27 12:45:40,095:INFO:Creating metrics dataframe
2024-05-27 12:45:40,096:INFO:Uploading results into container
2024-05-27 12:45:40,097:INFO:Uploading model into container now
2024-05-27 12:45:40,099:INFO:_master_model_container: 50
2024-05-27 12:45:40,100:INFO:_display_container: 1
2024-05-27 12:45:40,100:INFO:HuberRegressor()
2024-05-27 12:45:40,101:INFO:create_model() successfully completed......................................
2024-05-27 12:45:40,274:INFO:SubProcess create_model() end ==================================
2024-05-27 12:45:40,274:INFO:Creating metrics dataframe
2024-05-27 12:45:40,291:INFO:Initializing K Neighbors Regressor
2024-05-27 12:45:40,291:INFO:Total runtime is 0.3191553473472595 minutes
2024-05-27 12:45:40,297:INFO:SubProcess create_model() called ==================================
2024-05-27 12:45:40,298:INFO:Initializing create_model()
2024-05-27 12:45:40,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B121C42410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:45:40,299:INFO:Checking exceptions
2024-05-27 12:45:40,299:INFO:Importing libraries
2024-05-27 12:45:40,300:INFO:Copying training dataset
2024-05-27 12:45:40,310:INFO:Defining folds
2024-05-27 12:45:40,311:INFO:Declaring metric variables
2024-05-27 12:45:40,317:INFO:Importing untrained model
2024-05-27 12:45:40,322:INFO:K Neighbors Regressor Imported successfully
2024-05-27 12:45:40,333:INFO:Starting cross validation
2024-05-27 12:45:40,335:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:45:41,185:INFO:Calculating mean and std
2024-05-27 12:45:41,187:INFO:Creating metrics dataframe
2024-05-27 12:45:41,190:INFO:Uploading results into container
2024-05-27 12:45:41,190:INFO:Uploading model into container now
2024-05-27 12:45:41,191:INFO:_master_model_container: 51
2024-05-27 12:45:41,191:INFO:_display_container: 1
2024-05-27 12:45:41,192:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-27 12:45:41,192:INFO:create_model() successfully completed......................................
2024-05-27 12:45:41,363:INFO:SubProcess create_model() end ==================================
2024-05-27 12:45:41,363:INFO:Creating metrics dataframe
2024-05-27 12:45:41,382:INFO:Initializing Decision Tree Regressor
2024-05-27 12:45:41,383:INFO:Total runtime is 0.3373641649881998 minutes
2024-05-27 12:45:41,387:INFO:SubProcess create_model() called ==================================
2024-05-27 12:45:41,389:INFO:Initializing create_model()
2024-05-27 12:45:41,389:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B121C42410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:45:41,389:INFO:Checking exceptions
2024-05-27 12:45:41,389:INFO:Importing libraries
2024-05-27 12:45:41,389:INFO:Copying training dataset
2024-05-27 12:45:41,399:INFO:Defining folds
2024-05-27 12:45:41,400:INFO:Declaring metric variables
2024-05-27 12:45:41,403:INFO:Importing untrained model
2024-05-27 12:45:41,407:INFO:Decision Tree Regressor Imported successfully
2024-05-27 12:45:41,414:INFO:Starting cross validation
2024-05-27 12:45:41,415:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:45:42,532:INFO:Calculating mean and std
2024-05-27 12:45:42,533:INFO:Creating metrics dataframe
2024-05-27 12:45:42,536:INFO:Uploading results into container
2024-05-27 12:45:42,539:INFO:Uploading model into container now
2024-05-27 12:45:42,539:INFO:_master_model_container: 52
2024-05-27 12:45:42,539:INFO:_display_container: 1
2024-05-27 12:45:42,539:INFO:DecisionTreeRegressor(random_state=42)
2024-05-27 12:45:42,539:INFO:create_model() successfully completed......................................
2024-05-27 12:45:42,717:INFO:SubProcess create_model() end ==================================
2024-05-27 12:45:42,717:INFO:Creating metrics dataframe
2024-05-27 12:45:42,738:INFO:Initializing Random Forest Regressor
2024-05-27 12:45:42,738:INFO:Total runtime is 0.35994111299514764 minutes
2024-05-27 12:45:42,744:INFO:SubProcess create_model() called ==================================
2024-05-27 12:45:42,745:INFO:Initializing create_model()
2024-05-27 12:45:42,745:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B121C42410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:45:42,745:INFO:Checking exceptions
2024-05-27 12:45:42,745:INFO:Importing libraries
2024-05-27 12:45:42,745:INFO:Copying training dataset
2024-05-27 12:45:42,754:INFO:Defining folds
2024-05-27 12:45:42,754:INFO:Declaring metric variables
2024-05-27 12:45:42,760:INFO:Importing untrained model
2024-05-27 12:45:42,767:INFO:Random Forest Regressor Imported successfully
2024-05-27 12:45:42,777:INFO:Starting cross validation
2024-05-27 12:45:42,778:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:45:46,225:INFO:Calculating mean and std
2024-05-27 12:45:46,227:INFO:Creating metrics dataframe
2024-05-27 12:45:46,229:INFO:Uploading results into container
2024-05-27 12:45:46,231:INFO:Uploading model into container now
2024-05-27 12:45:46,232:INFO:_master_model_container: 53
2024-05-27 12:45:46,232:INFO:_display_container: 1
2024-05-27 12:45:46,233:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:45:46,233:INFO:create_model() successfully completed......................................
2024-05-27 12:45:46,409:INFO:SubProcess create_model() end ==================================
2024-05-27 12:45:46,409:INFO:Creating metrics dataframe
2024-05-27 12:45:46,430:INFO:Initializing Extra Trees Regressor
2024-05-27 12:45:46,430:INFO:Total runtime is 0.421464721361796 minutes
2024-05-27 12:45:46,435:INFO:SubProcess create_model() called ==================================
2024-05-27 12:45:46,436:INFO:Initializing create_model()
2024-05-27 12:45:46,436:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B121C42410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:45:46,436:INFO:Checking exceptions
2024-05-27 12:45:46,436:INFO:Importing libraries
2024-05-27 12:45:46,438:INFO:Copying training dataset
2024-05-27 12:45:46,448:INFO:Defining folds
2024-05-27 12:45:46,448:INFO:Declaring metric variables
2024-05-27 12:45:46,455:INFO:Importing untrained model
2024-05-27 12:45:46,460:INFO:Extra Trees Regressor Imported successfully
2024-05-27 12:45:46,470:INFO:Starting cross validation
2024-05-27 12:45:46,471:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:45:48,965:INFO:Calculating mean and std
2024-05-27 12:45:48,966:INFO:Creating metrics dataframe
2024-05-27 12:45:48,969:INFO:Uploading results into container
2024-05-27 12:45:48,969:INFO:Uploading model into container now
2024-05-27 12:45:48,970:INFO:_master_model_container: 54
2024-05-27 12:45:48,970:INFO:_display_container: 1
2024-05-27 12:45:48,970:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:45:48,971:INFO:create_model() successfully completed......................................
2024-05-27 12:45:49,147:INFO:SubProcess create_model() end ==================================
2024-05-27 12:45:49,147:INFO:Creating metrics dataframe
2024-05-27 12:45:49,169:INFO:Initializing AdaBoost Regressor
2024-05-27 12:45:49,169:INFO:Total runtime is 0.46711882352828976 minutes
2024-05-27 12:45:49,175:INFO:SubProcess create_model() called ==================================
2024-05-27 12:45:49,175:INFO:Initializing create_model()
2024-05-27 12:45:49,175:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B121C42410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:45:49,176:INFO:Checking exceptions
2024-05-27 12:45:49,176:INFO:Importing libraries
2024-05-27 12:45:49,176:INFO:Copying training dataset
2024-05-27 12:45:49,186:INFO:Defining folds
2024-05-27 12:45:49,187:INFO:Declaring metric variables
2024-05-27 12:45:49,190:INFO:Importing untrained model
2024-05-27 12:45:49,195:INFO:AdaBoost Regressor Imported successfully
2024-05-27 12:45:49,205:INFO:Starting cross validation
2024-05-27 12:45:49,206:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:45:50,770:INFO:Calculating mean and std
2024-05-27 12:45:50,772:INFO:Creating metrics dataframe
2024-05-27 12:45:50,775:INFO:Uploading results into container
2024-05-27 12:45:50,777:INFO:Uploading model into container now
2024-05-27 12:45:50,777:INFO:_master_model_container: 55
2024-05-27 12:45:50,777:INFO:_display_container: 1
2024-05-27 12:45:50,778:INFO:AdaBoostRegressor(random_state=42)
2024-05-27 12:45:50,778:INFO:create_model() successfully completed......................................
2024-05-27 12:45:50,960:INFO:SubProcess create_model() end ==================================
2024-05-27 12:45:50,961:INFO:Creating metrics dataframe
2024-05-27 12:45:50,982:INFO:Initializing Gradient Boosting Regressor
2024-05-27 12:45:50,982:INFO:Total runtime is 0.4973420818646749 minutes
2024-05-27 12:45:50,988:INFO:SubProcess create_model() called ==================================
2024-05-27 12:45:50,989:INFO:Initializing create_model()
2024-05-27 12:45:50,989:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B121C42410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:45:50,990:INFO:Checking exceptions
2024-05-27 12:45:50,990:INFO:Importing libraries
2024-05-27 12:45:50,990:INFO:Copying training dataset
2024-05-27 12:45:51,000:INFO:Defining folds
2024-05-27 12:45:51,000:INFO:Declaring metric variables
2024-05-27 12:45:51,005:INFO:Importing untrained model
2024-05-27 12:45:51,012:INFO:Gradient Boosting Regressor Imported successfully
2024-05-27 12:45:51,023:INFO:Starting cross validation
2024-05-27 12:45:51,024:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:45:52,938:INFO:Calculating mean and std
2024-05-27 12:45:52,940:INFO:Creating metrics dataframe
2024-05-27 12:45:52,942:INFO:Uploading results into container
2024-05-27 12:45:52,942:INFO:Uploading model into container now
2024-05-27 12:45:52,943:INFO:_master_model_container: 56
2024-05-27 12:45:52,943:INFO:_display_container: 1
2024-05-27 12:45:52,943:INFO:GradientBoostingRegressor(random_state=42)
2024-05-27 12:45:52,943:INFO:create_model() successfully completed......................................
2024-05-27 12:45:53,115:INFO:SubProcess create_model() end ==================================
2024-05-27 12:45:53,116:INFO:Creating metrics dataframe
2024-05-27 12:45:53,145:INFO:Initializing Light Gradient Boosting Machine
2024-05-27 12:45:53,145:INFO:Total runtime is 0.5333841602007547 minutes
2024-05-27 12:45:53,152:INFO:SubProcess create_model() called ==================================
2024-05-27 12:45:53,152:INFO:Initializing create_model()
2024-05-27 12:45:53,153:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B121C42410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:45:53,153:INFO:Checking exceptions
2024-05-27 12:45:53,153:INFO:Importing libraries
2024-05-27 12:45:53,153:INFO:Copying training dataset
2024-05-27 12:45:53,162:INFO:Defining folds
2024-05-27 12:45:53,163:INFO:Declaring metric variables
2024-05-27 12:45:53,170:INFO:Importing untrained model
2024-05-27 12:45:53,176:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 12:45:53,186:INFO:Starting cross validation
2024-05-27 12:45:53,187:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:45:55,573:INFO:Calculating mean and std
2024-05-27 12:45:55,575:INFO:Creating metrics dataframe
2024-05-27 12:45:55,579:INFO:Uploading results into container
2024-05-27 12:45:55,580:INFO:Uploading model into container now
2024-05-27 12:45:55,581:INFO:_master_model_container: 57
2024-05-27 12:45:55,582:INFO:_display_container: 1
2024-05-27 12:45:55,583:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:45:55,584:INFO:create_model() successfully completed......................................
2024-05-27 12:45:55,793:INFO:SubProcess create_model() end ==================================
2024-05-27 12:45:55,793:INFO:Creating metrics dataframe
2024-05-27 12:45:55,813:INFO:Initializing Dummy Regressor
2024-05-27 12:45:55,813:INFO:Total runtime is 0.5778585831324259 minutes
2024-05-27 12:45:55,820:INFO:SubProcess create_model() called ==================================
2024-05-27 12:45:55,820:INFO:Initializing create_model()
2024-05-27 12:45:55,820:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B121C42410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:45:55,821:INFO:Checking exceptions
2024-05-27 12:45:55,821:INFO:Importing libraries
2024-05-27 12:45:55,821:INFO:Copying training dataset
2024-05-27 12:45:55,831:INFO:Defining folds
2024-05-27 12:45:55,831:INFO:Declaring metric variables
2024-05-27 12:45:55,836:INFO:Importing untrained model
2024-05-27 12:45:55,842:INFO:Dummy Regressor Imported successfully
2024-05-27 12:45:55,885:INFO:Starting cross validation
2024-05-27 12:45:55,889:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:45:56,670:INFO:Calculating mean and std
2024-05-27 12:45:56,672:INFO:Creating metrics dataframe
2024-05-27 12:45:56,675:INFO:Uploading results into container
2024-05-27 12:45:56,676:INFO:Uploading model into container now
2024-05-27 12:45:56,676:INFO:_master_model_container: 58
2024-05-27 12:45:56,676:INFO:_display_container: 1
2024-05-27 12:45:56,677:INFO:DummyRegressor()
2024-05-27 12:45:56,677:INFO:create_model() successfully completed......................................
2024-05-27 12:45:56,854:INFO:SubProcess create_model() end ==================================
2024-05-27 12:45:56,854:INFO:Creating metrics dataframe
2024-05-27 12:45:56,890:INFO:Initializing create_model()
2024-05-27 12:45:56,890:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:45:56,890:INFO:Checking exceptions
2024-05-27 12:45:56,892:INFO:Importing libraries
2024-05-27 12:45:56,892:INFO:Copying training dataset
2024-05-27 12:45:56,900:INFO:Defining folds
2024-05-27 12:45:56,900:INFO:Declaring metric variables
2024-05-27 12:45:56,901:INFO:Importing untrained model
2024-05-27 12:45:56,901:INFO:Declaring custom model
2024-05-27 12:45:56,901:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 12:45:56,902:INFO:Cross validation set to False
2024-05-27 12:45:56,902:INFO:Fitting Model
2024-05-27 12:45:57,122:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000606 seconds.
2024-05-27 12:45:57,122:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-27 12:45:57,122:INFO:[LightGBM] [Info] Total Bins 1660
2024-05-27 12:45:57,123:INFO:[LightGBM] [Info] Number of data points in the train set: 910, number of used features: 15
2024-05-27 12:45:57,123:INFO:[LightGBM] [Info] Start training from score -0.029448
2024-05-27 12:45:57,208:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:45:57,208:INFO:create_model() successfully completed......................................
2024-05-27 12:45:57,520:INFO:_master_model_container: 58
2024-05-27 12:45:57,520:INFO:_display_container: 1
2024-05-27 12:45:57,521:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:45:57,521:INFO:compare_models() successfully completed......................................
2024-05-27 12:46:00,070:INFO:Initializing plot_model()
2024-05-27 12:46:00,071:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:46:00,071:INFO:Checking exceptions
2024-05-27 12:46:00,078:INFO:Preloading libraries
2024-05-27 12:46:00,103:INFO:Copying training dataset
2024-05-27 12:46:00,104:INFO:Plot type: feature
2024-05-27 12:46:00,111:WARNING:No coef_ found. Trying feature_importances_
2024-05-27 12:46:00,389:INFO:Visual Rendered Successfully
2024-05-27 12:46:00,570:INFO:plot_model() successfully completed......................................
2024-05-27 12:46:00,571:INFO:Initializing plot_model()
2024-05-27 12:46:00,573:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=error, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:46:00,573:INFO:Checking exceptions
2024-05-27 12:46:00,580:INFO:Preloading libraries
2024-05-27 12:46:00,591:INFO:Copying training dataset
2024-05-27 12:46:00,591:INFO:Plot type: error
2024-05-27 12:46:00,749:INFO:Fitting Model
2024-05-27 12:46:00,749:INFO:Scoring test/hold-out set
2024-05-27 12:46:01,030:INFO:Visual Rendered Successfully
2024-05-27 12:46:01,212:INFO:plot_model() successfully completed......................................
2024-05-27 12:46:01,213:INFO:Initializing plot_model()
2024-05-27 12:46:01,213:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=residuals, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:46:01,213:INFO:Checking exceptions
2024-05-27 12:46:01,222:INFO:Preloading libraries
2024-05-27 12:46:01,234:INFO:Copying training dataset
2024-05-27 12:46:01,235:INFO:Plot type: residuals
2024-05-27 12:46:01,436:INFO:Fitting Model
2024-05-27 12:46:01,513:INFO:Scoring test/hold-out set
2024-05-27 12:46:02,014:INFO:Visual Rendered Successfully
2024-05-27 12:46:02,209:INFO:plot_model() successfully completed......................................
2024-05-27 12:46:55,379:INFO:Initializing compare_models()
2024-05-27 12:46:55,379:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-05-27 12:46:55,379:INFO:Checking exceptions
2024-05-27 12:46:55,382:INFO:Preparing display monitor
2024-05-27 12:46:55,417:INFO:Initializing Linear Regression
2024-05-27 12:46:55,418:INFO:Total runtime is 1.8803278605143228e-05 minutes
2024-05-27 12:46:55,421:INFO:SubProcess create_model() called ==================================
2024-05-27 12:46:55,421:INFO:Initializing create_model()
2024-05-27 12:46:55,421:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11A687410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:46:55,421:INFO:Checking exceptions
2024-05-27 12:46:55,423:INFO:Importing libraries
2024-05-27 12:46:55,423:INFO:Copying training dataset
2024-05-27 12:46:55,434:INFO:Defining folds
2024-05-27 12:46:55,434:INFO:Declaring metric variables
2024-05-27 12:46:55,438:INFO:Importing untrained model
2024-05-27 12:46:55,442:INFO:Linear Regression Imported successfully
2024-05-27 12:46:55,452:INFO:Starting cross validation
2024-05-27 12:46:55,453:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:46:56,210:INFO:Calculating mean and std
2024-05-27 12:46:56,211:INFO:Creating metrics dataframe
2024-05-27 12:46:56,212:INFO:Uploading results into container
2024-05-27 12:46:56,213:INFO:Uploading model into container now
2024-05-27 12:46:56,213:INFO:_master_model_container: 59
2024-05-27 12:46:56,213:INFO:_display_container: 1
2024-05-27 12:46:56,214:INFO:LinearRegression(n_jobs=-1)
2024-05-27 12:46:56,214:INFO:create_model() successfully completed......................................
2024-05-27 12:46:56,402:INFO:SubProcess create_model() end ==================================
2024-05-27 12:46:56,402:INFO:Creating metrics dataframe
2024-05-27 12:46:56,415:INFO:Initializing Lasso Regression
2024-05-27 12:46:56,415:INFO:Total runtime is 0.016634853680928548 minutes
2024-05-27 12:46:56,423:INFO:SubProcess create_model() called ==================================
2024-05-27 12:46:56,424:INFO:Initializing create_model()
2024-05-27 12:46:56,424:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11A687410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:46:56,424:INFO:Checking exceptions
2024-05-27 12:46:56,425:INFO:Importing libraries
2024-05-27 12:46:56,425:INFO:Copying training dataset
2024-05-27 12:46:56,439:INFO:Defining folds
2024-05-27 12:46:56,440:INFO:Declaring metric variables
2024-05-27 12:46:56,444:INFO:Importing untrained model
2024-05-27 12:46:56,449:INFO:Lasso Regression Imported successfully
2024-05-27 12:46:56,458:INFO:Starting cross validation
2024-05-27 12:46:56,459:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:46:57,029:INFO:Calculating mean and std
2024-05-27 12:46:57,030:INFO:Creating metrics dataframe
2024-05-27 12:46:57,032:INFO:Uploading results into container
2024-05-27 12:46:57,033:INFO:Uploading model into container now
2024-05-27 12:46:57,033:INFO:_master_model_container: 60
2024-05-27 12:46:57,034:INFO:_display_container: 1
2024-05-27 12:46:57,034:INFO:Lasso(random_state=42)
2024-05-27 12:46:57,034:INFO:create_model() successfully completed......................................
2024-05-27 12:46:57,213:INFO:SubProcess create_model() end ==================================
2024-05-27 12:46:57,213:INFO:Creating metrics dataframe
2024-05-27 12:46:57,227:INFO:Initializing Ridge Regression
2024-05-27 12:46:57,228:INFO:Total runtime is 0.030182719230651855 minutes
2024-05-27 12:46:57,235:INFO:SubProcess create_model() called ==================================
2024-05-27 12:46:57,235:INFO:Initializing create_model()
2024-05-27 12:46:57,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11A687410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:46:57,236:INFO:Checking exceptions
2024-05-27 12:46:57,236:INFO:Importing libraries
2024-05-27 12:46:57,236:INFO:Copying training dataset
2024-05-27 12:46:57,247:INFO:Defining folds
2024-05-27 12:46:57,248:INFO:Declaring metric variables
2024-05-27 12:46:57,255:INFO:Importing untrained model
2024-05-27 12:46:57,261:INFO:Ridge Regression Imported successfully
2024-05-27 12:46:57,269:INFO:Starting cross validation
2024-05-27 12:46:57,270:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:46:57,855:INFO:Calculating mean and std
2024-05-27 12:46:57,856:INFO:Creating metrics dataframe
2024-05-27 12:46:57,857:INFO:Uploading results into container
2024-05-27 12:46:57,858:INFO:Uploading model into container now
2024-05-27 12:46:57,858:INFO:_master_model_container: 61
2024-05-27 12:46:57,858:INFO:_display_container: 1
2024-05-27 12:46:57,858:INFO:Ridge(random_state=42)
2024-05-27 12:46:57,858:INFO:create_model() successfully completed......................................
2024-05-27 12:46:58,045:INFO:SubProcess create_model() end ==================================
2024-05-27 12:46:58,046:INFO:Creating metrics dataframe
2024-05-27 12:46:58,059:INFO:Initializing Elastic Net
2024-05-27 12:46:58,059:INFO:Total runtime is 0.044044661521911624 minutes
2024-05-27 12:46:58,066:INFO:SubProcess create_model() called ==================================
2024-05-27 12:46:58,067:INFO:Initializing create_model()
2024-05-27 12:46:58,067:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11A687410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:46:58,068:INFO:Checking exceptions
2024-05-27 12:46:58,068:INFO:Importing libraries
2024-05-27 12:46:58,068:INFO:Copying training dataset
2024-05-27 12:46:58,078:INFO:Defining folds
2024-05-27 12:46:58,079:INFO:Declaring metric variables
2024-05-27 12:46:58,084:INFO:Importing untrained model
2024-05-27 12:46:58,090:INFO:Elastic Net Imported successfully
2024-05-27 12:46:58,102:INFO:Starting cross validation
2024-05-27 12:46:58,103:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:46:58,663:INFO:Calculating mean and std
2024-05-27 12:46:58,664:INFO:Creating metrics dataframe
2024-05-27 12:46:58,667:INFO:Uploading results into container
2024-05-27 12:46:58,668:INFO:Uploading model into container now
2024-05-27 12:46:58,668:INFO:_master_model_container: 62
2024-05-27 12:46:58,668:INFO:_display_container: 1
2024-05-27 12:46:58,669:INFO:ElasticNet(random_state=42)
2024-05-27 12:46:58,669:INFO:create_model() successfully completed......................................
2024-05-27 12:46:58,861:INFO:SubProcess create_model() end ==================================
2024-05-27 12:46:58,861:INFO:Creating metrics dataframe
2024-05-27 12:46:58,879:INFO:Initializing Least Angle Regression
2024-05-27 12:46:58,879:INFO:Total runtime is 0.05770020087560018 minutes
2024-05-27 12:46:58,885:INFO:SubProcess create_model() called ==================================
2024-05-27 12:46:58,887:INFO:Initializing create_model()
2024-05-27 12:46:58,887:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11A687410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:46:58,887:INFO:Checking exceptions
2024-05-27 12:46:58,887:INFO:Importing libraries
2024-05-27 12:46:58,887:INFO:Copying training dataset
2024-05-27 12:46:58,897:INFO:Defining folds
2024-05-27 12:46:58,898:INFO:Declaring metric variables
2024-05-27 12:46:58,904:INFO:Importing untrained model
2024-05-27 12:46:58,910:INFO:Least Angle Regression Imported successfully
2024-05-27 12:46:58,920:INFO:Starting cross validation
2024-05-27 12:46:58,922:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:46:59,586:INFO:Calculating mean and std
2024-05-27 12:46:59,587:INFO:Creating metrics dataframe
2024-05-27 12:46:59,590:INFO:Uploading results into container
2024-05-27 12:46:59,591:INFO:Uploading model into container now
2024-05-27 12:46:59,592:INFO:_master_model_container: 63
2024-05-27 12:46:59,592:INFO:_display_container: 1
2024-05-27 12:46:59,592:INFO:Lars(random_state=42)
2024-05-27 12:46:59,592:INFO:create_model() successfully completed......................................
2024-05-27 12:46:59,771:INFO:SubProcess create_model() end ==================================
2024-05-27 12:46:59,771:INFO:Creating metrics dataframe
2024-05-27 12:46:59,786:INFO:Initializing Lasso Least Angle Regression
2024-05-27 12:46:59,786:INFO:Total runtime is 0.07281597455342612 minutes
2024-05-27 12:46:59,791:INFO:SubProcess create_model() called ==================================
2024-05-27 12:46:59,792:INFO:Initializing create_model()
2024-05-27 12:46:59,793:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11A687410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:46:59,793:INFO:Checking exceptions
2024-05-27 12:46:59,793:INFO:Importing libraries
2024-05-27 12:46:59,793:INFO:Copying training dataset
2024-05-27 12:46:59,802:INFO:Defining folds
2024-05-27 12:46:59,804:INFO:Declaring metric variables
2024-05-27 12:46:59,810:INFO:Importing untrained model
2024-05-27 12:46:59,813:INFO:Lasso Least Angle Regression Imported successfully
2024-05-27 12:46:59,822:INFO:Starting cross validation
2024-05-27 12:46:59,823:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:47:00,433:INFO:Calculating mean and std
2024-05-27 12:47:00,434:INFO:Creating metrics dataframe
2024-05-27 12:47:00,436:INFO:Uploading results into container
2024-05-27 12:47:00,437:INFO:Uploading model into container now
2024-05-27 12:47:00,439:INFO:_master_model_container: 64
2024-05-27 12:47:00,439:INFO:_display_container: 1
2024-05-27 12:47:00,439:INFO:LassoLars(random_state=42)
2024-05-27 12:47:00,439:INFO:create_model() successfully completed......................................
2024-05-27 12:47:00,613:INFO:SubProcess create_model() end ==================================
2024-05-27 12:47:00,613:INFO:Creating metrics dataframe
2024-05-27 12:47:00,629:INFO:Initializing Orthogonal Matching Pursuit
2024-05-27 12:47:00,630:INFO:Total runtime is 0.08688212235768637 minutes
2024-05-27 12:47:00,638:INFO:SubProcess create_model() called ==================================
2024-05-27 12:47:00,638:INFO:Initializing create_model()
2024-05-27 12:47:00,639:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11A687410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:47:00,639:INFO:Checking exceptions
2024-05-27 12:47:00,639:INFO:Importing libraries
2024-05-27 12:47:00,639:INFO:Copying training dataset
2024-05-27 12:47:00,648:INFO:Defining folds
2024-05-27 12:47:00,649:INFO:Declaring metric variables
2024-05-27 12:47:00,654:INFO:Importing untrained model
2024-05-27 12:47:00,661:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-27 12:47:00,688:INFO:Starting cross validation
2024-05-27 12:47:00,689:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:47:01,265:INFO:Calculating mean and std
2024-05-27 12:47:01,267:INFO:Creating metrics dataframe
2024-05-27 12:47:01,270:INFO:Uploading results into container
2024-05-27 12:47:01,270:INFO:Uploading model into container now
2024-05-27 12:47:01,270:INFO:_master_model_container: 65
2024-05-27 12:47:01,270:INFO:_display_container: 1
2024-05-27 12:47:01,271:INFO:OrthogonalMatchingPursuit()
2024-05-27 12:47:01,271:INFO:create_model() successfully completed......................................
2024-05-27 12:47:01,453:INFO:SubProcess create_model() end ==================================
2024-05-27 12:47:01,453:INFO:Creating metrics dataframe
2024-05-27 12:47:01,471:INFO:Initializing Bayesian Ridge
2024-05-27 12:47:01,471:INFO:Total runtime is 0.10090970993041994 minutes
2024-05-27 12:47:01,478:INFO:SubProcess create_model() called ==================================
2024-05-27 12:47:01,478:INFO:Initializing create_model()
2024-05-27 12:47:01,478:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11A687410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:47:01,479:INFO:Checking exceptions
2024-05-27 12:47:01,479:INFO:Importing libraries
2024-05-27 12:47:01,479:INFO:Copying training dataset
2024-05-27 12:47:01,489:INFO:Defining folds
2024-05-27 12:47:01,489:INFO:Declaring metric variables
2024-05-27 12:47:01,493:INFO:Importing untrained model
2024-05-27 12:47:01,499:INFO:Bayesian Ridge Imported successfully
2024-05-27 12:47:01,509:INFO:Starting cross validation
2024-05-27 12:47:01,510:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:47:02,096:INFO:Calculating mean and std
2024-05-27 12:47:02,097:INFO:Creating metrics dataframe
2024-05-27 12:47:02,099:INFO:Uploading results into container
2024-05-27 12:47:02,100:INFO:Uploading model into container now
2024-05-27 12:47:02,101:INFO:_master_model_container: 66
2024-05-27 12:47:02,101:INFO:_display_container: 1
2024-05-27 12:47:02,102:INFO:BayesianRidge()
2024-05-27 12:47:02,103:INFO:create_model() successfully completed......................................
2024-05-27 12:47:02,282:INFO:SubProcess create_model() end ==================================
2024-05-27 12:47:02,282:INFO:Creating metrics dataframe
2024-05-27 12:47:02,297:INFO:Initializing Passive Aggressive Regressor
2024-05-27 12:47:02,297:INFO:Total runtime is 0.11467028856277467 minutes
2024-05-27 12:47:02,303:INFO:SubProcess create_model() called ==================================
2024-05-27 12:47:02,304:INFO:Initializing create_model()
2024-05-27 12:47:02,304:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11A687410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:47:02,304:INFO:Checking exceptions
2024-05-27 12:47:02,305:INFO:Importing libraries
2024-05-27 12:47:02,305:INFO:Copying training dataset
2024-05-27 12:47:02,315:INFO:Defining folds
2024-05-27 12:47:02,316:INFO:Declaring metric variables
2024-05-27 12:47:02,322:INFO:Importing untrained model
2024-05-27 12:47:02,325:INFO:Passive Aggressive Regressor Imported successfully
2024-05-27 12:47:02,337:INFO:Starting cross validation
2024-05-27 12:47:02,338:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:47:03,079:INFO:Calculating mean and std
2024-05-27 12:47:03,080:INFO:Creating metrics dataframe
2024-05-27 12:47:03,082:INFO:Uploading results into container
2024-05-27 12:47:03,084:INFO:Uploading model into container now
2024-05-27 12:47:03,084:INFO:_master_model_container: 67
2024-05-27 12:47:03,084:INFO:_display_container: 1
2024-05-27 12:47:03,085:INFO:PassiveAggressiveRegressor(random_state=42)
2024-05-27 12:47:03,085:INFO:create_model() successfully completed......................................
2024-05-27 12:47:03,270:INFO:SubProcess create_model() end ==================================
2024-05-27 12:47:03,270:INFO:Creating metrics dataframe
2024-05-27 12:47:03,287:INFO:Initializing Huber Regressor
2024-05-27 12:47:03,288:INFO:Total runtime is 0.13118000825246176 minutes
2024-05-27 12:47:03,293:INFO:SubProcess create_model() called ==================================
2024-05-27 12:47:03,294:INFO:Initializing create_model()
2024-05-27 12:47:03,294:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11A687410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:47:03,294:INFO:Checking exceptions
2024-05-27 12:47:03,294:INFO:Importing libraries
2024-05-27 12:47:03,294:INFO:Copying training dataset
2024-05-27 12:47:03,306:INFO:Defining folds
2024-05-27 12:47:03,306:INFO:Declaring metric variables
2024-05-27 12:47:03,310:INFO:Importing untrained model
2024-05-27 12:47:03,316:INFO:Huber Regressor Imported successfully
2024-05-27 12:47:03,325:INFO:Starting cross validation
2024-05-27 12:47:03,326:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:47:03,965:INFO:Calculating mean and std
2024-05-27 12:47:03,968:INFO:Creating metrics dataframe
2024-05-27 12:47:03,970:INFO:Uploading results into container
2024-05-27 12:47:03,971:INFO:Uploading model into container now
2024-05-27 12:47:03,972:INFO:_master_model_container: 68
2024-05-27 12:47:03,972:INFO:_display_container: 1
2024-05-27 12:47:03,972:INFO:HuberRegressor()
2024-05-27 12:47:03,972:INFO:create_model() successfully completed......................................
2024-05-27 12:47:04,156:INFO:SubProcess create_model() end ==================================
2024-05-27 12:47:04,156:INFO:Creating metrics dataframe
2024-05-27 12:47:04,172:INFO:Initializing K Neighbors Regressor
2024-05-27 12:47:04,172:INFO:Total runtime is 0.1459279537200928 minutes
2024-05-27 12:47:04,178:INFO:SubProcess create_model() called ==================================
2024-05-27 12:47:04,178:INFO:Initializing create_model()
2024-05-27 12:47:04,178:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11A687410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:47:04,178:INFO:Checking exceptions
2024-05-27 12:47:04,179:INFO:Importing libraries
2024-05-27 12:47:04,179:INFO:Copying training dataset
2024-05-27 12:47:04,190:INFO:Defining folds
2024-05-27 12:47:04,190:INFO:Declaring metric variables
2024-05-27 12:47:04,195:INFO:Importing untrained model
2024-05-27 12:47:04,199:INFO:K Neighbors Regressor Imported successfully
2024-05-27 12:47:04,209:INFO:Starting cross validation
2024-05-27 12:47:04,210:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:47:04,796:INFO:Calculating mean and std
2024-05-27 12:47:04,797:INFO:Creating metrics dataframe
2024-05-27 12:47:04,800:INFO:Uploading results into container
2024-05-27 12:47:04,801:INFO:Uploading model into container now
2024-05-27 12:47:04,802:INFO:_master_model_container: 69
2024-05-27 12:47:04,802:INFO:_display_container: 1
2024-05-27 12:47:04,802:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-27 12:47:04,802:INFO:create_model() successfully completed......................................
2024-05-27 12:47:04,985:INFO:SubProcess create_model() end ==================================
2024-05-27 12:47:04,986:INFO:Creating metrics dataframe
2024-05-27 12:47:05,003:INFO:Initializing Decision Tree Regressor
2024-05-27 12:47:05,003:INFO:Total runtime is 0.15977612336476646 minutes
2024-05-27 12:47:05,008:INFO:SubProcess create_model() called ==================================
2024-05-27 12:47:05,009:INFO:Initializing create_model()
2024-05-27 12:47:05,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11A687410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:47:05,009:INFO:Checking exceptions
2024-05-27 12:47:05,009:INFO:Importing libraries
2024-05-27 12:47:05,010:INFO:Copying training dataset
2024-05-27 12:47:05,021:INFO:Defining folds
2024-05-27 12:47:05,022:INFO:Declaring metric variables
2024-05-27 12:47:05,026:INFO:Importing untrained model
2024-05-27 12:47:05,031:INFO:Decision Tree Regressor Imported successfully
2024-05-27 12:47:05,040:INFO:Starting cross validation
2024-05-27 12:47:05,041:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:47:05,642:INFO:Calculating mean and std
2024-05-27 12:47:05,643:INFO:Creating metrics dataframe
2024-05-27 12:47:05,645:INFO:Uploading results into container
2024-05-27 12:47:05,645:INFO:Uploading model into container now
2024-05-27 12:47:05,646:INFO:_master_model_container: 70
2024-05-27 12:47:05,646:INFO:_display_container: 1
2024-05-27 12:47:05,646:INFO:DecisionTreeRegressor(random_state=42)
2024-05-27 12:47:05,646:INFO:create_model() successfully completed......................................
2024-05-27 12:47:05,823:INFO:SubProcess create_model() end ==================================
2024-05-27 12:47:05,823:INFO:Creating metrics dataframe
2024-05-27 12:47:05,841:INFO:Initializing Random Forest Regressor
2024-05-27 12:47:05,842:INFO:Total runtime is 0.1737415432929993 minutes
2024-05-27 12:47:05,849:INFO:SubProcess create_model() called ==================================
2024-05-27 12:47:05,850:INFO:Initializing create_model()
2024-05-27 12:47:05,850:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11A687410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:47:05,851:INFO:Checking exceptions
2024-05-27 12:47:05,851:INFO:Importing libraries
2024-05-27 12:47:05,851:INFO:Copying training dataset
2024-05-27 12:47:05,859:INFO:Defining folds
2024-05-27 12:47:05,859:INFO:Declaring metric variables
2024-05-27 12:47:05,863:INFO:Importing untrained model
2024-05-27 12:47:05,871:INFO:Random Forest Regressor Imported successfully
2024-05-27 12:47:05,880:INFO:Starting cross validation
2024-05-27 12:47:05,881:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:47:08,698:INFO:Calculating mean and std
2024-05-27 12:47:08,700:INFO:Creating metrics dataframe
2024-05-27 12:47:08,701:INFO:Uploading results into container
2024-05-27 12:47:08,703:INFO:Uploading model into container now
2024-05-27 12:47:08,704:INFO:_master_model_container: 71
2024-05-27 12:47:08,704:INFO:_display_container: 1
2024-05-27 12:47:08,704:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:47:08,704:INFO:create_model() successfully completed......................................
2024-05-27 12:47:08,887:INFO:SubProcess create_model() end ==================================
2024-05-27 12:47:08,887:INFO:Creating metrics dataframe
2024-05-27 12:47:08,904:INFO:Initializing Extra Trees Regressor
2024-05-27 12:47:08,904:INFO:Total runtime is 0.22479401032129925 minutes
2024-05-27 12:47:08,910:INFO:SubProcess create_model() called ==================================
2024-05-27 12:47:08,910:INFO:Initializing create_model()
2024-05-27 12:47:08,910:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11A687410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:47:08,910:INFO:Checking exceptions
2024-05-27 12:47:08,910:INFO:Importing libraries
2024-05-27 12:47:08,910:INFO:Copying training dataset
2024-05-27 12:47:08,922:INFO:Defining folds
2024-05-27 12:47:08,923:INFO:Declaring metric variables
2024-05-27 12:47:08,929:INFO:Importing untrained model
2024-05-27 12:47:08,934:INFO:Extra Trees Regressor Imported successfully
2024-05-27 12:47:08,944:INFO:Starting cross validation
2024-05-27 12:47:08,944:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:47:10,997:INFO:Calculating mean and std
2024-05-27 12:47:11,000:INFO:Creating metrics dataframe
2024-05-27 12:47:11,002:INFO:Uploading results into container
2024-05-27 12:47:11,003:INFO:Uploading model into container now
2024-05-27 12:47:11,003:INFO:_master_model_container: 72
2024-05-27 12:47:11,004:INFO:_display_container: 1
2024-05-27 12:47:11,004:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:47:11,004:INFO:create_model() successfully completed......................................
2024-05-27 12:47:11,187:INFO:SubProcess create_model() end ==================================
2024-05-27 12:47:11,188:INFO:Creating metrics dataframe
2024-05-27 12:47:11,206:INFO:Initializing AdaBoost Regressor
2024-05-27 12:47:11,206:INFO:Total runtime is 0.26316050291061405 minutes
2024-05-27 12:47:11,212:INFO:SubProcess create_model() called ==================================
2024-05-27 12:47:11,213:INFO:Initializing create_model()
2024-05-27 12:47:11,213:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11A687410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:47:11,213:INFO:Checking exceptions
2024-05-27 12:47:11,213:INFO:Importing libraries
2024-05-27 12:47:11,213:INFO:Copying training dataset
2024-05-27 12:47:11,222:INFO:Defining folds
2024-05-27 12:47:11,222:INFO:Declaring metric variables
2024-05-27 12:47:11,227:INFO:Importing untrained model
2024-05-27 12:47:11,234:INFO:AdaBoost Regressor Imported successfully
2024-05-27 12:47:11,242:INFO:Starting cross validation
2024-05-27 12:47:11,244:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:47:12,296:INFO:Calculating mean and std
2024-05-27 12:47:12,298:INFO:Creating metrics dataframe
2024-05-27 12:47:12,300:INFO:Uploading results into container
2024-05-27 12:47:12,301:INFO:Uploading model into container now
2024-05-27 12:47:12,301:INFO:_master_model_container: 73
2024-05-27 12:47:12,302:INFO:_display_container: 1
2024-05-27 12:47:12,302:INFO:AdaBoostRegressor(random_state=42)
2024-05-27 12:47:12,302:INFO:create_model() successfully completed......................................
2024-05-27 12:47:12,603:INFO:SubProcess create_model() end ==================================
2024-05-27 12:47:12,603:INFO:Creating metrics dataframe
2024-05-27 12:47:12,621:INFO:Initializing Gradient Boosting Regressor
2024-05-27 12:47:12,621:INFO:Total runtime is 0.28673607508341475 minutes
2024-05-27 12:47:12,629:INFO:SubProcess create_model() called ==================================
2024-05-27 12:47:12,630:INFO:Initializing create_model()
2024-05-27 12:47:12,630:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11A687410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:47:12,630:INFO:Checking exceptions
2024-05-27 12:47:12,630:INFO:Importing libraries
2024-05-27 12:47:12,630:INFO:Copying training dataset
2024-05-27 12:47:12,641:INFO:Defining folds
2024-05-27 12:47:12,641:INFO:Declaring metric variables
2024-05-27 12:47:12,646:INFO:Importing untrained model
2024-05-27 12:47:12,655:INFO:Gradient Boosting Regressor Imported successfully
2024-05-27 12:47:12,666:INFO:Starting cross validation
2024-05-27 12:47:12,669:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:47:14,721:INFO:Calculating mean and std
2024-05-27 12:47:14,723:INFO:Creating metrics dataframe
2024-05-27 12:47:14,725:INFO:Uploading results into container
2024-05-27 12:47:14,725:INFO:Uploading model into container now
2024-05-27 12:47:14,725:INFO:_master_model_container: 74
2024-05-27 12:47:14,725:INFO:_display_container: 1
2024-05-27 12:47:14,727:INFO:GradientBoostingRegressor(random_state=42)
2024-05-27 12:47:14,727:INFO:create_model() successfully completed......................................
2024-05-27 12:47:14,929:INFO:SubProcess create_model() end ==================================
2024-05-27 12:47:14,929:INFO:Creating metrics dataframe
2024-05-27 12:47:14,950:INFO:Initializing Light Gradient Boosting Machine
2024-05-27 12:47:14,950:INFO:Total runtime is 0.3255507588386536 minutes
2024-05-27 12:47:14,957:INFO:SubProcess create_model() called ==================================
2024-05-27 12:47:14,958:INFO:Initializing create_model()
2024-05-27 12:47:14,958:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11A687410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:47:14,958:INFO:Checking exceptions
2024-05-27 12:47:14,958:INFO:Importing libraries
2024-05-27 12:47:14,958:INFO:Copying training dataset
2024-05-27 12:47:14,970:INFO:Defining folds
2024-05-27 12:47:14,971:INFO:Declaring metric variables
2024-05-27 12:47:14,976:INFO:Importing untrained model
2024-05-27 12:47:14,983:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 12:47:14,995:INFO:Starting cross validation
2024-05-27 12:47:14,997:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:47:17,355:INFO:Calculating mean and std
2024-05-27 12:47:17,357:INFO:Creating metrics dataframe
2024-05-27 12:47:17,362:INFO:Uploading results into container
2024-05-27 12:47:17,363:INFO:Uploading model into container now
2024-05-27 12:47:17,364:INFO:_master_model_container: 75
2024-05-27 12:47:17,364:INFO:_display_container: 1
2024-05-27 12:47:17,365:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:47:17,367:INFO:create_model() successfully completed......................................
2024-05-27 12:47:17,562:INFO:SubProcess create_model() end ==================================
2024-05-27 12:47:17,563:INFO:Creating metrics dataframe
2024-05-27 12:47:17,583:INFO:Initializing Dummy Regressor
2024-05-27 12:47:17,583:INFO:Total runtime is 0.3694386124610901 minutes
2024-05-27 12:47:17,588:INFO:SubProcess create_model() called ==================================
2024-05-27 12:47:17,589:INFO:Initializing create_model()
2024-05-27 12:47:17,589:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11A687410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:47:17,589:INFO:Checking exceptions
2024-05-27 12:47:17,589:INFO:Importing libraries
2024-05-27 12:47:17,589:INFO:Copying training dataset
2024-05-27 12:47:17,601:INFO:Defining folds
2024-05-27 12:47:17,601:INFO:Declaring metric variables
2024-05-27 12:47:17,606:INFO:Importing untrained model
2024-05-27 12:47:17,610:INFO:Dummy Regressor Imported successfully
2024-05-27 12:47:17,624:INFO:Starting cross validation
2024-05-27 12:47:17,626:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:47:18,358:INFO:Calculating mean and std
2024-05-27 12:47:18,360:INFO:Creating metrics dataframe
2024-05-27 12:47:18,362:INFO:Uploading results into container
2024-05-27 12:47:18,362:INFO:Uploading model into container now
2024-05-27 12:47:18,363:INFO:_master_model_container: 76
2024-05-27 12:47:18,363:INFO:_display_container: 1
2024-05-27 12:47:18,363:INFO:DummyRegressor()
2024-05-27 12:47:18,364:INFO:create_model() successfully completed......................................
2024-05-27 12:47:18,549:INFO:SubProcess create_model() end ==================================
2024-05-27 12:47:18,549:INFO:Creating metrics dataframe
2024-05-27 12:47:18,591:INFO:Initializing create_model()
2024-05-27 12:47:18,592:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:47:18,592:INFO:Checking exceptions
2024-05-27 12:47:18,594:INFO:Importing libraries
2024-05-27 12:47:18,594:INFO:Copying training dataset
2024-05-27 12:47:18,602:INFO:Defining folds
2024-05-27 12:47:18,602:INFO:Declaring metric variables
2024-05-27 12:47:18,602:INFO:Importing untrained model
2024-05-27 12:47:18,603:INFO:Declaring custom model
2024-05-27 12:47:18,603:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 12:47:18,606:INFO:Cross validation set to False
2024-05-27 12:47:18,606:INFO:Fitting Model
2024-05-27 12:47:18,816:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000338 seconds.
2024-05-27 12:47:18,816:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-27 12:47:18,817:INFO:[LightGBM] [Info] Total Bins 1660
2024-05-27 12:47:18,817:INFO:[LightGBM] [Info] Number of data points in the train set: 910, number of used features: 15
2024-05-27 12:47:18,818:INFO:[LightGBM] [Info] Start training from score -0.029448
2024-05-27 12:47:18,907:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:47:18,908:INFO:create_model() successfully completed......................................
2024-05-27 12:47:19,159:INFO:_master_model_container: 76
2024-05-27 12:47:19,159:INFO:_display_container: 1
2024-05-27 12:47:19,160:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:47:19,160:INFO:compare_models() successfully completed......................................
2024-05-27 12:47:22,083:INFO:Initializing plot_model()
2024-05-27 12:47:22,083:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:47:22,083:INFO:Checking exceptions
2024-05-27 12:47:22,090:INFO:Preloading libraries
2024-05-27 12:47:22,099:INFO:Copying training dataset
2024-05-27 12:47:22,099:INFO:Plot type: feature
2024-05-27 12:47:22,100:WARNING:No coef_ found. Trying feature_importances_
2024-05-27 12:47:22,329:INFO:Visual Rendered Successfully
2024-05-27 12:47:22,520:INFO:plot_model() successfully completed......................................
2024-05-27 12:47:22,521:INFO:Initializing plot_model()
2024-05-27 12:47:22,521:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=error, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:47:22,522:INFO:Checking exceptions
2024-05-27 12:47:22,528:INFO:Preloading libraries
2024-05-27 12:47:22,543:INFO:Copying training dataset
2024-05-27 12:47:22,543:INFO:Plot type: error
2024-05-27 12:47:22,702:INFO:Fitting Model
2024-05-27 12:47:22,702:INFO:Scoring test/hold-out set
2024-05-27 12:47:22,985:INFO:Visual Rendered Successfully
2024-05-27 12:47:23,167:INFO:plot_model() successfully completed......................................
2024-05-27 12:47:23,168:INFO:Initializing plot_model()
2024-05-27 12:47:23,169:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A5B3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=residuals, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:47:23,169:INFO:Checking exceptions
2024-05-27 12:47:23,177:INFO:Preloading libraries
2024-05-27 12:47:23,190:INFO:Copying training dataset
2024-05-27 12:47:23,190:INFO:Plot type: residuals
2024-05-27 12:47:23,380:INFO:Fitting Model
2024-05-27 12:47:23,450:INFO:Scoring test/hold-out set
2024-05-27 12:47:23,986:INFO:Visual Rendered Successfully
2024-05-27 12:47:24,183:INFO:plot_model() successfully completed......................................
2024-05-27 12:50:27,564:WARNING:C:\Users\muril\AppData\Local\Temp\ipykernel_8820\4212681043.py:2: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
  plt.style.use('seaborn-darkgrid')

2024-05-27 12:52:08,452:WARNING:C:\Users\muril\AppData\Local\Temp\ipykernel_8820\1066813642.py:3: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_clean[numeric_columns] = scaler.fit_transform(df_clean[numeric_columns])

2024-05-27 12:52:46,247:WARNING:c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
141 fits failed out of a total of 300.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
69 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 1467, in wrapper
    estimator._validate_params()
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.

--------------------------------------------------------------------------------
72 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 1467, in wrapper
    estimator._validate_params()
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-27 12:52:46,251:WARNING:c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.73690131 0.7723179  0.76899183        nan        nan 0.70603466
 0.76899183        nan 0.72649309 0.77494848        nan        nan
        nan 0.76775927 0.70724616 0.64097707        nan 0.7714591
        nan        nan 0.69886104        nan        nan        nan
 0.69316    0.74093953        nan        nan        nan 0.77852071
        nan 0.72663432 0.73795808 0.69886104        nan        nan
        nan        nan 0.77254916        nan 0.6953924         nan
        nan        nan 0.76856778 0.69167232        nan 0.70716815
 0.77776253 0.77140226 0.75186111        nan 0.74493442        nan
        nan 0.70455147 0.72045513        nan        nan        nan
        nan        nan 0.70401667        nan        nan 0.77201249
        nan        nan 0.77220018        nan 0.72675909 0.74093953
 0.77889893        nan        nan 0.70631594        nan 0.74838051
 0.66321771 0.70773896 0.72697562 0.72675909 0.69642805        nan
 0.72045513 0.69886104        nan        nan 0.74838051 0.76027421
 0.75135719 0.70628675        nan 0.72663432        nan 0.77178874
 0.72663432 0.7723179  0.75135616        nan]
  warnings.warn(

2024-05-27 12:53:23,610:WARNING:c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
141 fits failed out of a total of 300.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
60 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 1467, in wrapper
    estimator._validate_params()
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.

--------------------------------------------------------------------------------
81 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 1467, in wrapper
    estimator._validate_params()
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-27 12:53:23,616:WARNING:c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.75585937 0.79038632 0.77436615        nan        nan 0.74595153
 0.77436615        nan 0.76142618 0.78462259        nan        nan
        nan 0.78063503 0.74489877 0.72712048        nan 0.78613949
        nan        nan 0.74547562        nan        nan        nan
 0.73151238 0.77264907        nan        nan        nan 0.79116805
        nan 0.76059954 0.75986035 0.74547562        nan        nan
        nan        nan 0.78932932        nan 0.73916425        nan
        nan        nan 0.7793353  0.7253631         nan 0.74008125
 0.79189862 0.78684028 0.77842616        nan 0.75567687        nan
        nan 0.74347782 0.75170118        nan        nan        nan
        nan        nan 0.73945853        nan        nan 0.78938319
        nan        nan 0.78975469        nan 0.76005707 0.77264907
 0.790783          nan        nan 0.74597706        nan 0.77582515
 0.73262594 0.74496854 0.75984297 0.76005707 0.7397241         nan
 0.75170118 0.74547562        nan        nan 0.77582515 0.77261023
 0.778412   0.74471839        nan 0.76059954        nan 0.78365244
 0.76059954 0.79038632 0.77840329        nan]
  warnings.warn(

2024-05-27 12:54:29,078:INFO:PyCaret RegressionExperiment
2024-05-27 12:54:29,079:INFO:Logging name: reg-default-name
2024-05-27 12:54:29,079:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-27 12:54:29,079:INFO:version 3.3.0
2024-05-27 12:54:29,079:INFO:Initializing setup()
2024-05-27 12:54:29,080:INFO:self.USI: a44d
2024-05-27 12:54:29,080:INFO:self._variable_keys: {'exp_name_log', 'X_train', 'logging_param', 'gpu_n_jobs_param', 'y_train', 'idx', 'gpu_param', 'y', '_ml_usecase', 'html_param', 'fold_generator', 'n_jobs_param', 'exp_id', 'fold_groups_param', 'data', 'seed', 'X', 'y_test', 'target_param', 'pipeline', '_available_plots', 'fold_shuffle_param', 'transform_target_param', 'log_plots_param', 'X_test', 'memory', 'USI'}
2024-05-27 12:54:29,081:INFO:Checking environment
2024-05-27 12:54:29,082:INFO:python_version: 3.11.5
2024-05-27 12:54:29,082:INFO:python_build: ('tags/v3.11.5:cce6ba9', 'Aug 24 2023 14:38:34')
2024-05-27 12:54:29,082:INFO:machine: AMD64
2024-05-27 12:54:29,082:INFO:platform: Windows-10-10.0.22631-SP0
2024-05-27 12:54:29,089:INFO:Memory: svmem(total=8459792384, available=499245056, percent=94.1, used=7960547328, free=499245056)
2024-05-27 12:54:29,089:INFO:Physical Core: 4
2024-05-27 12:54:29,089:INFO:Logical Core: 8
2024-05-27 12:54:29,089:INFO:Checking libraries
2024-05-27 12:54:29,089:INFO:System:
2024-05-27 12:54:29,090:INFO:    python: 3.11.5 (tags/v3.11.5:cce6ba9, Aug 24 2023, 14:38:34) [MSC v.1936 64 bit (AMD64)]
2024-05-27 12:54:29,090:INFO:executable: c:\Users\muril\AppData\Local\Programs\Python\Python311\python.exe
2024-05-27 12:54:29,090:INFO:   machine: Windows-10-10.0.22631-SP0
2024-05-27 12:54:29,090:INFO:PyCaret required dependencies:
2024-05-27 12:54:29,092:INFO:                 pip: 24.0
2024-05-27 12:54:29,092:INFO:          setuptools: 68.1.2
2024-05-27 12:54:29,092:INFO:             pycaret: 3.3.0
2024-05-27 12:54:29,092:INFO:             IPython: 8.14.0
2024-05-27 12:54:29,092:INFO:          ipywidgets: 8.1.0
2024-05-27 12:54:29,092:INFO:                tqdm: 4.66.1
2024-05-27 12:54:29,093:INFO:               numpy: 1.26.4
2024-05-27 12:54:29,093:INFO:              pandas: 2.0.2
2024-05-27 12:54:29,093:INFO:              jinja2: 3.1.2
2024-05-27 12:54:29,093:INFO:               scipy: 1.10.1
2024-05-27 12:54:29,093:INFO:              joblib: 1.2.0
2024-05-27 12:54:29,093:INFO:             sklearn: 1.4.1.post1
2024-05-27 12:54:29,093:INFO:                pyod: 1.1.3
2024-05-27 12:54:29,093:INFO:            imblearn: 0.12.1
2024-05-27 12:54:29,093:INFO:   category_encoders: 2.6.3
2024-05-27 12:54:29,093:INFO:            lightgbm: 4.3.0
2024-05-27 12:54:29,094:INFO:               numba: 0.59.1
2024-05-27 12:54:29,094:INFO:            requests: 2.31.0
2024-05-27 12:54:29,094:INFO:          matplotlib: 3.7.1
2024-05-27 12:54:29,094:INFO:          scikitplot: 0.3.7
2024-05-27 12:54:29,094:INFO:         yellowbrick: 1.5
2024-05-27 12:54:29,094:INFO:              plotly: 5.18.0
2024-05-27 12:54:29,094:INFO:    plotly-resampler: Not installed
2024-05-27 12:54:29,094:INFO:             kaleido: 0.2.1
2024-05-27 12:54:29,094:INFO:           schemdraw: 0.15
2024-05-27 12:54:29,094:INFO:         statsmodels: 0.14.1
2024-05-27 12:54:29,094:INFO:              sktime: 0.28.0
2024-05-27 12:54:29,094:INFO:               tbats: 1.1.3
2024-05-27 12:54:29,094:INFO:            pmdarima: 2.0.4
2024-05-27 12:54:29,095:INFO:              psutil: 5.9.5
2024-05-27 12:54:29,095:INFO:          markupsafe: 2.1.2
2024-05-27 12:54:29,095:INFO:             pickle5: Not installed
2024-05-27 12:54:29,095:INFO:         cloudpickle: 3.0.0
2024-05-27 12:54:29,095:INFO:         deprecation: 2.1.0
2024-05-27 12:54:29,095:INFO:              xxhash: 3.4.1
2024-05-27 12:54:29,095:INFO:           wurlitzer: Not installed
2024-05-27 12:54:29,095:INFO:PyCaret optional dependencies:
2024-05-27 12:54:29,095:INFO:                shap: Not installed
2024-05-27 12:54:29,095:INFO:           interpret: Not installed
2024-05-27 12:54:29,095:INFO:                umap: Not installed
2024-05-27 12:54:29,095:INFO:     ydata_profiling: Not installed
2024-05-27 12:54:29,095:INFO:  explainerdashboard: Not installed
2024-05-27 12:54:29,096:INFO:             autoviz: Not installed
2024-05-27 12:54:29,096:INFO:           fairlearn: Not installed
2024-05-27 12:54:29,096:INFO:          deepchecks: Not installed
2024-05-27 12:54:29,096:INFO:             xgboost: Not installed
2024-05-27 12:54:29,096:INFO:            catboost: Not installed
2024-05-27 12:54:29,096:INFO:              kmodes: Not installed
2024-05-27 12:54:29,096:INFO:             mlxtend: Not installed
2024-05-27 12:54:29,096:INFO:       statsforecast: Not installed
2024-05-27 12:54:29,096:INFO:        tune_sklearn: Not installed
2024-05-27 12:54:29,096:INFO:                 ray: Not installed
2024-05-27 12:54:29,096:INFO:            hyperopt: Not installed
2024-05-27 12:54:29,096:INFO:              optuna: Not installed
2024-05-27 12:54:29,096:INFO:               skopt: Not installed
2024-05-27 12:54:29,096:INFO:              mlflow: Not installed
2024-05-27 12:54:29,096:INFO:              gradio: Not installed
2024-05-27 12:54:29,096:INFO:             fastapi: Not installed
2024-05-27 12:54:29,096:INFO:             uvicorn: Not installed
2024-05-27 12:54:29,096:INFO:              m2cgen: Not installed
2024-05-27 12:54:29,096:INFO:           evidently: Not installed
2024-05-27 12:54:29,097:INFO:               fugue: Not installed
2024-05-27 12:54:29,097:INFO:           streamlit: 1.28.1
2024-05-27 12:54:29,097:INFO:             prophet: Not installed
2024-05-27 12:54:29,097:INFO:None
2024-05-27 12:54:29,097:INFO:Set up data.
2024-05-27 12:54:29,109:INFO:Set up folding strategy.
2024-05-27 12:54:29,110:INFO:Set up train/test split.
2024-05-27 12:54:29,117:INFO:Set up index.
2024-05-27 12:54:29,117:INFO:Assigning column types.
2024-05-27 12:54:29,124:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-27 12:54:29,125:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,130:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,136:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,209:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,261:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,262:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:29,263:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:29,263:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,268:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,273:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,345:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,397:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,397:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:29,397:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:29,398:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-27 12:54:29,403:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,408:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,477:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,525:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,527:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:29,527:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:29,534:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,539:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,605:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,657:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,657:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:29,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:29,658:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-27 12:54:29,668:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,739:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,791:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,791:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:29,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:29,803:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,875:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,931:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 12:54:29,932:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:29,932:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:29,933:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-27 12:54:30,011:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 12:54:30,062:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 12:54:30,063:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:30,063:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:30,198:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 12:54:30,322:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 12:54:30,323:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:30,324:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:30,324:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-27 12:54:30,556:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 12:54:30,632:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:30,632:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:30,713:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 12:54:30,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:30,768:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:30,768:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-27 12:54:30,897:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:30,898:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:31,027:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:31,027:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:31,035:INFO:Preparing preprocessing pipeline...
2024-05-27 12:54:31,035:INFO:Set up simple imputation.
2024-05-27 12:54:31,035:INFO:Set up removing outliers.
2024-05-27 12:54:31,035:INFO:Set up feature normalization.
2024-05-27 12:54:31,079:INFO:Finished creating preprocessing pipeline.
2024-05-27 12:54:31,084:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\muril\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['num_bed', 'num_bath',
                                             'size_house', 'size_lot',
                                             'num_floors', 'is_waterfront',
                                             'condition', 'size_basement',
                                             'year_built', 'renovation_date',
                                             'zip', 'latitude', 'longitude',
                                             'avg_size_neighbor_houses',
                                             'avg_size_neighbor_lot',
                                             'zip_prefix_3', 'zip_prefix_4'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2024-05-27 12:54:31,085:INFO:Creating final display dataframe.
2024-05-27 12:54:31,200:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target             price
2                   Target type        Regression
3           Original data shape        (1370, 18)
4        Transformed data shape        (1322, 18)
5   Transformed train set shape         (910, 18)
6    Transformed test set shape         (412, 18)
7              Numeric features                17
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12              Remove outliers              True
13           Outliers threshold              0.05
14                    Normalize              True
15             Normalize method            zscore
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              a44d
2024-05-27 12:54:31,349:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:31,349:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:31,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:31,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:54:31,476:WARNING:c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-05-27 12:54:31,477:INFO:setup() successfully completed in 2.41s...............
2024-05-27 12:54:31,494:INFO:Initializing compare_models()
2024-05-27 12:54:31,495:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-05-27 12:54:31,495:INFO:Checking exceptions
2024-05-27 12:54:31,502:INFO:Preparing display monitor
2024-05-27 12:54:31,542:INFO:Initializing Linear Regression
2024-05-27 12:54:31,542:INFO:Total runtime is 0.0 minutes
2024-05-27 12:54:31,550:INFO:SubProcess create_model() called ==================================
2024-05-27 12:54:31,550:INFO:Initializing create_model()
2024-05-27 12:54:31,551:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B129E36E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:54:31,551:INFO:Checking exceptions
2024-05-27 12:54:31,551:INFO:Importing libraries
2024-05-27 12:54:31,551:INFO:Copying training dataset
2024-05-27 12:54:31,560:INFO:Defining folds
2024-05-27 12:54:31,561:INFO:Declaring metric variables
2024-05-27 12:54:31,566:INFO:Importing untrained model
2024-05-27 12:54:31,574:INFO:Linear Regression Imported successfully
2024-05-27 12:54:31,583:INFO:Starting cross validation
2024-05-27 12:54:31,584:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:54:32,373:INFO:Calculating mean and std
2024-05-27 12:54:32,374:INFO:Creating metrics dataframe
2024-05-27 12:54:32,376:INFO:Uploading results into container
2024-05-27 12:54:32,377:INFO:Uploading model into container now
2024-05-27 12:54:32,377:INFO:_master_model_container: 1
2024-05-27 12:54:32,377:INFO:_display_container: 2
2024-05-27 12:54:32,378:INFO:LinearRegression(n_jobs=-1)
2024-05-27 12:54:32,378:INFO:create_model() successfully completed......................................
2024-05-27 12:54:32,998:INFO:SubProcess create_model() end ==================================
2024-05-27 12:54:32,998:INFO:Creating metrics dataframe
2024-05-27 12:54:33,019:INFO:Initializing Lasso Regression
2024-05-27 12:54:33,020:INFO:Total runtime is 0.024632449944814047 minutes
2024-05-27 12:54:33,024:INFO:SubProcess create_model() called ==================================
2024-05-27 12:54:33,025:INFO:Initializing create_model()
2024-05-27 12:54:33,025:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B129E36E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:54:33,025:INFO:Checking exceptions
2024-05-27 12:54:33,025:INFO:Importing libraries
2024-05-27 12:54:33,025:INFO:Copying training dataset
2024-05-27 12:54:33,034:INFO:Defining folds
2024-05-27 12:54:33,034:INFO:Declaring metric variables
2024-05-27 12:54:33,040:INFO:Importing untrained model
2024-05-27 12:54:33,044:INFO:Lasso Regression Imported successfully
2024-05-27 12:54:33,052:INFO:Starting cross validation
2024-05-27 12:54:33,054:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:54:34,526:INFO:Calculating mean and std
2024-05-27 12:54:34,530:INFO:Creating metrics dataframe
2024-05-27 12:54:34,534:INFO:Uploading results into container
2024-05-27 12:54:34,536:INFO:Uploading model into container now
2024-05-27 12:54:34,537:INFO:_master_model_container: 2
2024-05-27 12:54:34,537:INFO:_display_container: 2
2024-05-27 12:54:34,538:INFO:Lasso(random_state=42)
2024-05-27 12:54:34,539:INFO:create_model() successfully completed......................................
2024-05-27 12:54:35,673:INFO:SubProcess create_model() end ==================================
2024-05-27 12:54:35,674:INFO:Creating metrics dataframe
2024-05-27 12:54:35,682:INFO:Initializing Ridge Regression
2024-05-27 12:54:35,682:INFO:Total runtime is 0.06899291276931763 minutes
2024-05-27 12:54:35,685:INFO:SubProcess create_model() called ==================================
2024-05-27 12:54:35,686:INFO:Initializing create_model()
2024-05-27 12:54:35,686:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B129E36E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:54:35,686:INFO:Checking exceptions
2024-05-27 12:54:35,687:INFO:Importing libraries
2024-05-27 12:54:35,687:INFO:Copying training dataset
2024-05-27 12:54:35,696:INFO:Defining folds
2024-05-27 12:54:35,696:INFO:Declaring metric variables
2024-05-27 12:54:35,700:INFO:Importing untrained model
2024-05-27 12:54:35,707:INFO:Ridge Regression Imported successfully
2024-05-27 12:54:35,716:INFO:Starting cross validation
2024-05-27 12:54:35,718:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:54:36,385:INFO:Calculating mean and std
2024-05-27 12:54:36,386:INFO:Creating metrics dataframe
2024-05-27 12:54:36,388:INFO:Uploading results into container
2024-05-27 12:54:36,389:INFO:Uploading model into container now
2024-05-27 12:54:36,389:INFO:_master_model_container: 3
2024-05-27 12:54:36,389:INFO:_display_container: 2
2024-05-27 12:54:36,390:INFO:Ridge(random_state=42)
2024-05-27 12:54:36,390:INFO:create_model() successfully completed......................................
2024-05-27 12:54:36,538:INFO:SubProcess create_model() end ==================================
2024-05-27 12:54:36,539:INFO:Creating metrics dataframe
2024-05-27 12:54:36,551:INFO:Initializing Elastic Net
2024-05-27 12:54:36,552:INFO:Total runtime is 0.08348954916000366 minutes
2024-05-27 12:54:36,556:INFO:SubProcess create_model() called ==================================
2024-05-27 12:54:36,557:INFO:Initializing create_model()
2024-05-27 12:54:36,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B129E36E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:54:36,557:INFO:Checking exceptions
2024-05-27 12:54:36,557:INFO:Importing libraries
2024-05-27 12:54:36,557:INFO:Copying training dataset
2024-05-27 12:54:36,566:INFO:Defining folds
2024-05-27 12:54:36,566:INFO:Declaring metric variables
2024-05-27 12:54:36,570:INFO:Importing untrained model
2024-05-27 12:54:36,578:INFO:Elastic Net Imported successfully
2024-05-27 12:54:36,589:INFO:Starting cross validation
2024-05-27 12:54:36,591:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:54:37,236:INFO:Calculating mean and std
2024-05-27 12:54:37,238:INFO:Creating metrics dataframe
2024-05-27 12:54:37,239:INFO:Uploading results into container
2024-05-27 12:54:37,240:INFO:Uploading model into container now
2024-05-27 12:54:37,240:INFO:_master_model_container: 4
2024-05-27 12:54:37,240:INFO:_display_container: 2
2024-05-27 12:54:37,241:INFO:ElasticNet(random_state=42)
2024-05-27 12:54:37,241:INFO:create_model() successfully completed......................................
2024-05-27 12:54:37,393:INFO:SubProcess create_model() end ==================================
2024-05-27 12:54:37,393:INFO:Creating metrics dataframe
2024-05-27 12:54:37,408:INFO:Initializing Least Angle Regression
2024-05-27 12:54:37,408:INFO:Total runtime is 0.09775357643763224 minutes
2024-05-27 12:54:37,413:INFO:SubProcess create_model() called ==================================
2024-05-27 12:54:37,413:INFO:Initializing create_model()
2024-05-27 12:54:37,413:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B129E36E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:54:37,413:INFO:Checking exceptions
2024-05-27 12:54:37,413:INFO:Importing libraries
2024-05-27 12:54:37,413:INFO:Copying training dataset
2024-05-27 12:54:37,425:INFO:Defining folds
2024-05-27 12:54:37,425:INFO:Declaring metric variables
2024-05-27 12:54:37,429:INFO:Importing untrained model
2024-05-27 12:54:37,434:INFO:Least Angle Regression Imported successfully
2024-05-27 12:54:37,445:INFO:Starting cross validation
2024-05-27 12:54:37,447:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:54:38,103:INFO:Calculating mean and std
2024-05-27 12:54:38,104:INFO:Creating metrics dataframe
2024-05-27 12:54:38,106:INFO:Uploading results into container
2024-05-27 12:54:38,107:INFO:Uploading model into container now
2024-05-27 12:54:38,108:INFO:_master_model_container: 5
2024-05-27 12:54:38,108:INFO:_display_container: 2
2024-05-27 12:54:38,108:INFO:Lars(random_state=42)
2024-05-27 12:54:38,108:INFO:create_model() successfully completed......................................
2024-05-27 12:54:38,254:INFO:SubProcess create_model() end ==================================
2024-05-27 12:54:38,254:INFO:Creating metrics dataframe
2024-05-27 12:54:38,267:INFO:Initializing Lasso Least Angle Regression
2024-05-27 12:54:38,267:INFO:Total runtime is 0.11207857926686605 minutes
2024-05-27 12:54:38,272:INFO:SubProcess create_model() called ==================================
2024-05-27 12:54:38,273:INFO:Initializing create_model()
2024-05-27 12:54:38,273:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B129E36E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:54:38,273:INFO:Checking exceptions
2024-05-27 12:54:38,273:INFO:Importing libraries
2024-05-27 12:54:38,273:INFO:Copying training dataset
2024-05-27 12:54:38,279:INFO:Defining folds
2024-05-27 12:54:38,279:INFO:Declaring metric variables
2024-05-27 12:54:38,288:INFO:Importing untrained model
2024-05-27 12:54:38,295:INFO:Lasso Least Angle Regression Imported successfully
2024-05-27 12:54:38,305:INFO:Starting cross validation
2024-05-27 12:54:38,306:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:54:38,959:INFO:Calculating mean and std
2024-05-27 12:54:38,960:INFO:Creating metrics dataframe
2024-05-27 12:54:38,962:INFO:Uploading results into container
2024-05-27 12:54:38,963:INFO:Uploading model into container now
2024-05-27 12:54:38,964:INFO:_master_model_container: 6
2024-05-27 12:54:38,965:INFO:_display_container: 2
2024-05-27 12:54:38,965:INFO:LassoLars(random_state=42)
2024-05-27 12:54:38,966:INFO:create_model() successfully completed......................................
2024-05-27 12:54:39,113:INFO:SubProcess create_model() end ==================================
2024-05-27 12:54:39,113:INFO:Creating metrics dataframe
2024-05-27 12:54:39,123:INFO:Initializing Orthogonal Matching Pursuit
2024-05-27 12:54:39,124:INFO:Total runtime is 0.1263541102409363 minutes
2024-05-27 12:54:39,128:INFO:SubProcess create_model() called ==================================
2024-05-27 12:54:39,129:INFO:Initializing create_model()
2024-05-27 12:54:39,129:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B129E36E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:54:39,130:INFO:Checking exceptions
2024-05-27 12:54:39,130:INFO:Importing libraries
2024-05-27 12:54:39,130:INFO:Copying training dataset
2024-05-27 12:54:39,138:INFO:Defining folds
2024-05-27 12:54:39,138:INFO:Declaring metric variables
2024-05-27 12:54:39,142:INFO:Importing untrained model
2024-05-27 12:54:39,150:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-27 12:54:39,159:INFO:Starting cross validation
2024-05-27 12:54:39,161:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:54:39,812:INFO:Calculating mean and std
2024-05-27 12:54:39,814:INFO:Creating metrics dataframe
2024-05-27 12:54:39,816:INFO:Uploading results into container
2024-05-27 12:54:39,817:INFO:Uploading model into container now
2024-05-27 12:54:39,817:INFO:_master_model_container: 7
2024-05-27 12:54:39,817:INFO:_display_container: 2
2024-05-27 12:54:39,817:INFO:OrthogonalMatchingPursuit()
2024-05-27 12:54:39,817:INFO:create_model() successfully completed......................................
2024-05-27 12:54:39,962:INFO:SubProcess create_model() end ==================================
2024-05-27 12:54:39,962:INFO:Creating metrics dataframe
2024-05-27 12:54:39,976:INFO:Initializing Bayesian Ridge
2024-05-27 12:54:39,977:INFO:Total runtime is 0.14057720104853313 minutes
2024-05-27 12:54:40,010:INFO:SubProcess create_model() called ==================================
2024-05-27 12:54:40,010:INFO:Initializing create_model()
2024-05-27 12:54:40,011:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B129E36E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:54:40,011:INFO:Checking exceptions
2024-05-27 12:54:40,011:INFO:Importing libraries
2024-05-27 12:54:40,011:INFO:Copying training dataset
2024-05-27 12:54:40,026:INFO:Defining folds
2024-05-27 12:54:40,027:INFO:Declaring metric variables
2024-05-27 12:54:40,035:INFO:Importing untrained model
2024-05-27 12:54:40,041:INFO:Bayesian Ridge Imported successfully
2024-05-27 12:54:40,066:INFO:Starting cross validation
2024-05-27 12:54:40,069:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:54:40,822:INFO:Calculating mean and std
2024-05-27 12:54:40,823:INFO:Creating metrics dataframe
2024-05-27 12:54:40,825:INFO:Uploading results into container
2024-05-27 12:54:40,826:INFO:Uploading model into container now
2024-05-27 12:54:40,827:INFO:_master_model_container: 8
2024-05-27 12:54:40,827:INFO:_display_container: 2
2024-05-27 12:54:40,827:INFO:BayesianRidge()
2024-05-27 12:54:40,827:INFO:create_model() successfully completed......................................
2024-05-27 12:54:40,976:INFO:SubProcess create_model() end ==================================
2024-05-27 12:54:40,976:INFO:Creating metrics dataframe
2024-05-27 12:54:40,991:INFO:Initializing Passive Aggressive Regressor
2024-05-27 12:54:40,991:INFO:Total runtime is 0.15748484134674073 minutes
2024-05-27 12:54:40,995:INFO:SubProcess create_model() called ==================================
2024-05-27 12:54:40,995:INFO:Initializing create_model()
2024-05-27 12:54:40,996:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B129E36E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:54:40,996:INFO:Checking exceptions
2024-05-27 12:54:40,996:INFO:Importing libraries
2024-05-27 12:54:40,996:INFO:Copying training dataset
2024-05-27 12:54:41,005:INFO:Defining folds
2024-05-27 12:54:41,005:INFO:Declaring metric variables
2024-05-27 12:54:41,009:INFO:Importing untrained model
2024-05-27 12:54:41,017:INFO:Passive Aggressive Regressor Imported successfully
2024-05-27 12:54:41,029:INFO:Starting cross validation
2024-05-27 12:54:41,029:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:54:41,743:INFO:Calculating mean and std
2024-05-27 12:54:41,744:INFO:Creating metrics dataframe
2024-05-27 12:54:41,746:INFO:Uploading results into container
2024-05-27 12:54:41,747:INFO:Uploading model into container now
2024-05-27 12:54:41,747:INFO:_master_model_container: 9
2024-05-27 12:54:41,747:INFO:_display_container: 2
2024-05-27 12:54:41,748:INFO:PassiveAggressiveRegressor(random_state=42)
2024-05-27 12:54:41,748:INFO:create_model() successfully completed......................................
2024-05-27 12:54:41,892:INFO:SubProcess create_model() end ==================================
2024-05-27 12:54:41,892:INFO:Creating metrics dataframe
2024-05-27 12:54:41,905:INFO:Initializing Huber Regressor
2024-05-27 12:54:41,905:INFO:Total runtime is 0.17271260817845663 minutes
2024-05-27 12:54:41,910:INFO:SubProcess create_model() called ==================================
2024-05-27 12:54:41,910:INFO:Initializing create_model()
2024-05-27 12:54:41,911:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B129E36E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:54:41,911:INFO:Checking exceptions
2024-05-27 12:54:41,911:INFO:Importing libraries
2024-05-27 12:54:41,911:INFO:Copying training dataset
2024-05-27 12:54:41,921:INFO:Defining folds
2024-05-27 12:54:41,921:INFO:Declaring metric variables
2024-05-27 12:54:41,925:INFO:Importing untrained model
2024-05-27 12:54:41,934:INFO:Huber Regressor Imported successfully
2024-05-27 12:54:41,944:INFO:Starting cross validation
2024-05-27 12:54:41,946:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:54:42,690:INFO:Calculating mean and std
2024-05-27 12:54:42,692:INFO:Creating metrics dataframe
2024-05-27 12:54:42,693:INFO:Uploading results into container
2024-05-27 12:54:42,694:INFO:Uploading model into container now
2024-05-27 12:54:42,694:INFO:_master_model_container: 10
2024-05-27 12:54:42,695:INFO:_display_container: 2
2024-05-27 12:54:42,695:INFO:HuberRegressor()
2024-05-27 12:54:42,695:INFO:create_model() successfully completed......................................
2024-05-27 12:54:42,841:INFO:SubProcess create_model() end ==================================
2024-05-27 12:54:42,841:INFO:Creating metrics dataframe
2024-05-27 12:54:42,855:INFO:Initializing K Neighbors Regressor
2024-05-27 12:54:42,856:INFO:Total runtime is 0.18855655590693157 minutes
2024-05-27 12:54:42,862:INFO:SubProcess create_model() called ==================================
2024-05-27 12:54:42,862:INFO:Initializing create_model()
2024-05-27 12:54:42,862:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B129E36E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:54:42,862:INFO:Checking exceptions
2024-05-27 12:54:42,862:INFO:Importing libraries
2024-05-27 12:54:42,862:INFO:Copying training dataset
2024-05-27 12:54:42,871:INFO:Defining folds
2024-05-27 12:54:42,871:INFO:Declaring metric variables
2024-05-27 12:54:42,875:INFO:Importing untrained model
2024-05-27 12:54:42,883:INFO:K Neighbors Regressor Imported successfully
2024-05-27 12:54:42,892:INFO:Starting cross validation
2024-05-27 12:54:42,895:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:54:43,593:INFO:Calculating mean and std
2024-05-27 12:54:43,596:INFO:Creating metrics dataframe
2024-05-27 12:54:43,601:INFO:Uploading results into container
2024-05-27 12:54:43,604:INFO:Uploading model into container now
2024-05-27 12:54:43,605:INFO:_master_model_container: 11
2024-05-27 12:54:43,606:INFO:_display_container: 2
2024-05-27 12:54:43,606:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-27 12:54:43,607:INFO:create_model() successfully completed......................................
2024-05-27 12:54:43,761:INFO:SubProcess create_model() end ==================================
2024-05-27 12:54:43,761:INFO:Creating metrics dataframe
2024-05-27 12:54:43,776:INFO:Initializing Decision Tree Regressor
2024-05-27 12:54:43,776:INFO:Total runtime is 0.20389732917149864 minutes
2024-05-27 12:54:43,783:INFO:SubProcess create_model() called ==================================
2024-05-27 12:54:43,783:INFO:Initializing create_model()
2024-05-27 12:54:43,783:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B129E36E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:54:43,784:INFO:Checking exceptions
2024-05-27 12:54:43,784:INFO:Importing libraries
2024-05-27 12:54:43,784:INFO:Copying training dataset
2024-05-27 12:54:43,790:INFO:Defining folds
2024-05-27 12:54:43,790:INFO:Declaring metric variables
2024-05-27 12:54:43,794:INFO:Importing untrained model
2024-05-27 12:54:43,800:INFO:Decision Tree Regressor Imported successfully
2024-05-27 12:54:43,812:INFO:Starting cross validation
2024-05-27 12:54:43,814:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:54:44,515:INFO:Calculating mean and std
2024-05-27 12:54:44,516:INFO:Creating metrics dataframe
2024-05-27 12:54:44,518:INFO:Uploading results into container
2024-05-27 12:54:44,519:INFO:Uploading model into container now
2024-05-27 12:54:44,519:INFO:_master_model_container: 12
2024-05-27 12:54:44,519:INFO:_display_container: 2
2024-05-27 12:54:44,519:INFO:DecisionTreeRegressor(random_state=42)
2024-05-27 12:54:44,519:INFO:create_model() successfully completed......................................
2024-05-27 12:54:44,664:INFO:SubProcess create_model() end ==================================
2024-05-27 12:54:44,664:INFO:Creating metrics dataframe
2024-05-27 12:54:44,678:INFO:Initializing Random Forest Regressor
2024-05-27 12:54:44,679:INFO:Total runtime is 0.21895032326380415 minutes
2024-05-27 12:54:44,686:INFO:SubProcess create_model() called ==================================
2024-05-27 12:54:44,686:INFO:Initializing create_model()
2024-05-27 12:54:44,686:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B129E36E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:54:44,686:INFO:Checking exceptions
2024-05-27 12:54:44,686:INFO:Importing libraries
2024-05-27 12:54:44,686:INFO:Copying training dataset
2024-05-27 12:54:44,693:INFO:Defining folds
2024-05-27 12:54:44,694:INFO:Declaring metric variables
2024-05-27 12:54:44,702:INFO:Importing untrained model
2024-05-27 12:54:44,729:INFO:Random Forest Regressor Imported successfully
2024-05-27 12:54:44,751:INFO:Starting cross validation
2024-05-27 12:54:44,753:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:54:47,985:INFO:Calculating mean and std
2024-05-27 12:54:47,987:INFO:Creating metrics dataframe
2024-05-27 12:54:47,989:INFO:Uploading results into container
2024-05-27 12:54:47,990:INFO:Uploading model into container now
2024-05-27 12:54:47,990:INFO:_master_model_container: 13
2024-05-27 12:54:47,990:INFO:_display_container: 2
2024-05-27 12:54:47,991:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:54:47,991:INFO:create_model() successfully completed......................................
2024-05-27 12:54:48,141:INFO:SubProcess create_model() end ==================================
2024-05-27 12:54:48,141:INFO:Creating metrics dataframe
2024-05-27 12:54:48,153:INFO:Initializing Extra Trees Regressor
2024-05-27 12:54:48,153:INFO:Total runtime is 0.27683870395024623 minutes
2024-05-27 12:54:48,162:INFO:SubProcess create_model() called ==================================
2024-05-27 12:54:48,163:INFO:Initializing create_model()
2024-05-27 12:54:48,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B129E36E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:54:48,163:INFO:Checking exceptions
2024-05-27 12:54:48,164:INFO:Importing libraries
2024-05-27 12:54:48,164:INFO:Copying training dataset
2024-05-27 12:54:48,172:INFO:Defining folds
2024-05-27 12:54:48,172:INFO:Declaring metric variables
2024-05-27 12:54:48,176:INFO:Importing untrained model
2024-05-27 12:54:48,183:INFO:Extra Trees Regressor Imported successfully
2024-05-27 12:54:48,192:INFO:Starting cross validation
2024-05-27 12:54:48,194:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:54:50,456:INFO:Calculating mean and std
2024-05-27 12:54:50,457:INFO:Creating metrics dataframe
2024-05-27 12:54:50,461:INFO:Uploading results into container
2024-05-27 12:54:50,462:INFO:Uploading model into container now
2024-05-27 12:54:50,463:INFO:_master_model_container: 14
2024-05-27 12:54:50,464:INFO:_display_container: 2
2024-05-27 12:54:50,465:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:54:50,465:INFO:create_model() successfully completed......................................
2024-05-27 12:54:50,614:INFO:SubProcess create_model() end ==================================
2024-05-27 12:54:50,614:INFO:Creating metrics dataframe
2024-05-27 12:54:50,628:INFO:Initializing AdaBoost Regressor
2024-05-27 12:54:50,629:INFO:Total runtime is 0.3181095520655315 minutes
2024-05-27 12:54:50,632:INFO:SubProcess create_model() called ==================================
2024-05-27 12:54:50,633:INFO:Initializing create_model()
2024-05-27 12:54:50,633:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B129E36E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:54:50,633:INFO:Checking exceptions
2024-05-27 12:54:50,633:INFO:Importing libraries
2024-05-27 12:54:50,633:INFO:Copying training dataset
2024-05-27 12:54:50,644:INFO:Defining folds
2024-05-27 12:54:50,644:INFO:Declaring metric variables
2024-05-27 12:54:50,653:INFO:Importing untrained model
2024-05-27 12:54:50,659:INFO:AdaBoost Regressor Imported successfully
2024-05-27 12:54:50,671:INFO:Starting cross validation
2024-05-27 12:54:50,672:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:54:52,034:INFO:Calculating mean and std
2024-05-27 12:54:52,036:INFO:Creating metrics dataframe
2024-05-27 12:54:52,040:INFO:Uploading results into container
2024-05-27 12:54:52,042:INFO:Uploading model into container now
2024-05-27 12:54:52,044:INFO:_master_model_container: 15
2024-05-27 12:54:52,044:INFO:_display_container: 2
2024-05-27 12:54:52,044:INFO:AdaBoostRegressor(random_state=42)
2024-05-27 12:54:52,045:INFO:create_model() successfully completed......................................
2024-05-27 12:54:52,215:INFO:SubProcess create_model() end ==================================
2024-05-27 12:54:52,215:INFO:Creating metrics dataframe
2024-05-27 12:54:52,228:INFO:Initializing Gradient Boosting Regressor
2024-05-27 12:54:52,229:INFO:Total runtime is 0.3447591741879782 minutes
2024-05-27 12:54:52,232:INFO:SubProcess create_model() called ==================================
2024-05-27 12:54:52,232:INFO:Initializing create_model()
2024-05-27 12:54:52,233:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B129E36E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:54:52,233:INFO:Checking exceptions
2024-05-27 12:54:52,233:INFO:Importing libraries
2024-05-27 12:54:52,233:INFO:Copying training dataset
2024-05-27 12:54:52,242:INFO:Defining folds
2024-05-27 12:54:52,242:INFO:Declaring metric variables
2024-05-27 12:54:52,246:INFO:Importing untrained model
2024-05-27 12:54:52,252:INFO:Gradient Boosting Regressor Imported successfully
2024-05-27 12:54:52,260:INFO:Starting cross validation
2024-05-27 12:54:52,262:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:54:54,008:INFO:Calculating mean and std
2024-05-27 12:54:54,010:INFO:Creating metrics dataframe
2024-05-27 12:54:54,011:INFO:Uploading results into container
2024-05-27 12:54:54,012:INFO:Uploading model into container now
2024-05-27 12:54:54,013:INFO:_master_model_container: 16
2024-05-27 12:54:54,013:INFO:_display_container: 2
2024-05-27 12:54:54,013:INFO:GradientBoostingRegressor(random_state=42)
2024-05-27 12:54:54,013:INFO:create_model() successfully completed......................................
2024-05-27 12:54:54,155:INFO:SubProcess create_model() end ==================================
2024-05-27 12:54:54,156:INFO:Creating metrics dataframe
2024-05-27 12:54:54,184:INFO:Initializing Light Gradient Boosting Machine
2024-05-27 12:54:54,184:INFO:Total runtime is 0.37735366026560474 minutes
2024-05-27 12:54:54,190:INFO:SubProcess create_model() called ==================================
2024-05-27 12:54:54,191:INFO:Initializing create_model()
2024-05-27 12:54:54,191:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B129E36E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:54:54,191:INFO:Checking exceptions
2024-05-27 12:54:54,191:INFO:Importing libraries
2024-05-27 12:54:54,191:INFO:Copying training dataset
2024-05-27 12:54:54,204:INFO:Defining folds
2024-05-27 12:54:54,205:INFO:Declaring metric variables
2024-05-27 12:54:54,212:INFO:Importing untrained model
2024-05-27 12:54:54,218:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 12:54:54,230:INFO:Starting cross validation
2024-05-27 12:54:54,232:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:54:56,454:INFO:Calculating mean and std
2024-05-27 12:54:56,457:INFO:Creating metrics dataframe
2024-05-27 12:54:56,460:INFO:Uploading results into container
2024-05-27 12:54:56,461:INFO:Uploading model into container now
2024-05-27 12:54:56,462:INFO:_master_model_container: 17
2024-05-27 12:54:56,462:INFO:_display_container: 2
2024-05-27 12:54:56,463:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:54:56,463:INFO:create_model() successfully completed......................................
2024-05-27 12:54:56,638:INFO:SubProcess create_model() end ==================================
2024-05-27 12:54:56,638:INFO:Creating metrics dataframe
2024-05-27 12:54:56,652:INFO:Initializing Dummy Regressor
2024-05-27 12:54:56,653:INFO:Total runtime is 0.4185057520866395 minutes
2024-05-27 12:54:56,656:INFO:SubProcess create_model() called ==================================
2024-05-27 12:54:56,656:INFO:Initializing create_model()
2024-05-27 12:54:56,657:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B129E36E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:54:56,657:INFO:Checking exceptions
2024-05-27 12:54:56,657:INFO:Importing libraries
2024-05-27 12:54:56,657:INFO:Copying training dataset
2024-05-27 12:54:56,682:INFO:Defining folds
2024-05-27 12:54:56,683:INFO:Declaring metric variables
2024-05-27 12:54:56,693:INFO:Importing untrained model
2024-05-27 12:54:56,697:INFO:Dummy Regressor Imported successfully
2024-05-27 12:54:56,707:INFO:Starting cross validation
2024-05-27 12:54:56,708:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:54:57,424:INFO:Calculating mean and std
2024-05-27 12:54:57,426:INFO:Creating metrics dataframe
2024-05-27 12:54:57,429:INFO:Uploading results into container
2024-05-27 12:54:57,429:INFO:Uploading model into container now
2024-05-27 12:54:57,430:INFO:_master_model_container: 18
2024-05-27 12:54:57,430:INFO:_display_container: 2
2024-05-27 12:54:57,431:INFO:DummyRegressor()
2024-05-27 12:54:57,431:INFO:create_model() successfully completed......................................
2024-05-27 12:54:57,575:INFO:SubProcess create_model() end ==================================
2024-05-27 12:54:57,576:INFO:Creating metrics dataframe
2024-05-27 12:54:57,607:INFO:Initializing create_model()
2024-05-27 12:54:57,607:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:54:57,607:INFO:Checking exceptions
2024-05-27 12:54:57,610:INFO:Importing libraries
2024-05-27 12:54:57,610:INFO:Copying training dataset
2024-05-27 12:54:57,618:INFO:Defining folds
2024-05-27 12:54:57,618:INFO:Declaring metric variables
2024-05-27 12:54:57,618:INFO:Importing untrained model
2024-05-27 12:54:57,618:INFO:Declaring custom model
2024-05-27 12:54:57,619:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 12:54:57,620:INFO:Cross validation set to False
2024-05-27 12:54:57,620:INFO:Fitting Model
2024-05-27 12:54:57,804:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000583 seconds.
2024-05-27 12:54:57,804:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-27 12:54:57,804:INFO:[LightGBM] [Info] Total Bins 1660
2024-05-27 12:54:57,805:INFO:[LightGBM] [Info] Number of data points in the train set: 910, number of used features: 15
2024-05-27 12:54:57,806:INFO:[LightGBM] [Info] Start training from score -0.029448
2024-05-27 12:54:57,899:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:54:57,900:INFO:create_model() successfully completed......................................
2024-05-27 12:54:58,132:INFO:_master_model_container: 18
2024-05-27 12:54:58,133:INFO:_display_container: 2
2024-05-27 12:54:58,133:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:54:58,134:INFO:compare_models() successfully completed......................................
2024-05-27 12:54:58,196:INFO:Initializing plot_model()
2024-05-27 12:54:58,197:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:54:58,197:INFO:Checking exceptions
2024-05-27 12:54:58,209:INFO:Preloading libraries
2024-05-27 12:54:58,220:INFO:Copying training dataset
2024-05-27 12:54:58,220:INFO:Plot type: feature
2024-05-27 12:54:58,221:WARNING:No coef_ found. Trying feature_importances_
2024-05-27 12:54:58,467:INFO:Visual Rendered Successfully
2024-05-27 12:54:58,616:INFO:plot_model() successfully completed......................................
2024-05-27 12:54:58,618:INFO:Initializing plot_model()
2024-05-27 12:54:58,618:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=error, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:54:58,618:INFO:Checking exceptions
2024-05-27 12:54:58,625:INFO:Preloading libraries
2024-05-27 12:54:58,634:INFO:Copying training dataset
2024-05-27 12:54:58,634:INFO:Plot type: error
2024-05-27 12:54:58,808:INFO:Fitting Model
2024-05-27 12:54:58,809:INFO:Scoring test/hold-out set
2024-05-27 12:54:59,095:INFO:Visual Rendered Successfully
2024-05-27 12:54:59,257:INFO:plot_model() successfully completed......................................
2024-05-27 12:54:59,258:INFO:Initializing plot_model()
2024-05-27 12:54:59,258:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=residuals, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:54:59,259:INFO:Checking exceptions
2024-05-27 12:54:59,266:INFO:Preloading libraries
2024-05-27 12:54:59,277:INFO:Copying training dataset
2024-05-27 12:54:59,277:INFO:Plot type: residuals
2024-05-27 12:54:59,484:INFO:Fitting Model
2024-05-27 12:54:59,572:INFO:Scoring test/hold-out set
2024-05-27 12:55:00,172:INFO:Visual Rendered Successfully
2024-05-27 12:55:00,455:INFO:plot_model() successfully completed......................................
2024-05-27 12:55:00,492:INFO:Initializing evaluate_model()
2024-05-27 12:55:00,492:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-27 12:55:00,511:INFO:Initializing plot_model()
2024-05-27 12:55:00,511:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-27 12:55:00,511:INFO:Checking exceptions
2024-05-27 12:55:00,517:INFO:Preloading libraries
2024-05-27 12:55:00,530:INFO:Copying training dataset
2024-05-27 12:55:00,531:INFO:Plot type: pipeline
2024-05-27 12:55:00,717:INFO:Visual Rendered Successfully
2024-05-27 12:55:00,863:INFO:plot_model() successfully completed......................................
2024-05-27 12:55:00,905:INFO:Initializing tune_model()
2024-05-27 12:55:00,906:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-05-27 12:55:00,906:INFO:Checking exceptions
2024-05-27 12:55:00,933:INFO:Copying training dataset
2024-05-27 12:55:00,945:INFO:Checking base model
2024-05-27 12:55:00,945:INFO:Base model : Light Gradient Boosting Machine
2024-05-27 12:55:00,955:INFO:Declaring metric variables
2024-05-27 12:55:00,989:INFO:Defining Hyperparameters
2024-05-27 12:55:01,252:INFO:Tuning with n_jobs=-1
2024-05-27 12:55:01,252:INFO:Initializing RandomizedSearchCV
2024-05-27 12:55:16,666:INFO:best_params: {'actual_estimator__reg_lambda': 5, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 100, 'actual_estimator__min_split_gain': 0.6, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.8}
2024-05-27 12:55:16,668:INFO:Hyperparameter search completed
2024-05-27 12:55:16,669:INFO:SubProcess create_model() called ==================================
2024-05-27 12:55:16,670:INFO:Initializing create_model()
2024-05-27 12:55:16,670:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11802C290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 5, 'reg_alpha': 0.001, 'num_leaves': 30, 'n_estimators': 100, 'min_split_gain': 0.6, 'min_child_samples': 6, 'learning_rate': 0.2, 'feature_fraction': 0.8, 'bagging_freq': 3, 'bagging_fraction': 0.8})
2024-05-27 12:55:16,670:INFO:Checking exceptions
2024-05-27 12:55:16,671:INFO:Importing libraries
2024-05-27 12:55:16,671:INFO:Copying training dataset
2024-05-27 12:55:16,685:INFO:Defining folds
2024-05-27 12:55:16,685:INFO:Declaring metric variables
2024-05-27 12:55:16,692:INFO:Importing untrained model
2024-05-27 12:55:16,692:INFO:Declaring custom model
2024-05-27 12:55:16,702:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 12:55:16,716:INFO:Starting cross validation
2024-05-27 12:55:16,718:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:55:17,914:INFO:Calculating mean and std
2024-05-27 12:55:17,917:INFO:Creating metrics dataframe
2024-05-27 12:55:17,927:INFO:Finalizing model
2024-05-27 12:55:18,179:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-05-27 12:55:18,180:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-05-27 12:55:18,180:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-05-27 12:55:18,182:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-05-27 12:55:18,182:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-05-27 12:55:18,182:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-05-27 12:55:18,183:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.
2024-05-27 12:55:18,183:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-27 12:55:18,183:INFO:[LightGBM] [Info] Total Bins 1660
2024-05-27 12:55:18,184:INFO:[LightGBM] [Info] Number of data points in the train set: 910, number of used features: 15
2024-05-27 12:55:18,184:INFO:[LightGBM] [Info] Start training from score -0.029448
2024-05-27 12:55:18,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,202:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,202:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,202:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,205:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,205:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,205:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,206:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,206:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,206:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,207:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,207:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,207:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,208:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,211:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,211:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,211:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,212:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,212:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,212:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,214:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,214:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,214:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,215:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,215:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,215:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,216:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,216:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,216:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,218:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,218:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,221:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,221:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,222:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,222:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,222:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,222:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,225:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,225:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,225:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 12:55:18,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 12:55:18,238:INFO:Uploading results into container
2024-05-27 12:55:18,240:INFO:Uploading model into container now
2024-05-27 12:55:18,241:INFO:_master_model_container: 19
2024-05-27 12:55:18,242:INFO:_display_container: 2
2024-05-27 12:55:18,243:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=3, feature_fraction=0.8,
              learning_rate=0.2, min_child_samples=6, min_split_gain=0.6,
              n_jobs=-1, num_leaves=30, random_state=42, reg_alpha=0.001,
              reg_lambda=5)
2024-05-27 12:55:18,243:INFO:create_model() successfully completed......................................
2024-05-27 12:55:18,432:INFO:SubProcess create_model() end ==================================
2024-05-27 12:55:18,432:INFO:choose_better activated
2024-05-27 12:55:18,437:INFO:SubProcess create_model() called ==================================
2024-05-27 12:55:18,438:INFO:Initializing create_model()
2024-05-27 12:55:18,438:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:55:18,438:INFO:Checking exceptions
2024-05-27 12:55:18,440:INFO:Importing libraries
2024-05-27 12:55:18,440:INFO:Copying training dataset
2024-05-27 12:55:18,449:INFO:Defining folds
2024-05-27 12:55:18,449:INFO:Declaring metric variables
2024-05-27 12:55:18,449:INFO:Importing untrained model
2024-05-27 12:55:18,449:INFO:Declaring custom model
2024-05-27 12:55:18,450:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 12:55:18,450:INFO:Starting cross validation
2024-05-27 12:55:18,451:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:55:20,768:INFO:Calculating mean and std
2024-05-27 12:55:20,769:INFO:Creating metrics dataframe
2024-05-27 12:55:20,772:INFO:Finalizing model
2024-05-27 12:55:21,024:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000311 seconds.
2024-05-27 12:55:21,024:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-27 12:55:21,025:INFO:[LightGBM] [Info] Total Bins 1660
2024-05-27 12:55:21,025:INFO:[LightGBM] [Info] Number of data points in the train set: 910, number of used features: 15
2024-05-27 12:55:21,025:INFO:[LightGBM] [Info] Start training from score -0.029448
2024-05-27 12:55:21,112:INFO:Uploading results into container
2024-05-27 12:55:21,113:INFO:Uploading model into container now
2024-05-27 12:55:21,114:INFO:_master_model_container: 20
2024-05-27 12:55:21,114:INFO:_display_container: 3
2024-05-27 12:55:21,115:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:55:21,115:INFO:create_model() successfully completed......................................
2024-05-27 12:55:21,312:INFO:SubProcess create_model() end ==================================
2024-05-27 12:55:21,314:INFO:LGBMRegressor(n_jobs=-1, random_state=42) result for R2 is 0.8022
2024-05-27 12:55:21,315:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=3, feature_fraction=0.8,
              learning_rate=0.2, min_child_samples=6, min_split_gain=0.6,
              n_jobs=-1, num_leaves=30, random_state=42, reg_alpha=0.001,
              reg_lambda=5) result for R2 is 0.7718
2024-05-27 12:55:21,315:INFO:LGBMRegressor(n_jobs=-1, random_state=42) is best model
2024-05-27 12:55:21,316:INFO:choose_better completed
2024-05-27 12:55:21,316:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-27 12:55:21,331:INFO:_master_model_container: 20
2024-05-27 12:55:21,331:INFO:_display_container: 2
2024-05-27 12:55:21,332:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 12:55:21,332:INFO:tune_model() successfully completed......................................
2024-05-27 12:55:21,526:INFO:Initializing plot_model()
2024-05-27 12:55:21,526:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:55:21,526:INFO:Checking exceptions
2024-05-27 12:55:21,533:INFO:Preloading libraries
2024-05-27 12:55:21,547:INFO:Copying training dataset
2024-05-27 12:55:21,547:INFO:Plot type: feature
2024-05-27 12:55:21,548:WARNING:No coef_ found. Trying feature_importances_
2024-05-27 12:55:21,797:INFO:Visual Rendered Successfully
2024-05-27 12:55:21,964:INFO:plot_model() successfully completed......................................
2024-05-27 12:55:21,966:INFO:Initializing plot_model()
2024-05-27 12:55:21,966:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=error, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:55:21,966:INFO:Checking exceptions
2024-05-27 12:55:21,974:INFO:Preloading libraries
2024-05-27 12:55:21,984:INFO:Copying training dataset
2024-05-27 12:55:21,984:INFO:Plot type: error
2024-05-27 12:55:22,161:INFO:Fitting Model
2024-05-27 12:55:22,163:INFO:Scoring test/hold-out set
2024-05-27 12:55:22,462:INFO:Visual Rendered Successfully
2024-05-27 12:55:22,635:INFO:plot_model() successfully completed......................................
2024-05-27 12:55:22,637:INFO:Initializing plot_model()
2024-05-27 12:55:22,637:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=residuals, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 12:55:22,637:INFO:Checking exceptions
2024-05-27 12:55:22,647:INFO:Preloading libraries
2024-05-27 12:55:22,657:INFO:Copying training dataset
2024-05-27 12:55:22,657:INFO:Plot type: residuals
2024-05-27 12:55:22,861:INFO:Fitting Model
2024-05-27 12:55:22,949:INFO:Scoring test/hold-out set
2024-05-27 12:55:23,423:INFO:Visual Rendered Successfully
2024-05-27 12:55:23,592:INFO:plot_model() successfully completed......................................
2024-05-27 12:55:23,611:INFO:Initializing evaluate_model()
2024-05-27 12:55:23,612:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-27 12:55:23,626:INFO:Initializing plot_model()
2024-05-27 12:55:23,626:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2325D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-27 12:55:23,626:INFO:Checking exceptions
2024-05-27 12:55:23,633:INFO:Preloading libraries
2024-05-27 12:55:23,646:INFO:Copying training dataset
2024-05-27 12:55:23,647:INFO:Plot type: pipeline
2024-05-27 12:55:23,837:INFO:Visual Rendered Successfully
2024-05-27 12:55:24,003:INFO:plot_model() successfully completed......................................
2024-05-27 21:08:35,234:WARNING:C:\Users\muril\AppData\Local\Temp\ipykernel_8820\4212681043.py:2: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
  plt.style.use('seaborn-darkgrid')

2024-05-27 21:10:16,508:WARNING:C:\Users\muril\AppData\Local\Temp\ipykernel_8820\1066813642.py:3: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_clean[numeric_columns] = scaler.fit_transform(df_clean[numeric_columns])

2024-05-27 21:11:03,878:WARNING:c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
141 fits failed out of a total of 300.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
57 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 1467, in wrapper
    estimator._validate_params()
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.

--------------------------------------------------------------------------------
84 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 1467, in wrapper
    estimator._validate_params()
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-27 21:11:03,890:WARNING:c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.73690131 0.7723179  0.76899183        nan        nan 0.70603466
 0.76899183        nan 0.72649309 0.77494848        nan        nan
        nan 0.76775927 0.70724616 0.64097707        nan 0.7714591
        nan        nan 0.69886104        nan        nan        nan
 0.69316    0.74093953        nan        nan        nan 0.77852071
        nan 0.72663432 0.73795808 0.69886104        nan        nan
        nan        nan 0.77254916        nan 0.6953924         nan
        nan        nan 0.76856778 0.69167232        nan 0.70716815
 0.77776253 0.77140226 0.75186111        nan 0.74493442        nan
        nan 0.70455147 0.72045513        nan        nan        nan
        nan        nan 0.70401667        nan        nan 0.77201249
        nan        nan 0.77220018        nan 0.72675909 0.74093953
 0.77889893        nan        nan 0.70631594        nan 0.74838051
 0.66321771 0.70773896 0.72697562 0.72675909 0.69642805        nan
 0.72045513 0.69886104        nan        nan 0.74838051 0.76027421
 0.75135719 0.70628675        nan 0.72663432        nan 0.77178874
 0.72663432 0.7723179  0.75135616        nan]
  warnings.warn(

2024-05-27 21:11:43,061:WARNING:c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
141 fits failed out of a total of 300.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
61 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 1467, in wrapper
    estimator._validate_params()
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.

--------------------------------------------------------------------------------
80 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 1467, in wrapper
    estimator._validate_params()
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-27 21:11:43,081:WARNING:c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.75585937 0.79038632 0.77436615        nan        nan 0.74595153
 0.77436615        nan 0.76142618 0.78462259        nan        nan
        nan 0.78063503 0.74489877 0.72712048        nan 0.78613949
        nan        nan 0.74547562        nan        nan        nan
 0.73151238 0.77264907        nan        nan        nan 0.79116805
        nan 0.76059954 0.75986035 0.74547562        nan        nan
        nan        nan 0.78932932        nan 0.73916425        nan
        nan        nan 0.7793353  0.7253631         nan 0.74008125
 0.79189862 0.78684028 0.77842616        nan 0.75567687        nan
        nan 0.74347782 0.75170118        nan        nan        nan
        nan        nan 0.73945853        nan        nan 0.78938319
        nan        nan 0.78975469        nan 0.76005707 0.77264907
 0.790783          nan        nan 0.74597706        nan 0.77582515
 0.73262594 0.74496854 0.75984297 0.76005707 0.7397241         nan
 0.75170118 0.74547562        nan        nan 0.77582515 0.77261023
 0.778412   0.74471839        nan 0.76059954        nan 0.78365244
 0.76059954 0.79038632 0.77840329        nan]
  warnings.warn(

2024-05-27 21:13:17,271:INFO:PyCaret RegressionExperiment
2024-05-27 21:13:17,272:INFO:Logging name: reg-default-name
2024-05-27 21:13:17,273:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-27 21:13:17,273:INFO:version 3.3.0
2024-05-27 21:13:17,273:INFO:Initializing setup()
2024-05-27 21:13:17,273:INFO:self.USI: 4d91
2024-05-27 21:13:17,273:INFO:self._variable_keys: {'exp_name_log', 'X_train', 'logging_param', 'gpu_n_jobs_param', 'y_train', 'idx', 'gpu_param', 'y', '_ml_usecase', 'html_param', 'fold_generator', 'n_jobs_param', 'exp_id', 'fold_groups_param', 'data', 'seed', 'X', 'y_test', 'target_param', 'pipeline', '_available_plots', 'fold_shuffle_param', 'transform_target_param', 'log_plots_param', 'X_test', 'memory', 'USI'}
2024-05-27 21:13:17,274:INFO:Checking environment
2024-05-27 21:13:17,275:INFO:python_version: 3.11.5
2024-05-27 21:13:17,275:INFO:python_build: ('tags/v3.11.5:cce6ba9', 'Aug 24 2023 14:38:34')
2024-05-27 21:13:17,277:INFO:machine: AMD64
2024-05-27 21:13:17,277:INFO:platform: Windows-10-10.0.22631-SP0
2024-05-27 21:13:17,299:INFO:Memory: svmem(total=8459792384, available=804225024, percent=90.5, used=7655567360, free=804225024)
2024-05-27 21:13:17,300:INFO:Physical Core: 4
2024-05-27 21:13:17,300:INFO:Logical Core: 8
2024-05-27 21:13:17,302:INFO:Checking libraries
2024-05-27 21:13:17,303:INFO:System:
2024-05-27 21:13:17,303:INFO:    python: 3.11.5 (tags/v3.11.5:cce6ba9, Aug 24 2023, 14:38:34) [MSC v.1936 64 bit (AMD64)]
2024-05-27 21:13:17,303:INFO:executable: c:\Users\muril\AppData\Local\Programs\Python\Python311\python.exe
2024-05-27 21:13:17,303:INFO:   machine: Windows-10-10.0.22631-SP0
2024-05-27 21:13:17,303:INFO:PyCaret required dependencies:
2024-05-27 21:13:17,323:INFO:                 pip: 24.0
2024-05-27 21:13:17,323:INFO:          setuptools: 68.1.2
2024-05-27 21:13:17,324:INFO:             pycaret: 3.3.0
2024-05-27 21:13:17,324:INFO:             IPython: 8.14.0
2024-05-27 21:13:17,324:INFO:          ipywidgets: 8.1.0
2024-05-27 21:13:17,324:INFO:                tqdm: 4.66.1
2024-05-27 21:13:17,324:INFO:               numpy: 1.26.4
2024-05-27 21:13:17,324:INFO:              pandas: 2.0.2
2024-05-27 21:13:17,324:INFO:              jinja2: 3.1.2
2024-05-27 21:13:17,325:INFO:               scipy: 1.10.1
2024-05-27 21:13:17,325:INFO:              joblib: 1.2.0
2024-05-27 21:13:17,325:INFO:             sklearn: 1.4.1.post1
2024-05-27 21:13:17,325:INFO:                pyod: 1.1.3
2024-05-27 21:13:17,325:INFO:            imblearn: 0.12.1
2024-05-27 21:13:17,325:INFO:   category_encoders: 2.6.3
2024-05-27 21:13:17,325:INFO:            lightgbm: 4.3.0
2024-05-27 21:13:17,325:INFO:               numba: 0.59.1
2024-05-27 21:13:17,325:INFO:            requests: 2.31.0
2024-05-27 21:13:17,325:INFO:          matplotlib: 3.7.1
2024-05-27 21:13:17,325:INFO:          scikitplot: 0.3.7
2024-05-27 21:13:17,326:INFO:         yellowbrick: 1.5
2024-05-27 21:13:17,326:INFO:              plotly: 5.18.0
2024-05-27 21:13:17,326:INFO:    plotly-resampler: Not installed
2024-05-27 21:13:17,326:INFO:             kaleido: 0.2.1
2024-05-27 21:13:17,326:INFO:           schemdraw: 0.15
2024-05-27 21:13:17,326:INFO:         statsmodels: 0.14.1
2024-05-27 21:13:17,326:INFO:              sktime: 0.28.0
2024-05-27 21:13:17,326:INFO:               tbats: 1.1.3
2024-05-27 21:13:17,326:INFO:            pmdarima: 2.0.4
2024-05-27 21:13:17,326:INFO:              psutil: 5.9.5
2024-05-27 21:13:17,326:INFO:          markupsafe: 2.1.2
2024-05-27 21:13:17,326:INFO:             pickle5: Not installed
2024-05-27 21:13:17,326:INFO:         cloudpickle: 3.0.0
2024-05-27 21:13:17,327:INFO:         deprecation: 2.1.0
2024-05-27 21:13:17,327:INFO:              xxhash: 3.4.1
2024-05-27 21:13:17,327:INFO:           wurlitzer: Not installed
2024-05-27 21:13:17,327:INFO:PyCaret optional dependencies:
2024-05-27 21:13:17,327:INFO:                shap: Not installed
2024-05-27 21:13:17,327:INFO:           interpret: Not installed
2024-05-27 21:13:17,327:INFO:                umap: Not installed
2024-05-27 21:13:17,328:INFO:     ydata_profiling: Not installed
2024-05-27 21:13:17,328:INFO:  explainerdashboard: Not installed
2024-05-27 21:13:17,328:INFO:             autoviz: Not installed
2024-05-27 21:13:17,328:INFO:           fairlearn: Not installed
2024-05-27 21:13:17,328:INFO:          deepchecks: Not installed
2024-05-27 21:13:17,328:INFO:             xgboost: Not installed
2024-05-27 21:13:17,328:INFO:            catboost: Not installed
2024-05-27 21:13:17,330:INFO:              kmodes: Not installed
2024-05-27 21:13:17,330:INFO:             mlxtend: Not installed
2024-05-27 21:13:17,330:INFO:       statsforecast: Not installed
2024-05-27 21:13:17,330:INFO:        tune_sklearn: Not installed
2024-05-27 21:13:17,330:INFO:                 ray: Not installed
2024-05-27 21:13:17,330:INFO:            hyperopt: Not installed
2024-05-27 21:13:17,330:INFO:              optuna: Not installed
2024-05-27 21:13:17,330:INFO:               skopt: Not installed
2024-05-27 21:13:17,330:INFO:              mlflow: Not installed
2024-05-27 21:13:17,330:INFO:              gradio: Not installed
2024-05-27 21:13:17,330:INFO:             fastapi: Not installed
2024-05-27 21:13:17,330:INFO:             uvicorn: Not installed
2024-05-27 21:13:17,331:INFO:              m2cgen: Not installed
2024-05-27 21:13:17,331:INFO:           evidently: Not installed
2024-05-27 21:13:17,331:INFO:               fugue: Not installed
2024-05-27 21:13:17,331:INFO:           streamlit: 1.28.1
2024-05-27 21:13:17,331:INFO:             prophet: Not installed
2024-05-27 21:13:17,331:INFO:None
2024-05-27 21:13:17,334:INFO:Set up data.
2024-05-27 21:13:17,438:INFO:Set up folding strategy.
2024-05-27 21:13:17,439:INFO:Set up train/test split.
2024-05-27 21:13:17,466:INFO:Set up index.
2024-05-27 21:13:17,468:INFO:Assigning column types.
2024-05-27 21:13:17,501:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-27 21:13:17,514:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-27 21:13:17,532:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-27 21:13:17,542:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 21:13:17,803:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 21:13:17,920:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 21:13:17,936:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:17,939:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:17,943:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-27 21:13:17,952:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-27 21:13:17,965:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 21:13:18,128:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 21:13:18,284:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 21:13:18,287:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:18,288:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:18,289:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-27 21:13:18,301:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-27 21:13:18,311:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 21:13:18,745:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 21:13:18,886:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 21:13:18,889:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:18,889:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:18,901:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-27 21:13:18,909:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 21:13:19,059:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 21:13:19,194:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 21:13:19,196:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:19,196:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:19,197:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-27 21:13:19,221:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 21:13:19,367:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 21:13:19,473:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 21:13:19,474:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:19,475:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:19,497:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-27 21:13:19,610:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 21:13:19,714:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 21:13:19,714:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:19,715:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:19,716:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-27 21:13:19,838:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 21:13:19,930:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 21:13:19,931:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:19,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:20,048:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 21:13:20,122:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 21:13:20,123:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:20,123:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:20,124:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-27 21:13:20,241:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 21:13:20,312:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:20,312:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:20,444:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-27 21:13:20,543:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:20,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:20,544:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-27 21:13:20,754:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:20,754:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:20,920:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:20,921:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:20,956:INFO:Preparing preprocessing pipeline...
2024-05-27 21:13:20,958:INFO:Set up simple imputation.
2024-05-27 21:13:20,965:INFO:Set up removing outliers.
2024-05-27 21:13:20,966:INFO:Set up feature normalization.
2024-05-27 21:13:21,132:INFO:Finished creating preprocessing pipeline.
2024-05-27 21:13:21,159:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\muril\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['num_bed', 'num_bath',
                                             'size_house', 'size_lot',
                                             'num_floors', 'is_waterfront',
                                             'condition', 'size_basement',
                                             'year_built', 'renovation_date',
                                             'zip', 'latitude', 'longitude',
                                             'avg_size_neighbor_houses',
                                             'avg_size_neighbor_lot',
                                             'zip_prefix_3', 'zip_prefix_4'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2024-05-27 21:13:21,159:INFO:Creating final display dataframe.
2024-05-27 21:13:21,432:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target             price
2                   Target type        Regression
3           Original data shape        (1370, 18)
4        Transformed data shape        (1322, 18)
5   Transformed train set shape         (910, 18)
6    Transformed test set shape         (412, 18)
7              Numeric features                17
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12              Remove outliers              True
13           Outliers threshold              0.05
14                    Normalize              True
15             Normalize method            zscore
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              4d91
2024-05-27 21:13:21,807:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:21,809:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:21,962:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:21,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 21:13:21,979:WARNING:c:\Users\muril\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-05-27 21:13:21,980:INFO:setup() successfully completed in 4.89s...............
2024-05-27 21:13:22,012:INFO:Initializing compare_models()
2024-05-27 21:13:22,012:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-05-27 21:13:22,012:INFO:Checking exceptions
2024-05-27 21:13:22,021:INFO:Preparing display monitor
2024-05-27 21:13:22,151:INFO:Initializing Linear Regression
2024-05-27 21:13:22,151:INFO:Total runtime is 1.6589959462483723e-05 minutes
2024-05-27 21:13:22,162:INFO:SubProcess create_model() called ==================================
2024-05-27 21:13:22,170:INFO:Initializing create_model()
2024-05-27 21:13:22,170:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B13150D110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 21:13:22,171:INFO:Checking exceptions
2024-05-27 21:13:22,171:INFO:Importing libraries
2024-05-27 21:13:22,171:INFO:Copying training dataset
2024-05-27 21:13:22,185:INFO:Defining folds
2024-05-27 21:13:22,185:INFO:Declaring metric variables
2024-05-27 21:13:22,194:INFO:Importing untrained model
2024-05-27 21:13:22,203:INFO:Linear Regression Imported successfully
2024-05-27 21:13:22,223:INFO:Starting cross validation
2024-05-27 21:13:22,231:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 21:13:27,984:INFO:Calculating mean and std
2024-05-27 21:13:27,989:INFO:Creating metrics dataframe
2024-05-27 21:13:28,015:INFO:Uploading results into container
2024-05-27 21:13:28,018:INFO:Uploading model into container now
2024-05-27 21:13:28,021:INFO:_master_model_container: 1
2024-05-27 21:13:28,021:INFO:_display_container: 2
2024-05-27 21:13:28,023:INFO:LinearRegression(n_jobs=-1)
2024-05-27 21:13:28,023:INFO:create_model() successfully completed......................................
2024-05-27 21:13:31,737:INFO:SubProcess create_model() end ==================================
2024-05-27 21:13:31,737:INFO:Creating metrics dataframe
2024-05-27 21:13:31,764:INFO:Initializing Lasso Regression
2024-05-27 21:13:31,765:INFO:Total runtime is 0.16024521589279175 minutes
2024-05-27 21:13:31,772:INFO:SubProcess create_model() called ==================================
2024-05-27 21:13:31,773:INFO:Initializing create_model()
2024-05-27 21:13:31,773:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B13150D110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 21:13:31,773:INFO:Checking exceptions
2024-05-27 21:13:31,773:INFO:Importing libraries
2024-05-27 21:13:31,773:INFO:Copying training dataset
2024-05-27 21:13:31,790:INFO:Defining folds
2024-05-27 21:13:31,790:INFO:Declaring metric variables
2024-05-27 21:13:31,798:INFO:Importing untrained model
2024-05-27 21:13:31,806:INFO:Lasso Regression Imported successfully
2024-05-27 21:13:31,822:INFO:Starting cross validation
2024-05-27 21:13:31,825:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 21:13:32,675:INFO:Calculating mean and std
2024-05-27 21:13:32,678:INFO:Creating metrics dataframe
2024-05-27 21:13:32,682:INFO:Uploading results into container
2024-05-27 21:13:32,684:INFO:Uploading model into container now
2024-05-27 21:13:32,684:INFO:_master_model_container: 2
2024-05-27 21:13:32,685:INFO:_display_container: 2
2024-05-27 21:13:32,685:INFO:Lasso(random_state=42)
2024-05-27 21:13:32,686:INFO:create_model() successfully completed......................................
2024-05-27 21:13:34,217:INFO:SubProcess create_model() end ==================================
2024-05-27 21:13:34,217:INFO:Creating metrics dataframe
2024-05-27 21:13:34,239:INFO:Initializing Ridge Regression
2024-05-27 21:13:34,239:INFO:Total runtime is 0.20147661765416464 minutes
2024-05-27 21:13:34,249:INFO:SubProcess create_model() called ==================================
2024-05-27 21:13:34,250:INFO:Initializing create_model()
2024-05-27 21:13:34,251:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B13150D110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 21:13:34,251:INFO:Checking exceptions
2024-05-27 21:13:34,251:INFO:Importing libraries
2024-05-27 21:13:34,251:INFO:Copying training dataset
2024-05-27 21:13:34,269:INFO:Defining folds
2024-05-27 21:13:34,269:INFO:Declaring metric variables
2024-05-27 21:13:34,280:INFO:Importing untrained model
2024-05-27 21:13:34,288:INFO:Ridge Regression Imported successfully
2024-05-27 21:13:34,305:INFO:Starting cross validation
2024-05-27 21:13:34,308:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 21:13:35,356:INFO:Calculating mean and std
2024-05-27 21:13:35,358:INFO:Creating metrics dataframe
2024-05-27 21:13:35,362:INFO:Uploading results into container
2024-05-27 21:13:35,363:INFO:Uploading model into container now
2024-05-27 21:13:35,364:INFO:_master_model_container: 3
2024-05-27 21:13:35,364:INFO:_display_container: 2
2024-05-27 21:13:35,364:INFO:Ridge(random_state=42)
2024-05-27 21:13:35,365:INFO:create_model() successfully completed......................................
2024-05-27 21:13:35,695:INFO:SubProcess create_model() end ==================================
2024-05-27 21:13:35,695:INFO:Creating metrics dataframe
2024-05-27 21:13:35,747:INFO:Initializing Elastic Net
2024-05-27 21:13:35,748:INFO:Total runtime is 0.22663243611653647 minutes
2024-05-27 21:13:35,760:INFO:SubProcess create_model() called ==================================
2024-05-27 21:13:35,761:INFO:Initializing create_model()
2024-05-27 21:13:35,761:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B13150D110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 21:13:35,763:INFO:Checking exceptions
2024-05-27 21:13:35,763:INFO:Importing libraries
2024-05-27 21:13:35,763:INFO:Copying training dataset
2024-05-27 21:13:35,800:INFO:Defining folds
2024-05-27 21:13:35,801:INFO:Declaring metric variables
2024-05-27 21:13:35,813:INFO:Importing untrained model
2024-05-27 21:13:35,823:INFO:Elastic Net Imported successfully
2024-05-27 21:13:35,842:INFO:Starting cross validation
2024-05-27 21:13:35,845:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 21:13:36,815:INFO:Calculating mean and std
2024-05-27 21:13:36,816:INFO:Creating metrics dataframe
2024-05-27 21:13:36,818:INFO:Uploading results into container
2024-05-27 21:13:36,818:INFO:Uploading model into container now
2024-05-27 21:13:36,819:INFO:_master_model_container: 4
2024-05-27 21:13:36,819:INFO:_display_container: 2
2024-05-27 21:13:36,819:INFO:ElasticNet(random_state=42)
2024-05-27 21:13:36,820:INFO:create_model() successfully completed......................................
2024-05-27 21:13:37,019:INFO:SubProcess create_model() end ==================================
2024-05-27 21:13:37,020:INFO:Creating metrics dataframe
2024-05-27 21:13:37,033:INFO:Initializing Least Angle Regression
2024-05-27 21:13:37,033:INFO:Total runtime is 0.2480338493982951 minutes
2024-05-27 21:13:37,037:INFO:SubProcess create_model() called ==================================
2024-05-27 21:13:37,037:INFO:Initializing create_model()
2024-05-27 21:13:37,037:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B13150D110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 21:13:37,037:INFO:Checking exceptions
2024-05-27 21:13:37,038:INFO:Importing libraries
2024-05-27 21:13:37,038:INFO:Copying training dataset
2024-05-27 21:13:37,047:INFO:Defining folds
2024-05-27 21:13:37,047:INFO:Declaring metric variables
2024-05-27 21:13:37,051:INFO:Importing untrained model
2024-05-27 21:13:37,054:INFO:Least Angle Regression Imported successfully
2024-05-27 21:13:37,062:INFO:Starting cross validation
2024-05-27 21:13:37,063:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 21:13:38,035:INFO:Calculating mean and std
2024-05-27 21:13:38,036:INFO:Creating metrics dataframe
2024-05-27 21:13:38,038:INFO:Uploading results into container
2024-05-27 21:13:38,039:INFO:Uploading model into container now
2024-05-27 21:13:38,039:INFO:_master_model_container: 5
2024-05-27 21:13:38,039:INFO:_display_container: 2
2024-05-27 21:13:38,040:INFO:Lars(random_state=42)
2024-05-27 21:13:38,040:INFO:create_model() successfully completed......................................
2024-05-27 21:13:38,245:INFO:SubProcess create_model() end ==================================
2024-05-27 21:13:38,246:INFO:Creating metrics dataframe
2024-05-27 21:13:38,261:INFO:Initializing Lasso Least Angle Regression
2024-05-27 21:13:38,261:INFO:Total runtime is 0.2685138821601868 minutes
2024-05-27 21:13:38,265:INFO:SubProcess create_model() called ==================================
2024-05-27 21:13:38,266:INFO:Initializing create_model()
2024-05-27 21:13:38,266:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B13150D110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 21:13:38,266:INFO:Checking exceptions
2024-05-27 21:13:38,266:INFO:Importing libraries
2024-05-27 21:13:38,266:INFO:Copying training dataset
2024-05-27 21:13:38,273:INFO:Defining folds
2024-05-27 21:13:38,273:INFO:Declaring metric variables
2024-05-27 21:13:38,279:INFO:Importing untrained model
2024-05-27 21:13:38,283:INFO:Lasso Least Angle Regression Imported successfully
2024-05-27 21:13:38,289:INFO:Starting cross validation
2024-05-27 21:13:38,290:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 21:13:39,170:INFO:Calculating mean and std
2024-05-27 21:13:39,171:INFO:Creating metrics dataframe
2024-05-27 21:13:39,173:INFO:Uploading results into container
2024-05-27 21:13:39,173:INFO:Uploading model into container now
2024-05-27 21:13:39,174:INFO:_master_model_container: 6
2024-05-27 21:13:39,174:INFO:_display_container: 2
2024-05-27 21:13:39,174:INFO:LassoLars(random_state=42)
2024-05-27 21:13:39,174:INFO:create_model() successfully completed......................................
2024-05-27 21:13:39,375:INFO:SubProcess create_model() end ==================================
2024-05-27 21:13:39,376:INFO:Creating metrics dataframe
2024-05-27 21:13:39,398:INFO:Initializing Orthogonal Matching Pursuit
2024-05-27 21:13:39,399:INFO:Total runtime is 0.2874699115753174 minutes
2024-05-27 21:13:39,405:INFO:SubProcess create_model() called ==================================
2024-05-27 21:13:39,405:INFO:Initializing create_model()
2024-05-27 21:13:39,405:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B13150D110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 21:13:39,405:INFO:Checking exceptions
2024-05-27 21:13:39,405:INFO:Importing libraries
2024-05-27 21:13:39,406:INFO:Copying training dataset
2024-05-27 21:13:39,417:INFO:Defining folds
2024-05-27 21:13:39,417:INFO:Declaring metric variables
2024-05-27 21:13:39,421:INFO:Importing untrained model
2024-05-27 21:13:39,429:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-27 21:13:39,437:INFO:Starting cross validation
2024-05-27 21:13:39,439:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 21:13:40,254:INFO:Calculating mean and std
2024-05-27 21:13:40,255:INFO:Creating metrics dataframe
2024-05-27 21:13:40,258:INFO:Uploading results into container
2024-05-27 21:13:40,260:INFO:Uploading model into container now
2024-05-27 21:13:40,260:INFO:_master_model_container: 7
2024-05-27 21:13:40,260:INFO:_display_container: 2
2024-05-27 21:13:40,261:INFO:OrthogonalMatchingPursuit()
2024-05-27 21:13:40,261:INFO:create_model() successfully completed......................................
2024-05-27 21:13:40,458:INFO:SubProcess create_model() end ==================================
2024-05-27 21:13:40,458:INFO:Creating metrics dataframe
2024-05-27 21:13:40,483:INFO:Initializing Bayesian Ridge
2024-05-27 21:13:40,484:INFO:Total runtime is 0.30554962952931725 minutes
2024-05-27 21:13:40,489:INFO:SubProcess create_model() called ==================================
2024-05-27 21:13:40,490:INFO:Initializing create_model()
2024-05-27 21:13:40,490:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B13150D110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 21:13:40,490:INFO:Checking exceptions
2024-05-27 21:13:40,490:INFO:Importing libraries
2024-05-27 21:13:40,491:INFO:Copying training dataset
2024-05-27 21:13:40,502:INFO:Defining folds
2024-05-27 21:13:40,502:INFO:Declaring metric variables
2024-05-27 21:13:40,506:INFO:Importing untrained model
2024-05-27 21:13:40,511:INFO:Bayesian Ridge Imported successfully
2024-05-27 21:13:40,518:INFO:Starting cross validation
2024-05-27 21:13:40,519:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 21:13:41,705:INFO:Calculating mean and std
2024-05-27 21:13:41,707:INFO:Creating metrics dataframe
2024-05-27 21:13:41,714:INFO:Uploading results into container
2024-05-27 21:13:41,716:INFO:Uploading model into container now
2024-05-27 21:13:41,717:INFO:_master_model_container: 8
2024-05-27 21:13:41,717:INFO:_display_container: 2
2024-05-27 21:13:41,718:INFO:BayesianRidge()
2024-05-27 21:13:41,718:INFO:create_model() successfully completed......................................
2024-05-27 21:13:41,913:INFO:SubProcess create_model() end ==================================
2024-05-27 21:13:41,913:INFO:Creating metrics dataframe
2024-05-27 21:13:41,931:INFO:Initializing Passive Aggressive Regressor
2024-05-27 21:13:41,931:INFO:Total runtime is 0.32968144814173383 minutes
2024-05-27 21:13:41,936:INFO:SubProcess create_model() called ==================================
2024-05-27 21:13:41,938:INFO:Initializing create_model()
2024-05-27 21:13:41,938:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B13150D110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 21:13:41,938:INFO:Checking exceptions
2024-05-27 21:13:41,938:INFO:Importing libraries
2024-05-27 21:13:41,938:INFO:Copying training dataset
2024-05-27 21:13:41,952:INFO:Defining folds
2024-05-27 21:13:41,952:INFO:Declaring metric variables
2024-05-27 21:13:41,957:INFO:Importing untrained model
2024-05-27 21:13:41,966:INFO:Passive Aggressive Regressor Imported successfully
2024-05-27 21:13:41,974:INFO:Starting cross validation
2024-05-27 21:13:41,977:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 21:13:42,736:INFO:Calculating mean and std
2024-05-27 21:13:42,737:INFO:Creating metrics dataframe
2024-05-27 21:13:42,739:INFO:Uploading results into container
2024-05-27 21:13:42,739:INFO:Uploading model into container now
2024-05-27 21:13:42,740:INFO:_master_model_container: 9
2024-05-27 21:13:42,740:INFO:_display_container: 2
2024-05-27 21:13:42,741:INFO:PassiveAggressiveRegressor(random_state=42)
2024-05-27 21:13:42,741:INFO:create_model() successfully completed......................................
2024-05-27 21:13:42,935:INFO:SubProcess create_model() end ==================================
2024-05-27 21:13:42,935:INFO:Creating metrics dataframe
2024-05-27 21:13:42,953:INFO:Initializing Huber Regressor
2024-05-27 21:13:42,953:INFO:Total runtime is 0.34671165943145754 minutes
2024-05-27 21:13:42,961:INFO:SubProcess create_model() called ==================================
2024-05-27 21:13:42,961:INFO:Initializing create_model()
2024-05-27 21:13:42,962:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B13150D110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 21:13:42,962:INFO:Checking exceptions
2024-05-27 21:13:42,962:INFO:Importing libraries
2024-05-27 21:13:42,962:INFO:Copying training dataset
2024-05-27 21:13:42,970:INFO:Defining folds
2024-05-27 21:13:42,971:INFO:Declaring metric variables
2024-05-27 21:13:42,976:INFO:Importing untrained model
2024-05-27 21:13:42,981:INFO:Huber Regressor Imported successfully
2024-05-27 21:13:42,990:INFO:Starting cross validation
2024-05-27 21:13:42,991:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 21:13:43,825:INFO:Calculating mean and std
2024-05-27 21:13:43,828:INFO:Creating metrics dataframe
2024-05-27 21:13:43,831:INFO:Uploading results into container
2024-05-27 21:13:43,831:INFO:Uploading model into container now
2024-05-27 21:13:43,832:INFO:_master_model_container: 10
2024-05-27 21:13:43,832:INFO:_display_container: 2
2024-05-27 21:13:43,833:INFO:HuberRegressor()
2024-05-27 21:13:43,833:INFO:create_model() successfully completed......................................
2024-05-27 21:13:44,035:INFO:SubProcess create_model() end ==================================
2024-05-27 21:13:44,035:INFO:Creating metrics dataframe
2024-05-27 21:13:44,050:INFO:Initializing K Neighbors Regressor
2024-05-27 21:13:44,050:INFO:Total runtime is 0.3649927616119385 minutes
2024-05-27 21:13:44,054:INFO:SubProcess create_model() called ==================================
2024-05-27 21:13:44,055:INFO:Initializing create_model()
2024-05-27 21:13:44,055:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B13150D110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 21:13:44,055:INFO:Checking exceptions
2024-05-27 21:13:44,055:INFO:Importing libraries
2024-05-27 21:13:44,055:INFO:Copying training dataset
2024-05-27 21:13:44,064:INFO:Defining folds
2024-05-27 21:13:44,064:INFO:Declaring metric variables
2024-05-27 21:13:44,068:INFO:Importing untrained model
2024-05-27 21:13:44,071:INFO:K Neighbors Regressor Imported successfully
2024-05-27 21:13:44,080:INFO:Starting cross validation
2024-05-27 21:13:44,081:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 21:13:45,600:INFO:Calculating mean and std
2024-05-27 21:13:45,604:INFO:Creating metrics dataframe
2024-05-27 21:13:45,612:INFO:Uploading results into container
2024-05-27 21:13:45,614:INFO:Uploading model into container now
2024-05-27 21:13:45,615:INFO:_master_model_container: 11
2024-05-27 21:13:45,615:INFO:_display_container: 2
2024-05-27 21:13:45,616:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-27 21:13:45,616:INFO:create_model() successfully completed......................................
2024-05-27 21:13:45,939:INFO:SubProcess create_model() end ==================================
2024-05-27 21:13:45,939:INFO:Creating metrics dataframe
2024-05-27 21:13:45,959:INFO:Initializing Decision Tree Regressor
2024-05-27 21:13:45,960:INFO:Total runtime is 0.39682335058848067 minutes
2024-05-27 21:13:45,967:INFO:SubProcess create_model() called ==================================
2024-05-27 21:13:45,968:INFO:Initializing create_model()
2024-05-27 21:13:45,968:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B13150D110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 21:13:45,968:INFO:Checking exceptions
2024-05-27 21:13:45,968:INFO:Importing libraries
2024-05-27 21:13:45,968:INFO:Copying training dataset
2024-05-27 21:13:45,982:INFO:Defining folds
2024-05-27 21:13:45,982:INFO:Declaring metric variables
2024-05-27 21:13:45,994:INFO:Importing untrained model
2024-05-27 21:13:46,005:INFO:Decision Tree Regressor Imported successfully
2024-05-27 21:13:46,018:INFO:Starting cross validation
2024-05-27 21:13:46,019:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 21:13:46,859:INFO:Calculating mean and std
2024-05-27 21:13:46,861:INFO:Creating metrics dataframe
2024-05-27 21:13:46,865:INFO:Uploading results into container
2024-05-27 21:13:46,866:INFO:Uploading model into container now
2024-05-27 21:13:46,866:INFO:_master_model_container: 12
2024-05-27 21:13:46,866:INFO:_display_container: 2
2024-05-27 21:13:46,867:INFO:DecisionTreeRegressor(random_state=42)
2024-05-27 21:13:46,867:INFO:create_model() successfully completed......................................
2024-05-27 21:13:47,068:INFO:SubProcess create_model() end ==================================
2024-05-27 21:13:47,068:INFO:Creating metrics dataframe
2024-05-27 21:13:47,096:INFO:Initializing Random Forest Regressor
2024-05-27 21:13:47,096:INFO:Total runtime is 0.41575766007105514 minutes
2024-05-27 21:13:47,101:INFO:SubProcess create_model() called ==================================
2024-05-27 21:13:47,102:INFO:Initializing create_model()
2024-05-27 21:13:47,102:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B13150D110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 21:13:47,102:INFO:Checking exceptions
2024-05-27 21:13:47,102:INFO:Importing libraries
2024-05-27 21:13:47,102:INFO:Copying training dataset
2024-05-27 21:13:47,111:INFO:Defining folds
2024-05-27 21:13:47,111:INFO:Declaring metric variables
2024-05-27 21:13:47,115:INFO:Importing untrained model
2024-05-27 21:13:47,119:INFO:Random Forest Regressor Imported successfully
2024-05-27 21:13:47,128:INFO:Starting cross validation
2024-05-27 21:13:47,129:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 21:13:50,794:INFO:Calculating mean and std
2024-05-27 21:13:50,796:INFO:Creating metrics dataframe
2024-05-27 21:13:50,799:INFO:Uploading results into container
2024-05-27 21:13:50,800:INFO:Uploading model into container now
2024-05-27 21:13:50,802:INFO:_master_model_container: 13
2024-05-27 21:13:50,802:INFO:_display_container: 2
2024-05-27 21:13:50,803:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2024-05-27 21:13:50,803:INFO:create_model() successfully completed......................................
2024-05-27 21:13:51,137:INFO:SubProcess create_model() end ==================================
2024-05-27 21:13:51,137:INFO:Creating metrics dataframe
2024-05-27 21:13:51,155:INFO:Initializing Extra Trees Regressor
2024-05-27 21:13:51,155:INFO:Total runtime is 0.48340280850728357 minutes
2024-05-27 21:13:51,164:INFO:SubProcess create_model() called ==================================
2024-05-27 21:13:51,165:INFO:Initializing create_model()
2024-05-27 21:13:51,165:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B13150D110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 21:13:51,165:INFO:Checking exceptions
2024-05-27 21:13:51,165:INFO:Importing libraries
2024-05-27 21:13:51,165:INFO:Copying training dataset
2024-05-27 21:13:51,176:INFO:Defining folds
2024-05-27 21:13:51,176:INFO:Declaring metric variables
2024-05-27 21:13:51,184:INFO:Importing untrained model
2024-05-27 21:13:51,194:INFO:Extra Trees Regressor Imported successfully
2024-05-27 21:13:51,206:INFO:Starting cross validation
2024-05-27 21:13:51,207:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 21:13:53,884:INFO:Calculating mean and std
2024-05-27 21:13:53,887:INFO:Creating metrics dataframe
2024-05-27 21:13:53,890:INFO:Uploading results into container
2024-05-27 21:13:53,891:INFO:Uploading model into container now
2024-05-27 21:13:53,892:INFO:_master_model_container: 14
2024-05-27 21:13:53,892:INFO:_display_container: 2
2024-05-27 21:13:53,893:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-05-27 21:13:53,893:INFO:create_model() successfully completed......................................
2024-05-27 21:13:54,099:INFO:SubProcess create_model() end ==================================
2024-05-27 21:13:54,099:INFO:Creating metrics dataframe
2024-05-27 21:13:54,117:INFO:Initializing AdaBoost Regressor
2024-05-27 21:13:54,119:INFO:Total runtime is 0.5328020731608073 minutes
2024-05-27 21:13:54,126:INFO:SubProcess create_model() called ==================================
2024-05-27 21:13:54,127:INFO:Initializing create_model()
2024-05-27 21:13:54,127:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B13150D110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 21:13:54,128:INFO:Checking exceptions
2024-05-27 21:13:54,128:INFO:Importing libraries
2024-05-27 21:13:54,129:INFO:Copying training dataset
2024-05-27 21:13:54,137:INFO:Defining folds
2024-05-27 21:13:54,137:INFO:Declaring metric variables
2024-05-27 21:13:54,142:INFO:Importing untrained model
2024-05-27 21:13:54,149:INFO:AdaBoost Regressor Imported successfully
2024-05-27 21:13:54,157:INFO:Starting cross validation
2024-05-27 21:13:54,160:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 21:13:55,794:INFO:Calculating mean and std
2024-05-27 21:13:55,797:INFO:Creating metrics dataframe
2024-05-27 21:13:55,802:INFO:Uploading results into container
2024-05-27 21:13:55,802:INFO:Uploading model into container now
2024-05-27 21:13:55,803:INFO:_master_model_container: 15
2024-05-27 21:13:55,803:INFO:_display_container: 2
2024-05-27 21:13:55,805:INFO:AdaBoostRegressor(random_state=42)
2024-05-27 21:13:55,805:INFO:create_model() successfully completed......................................
2024-05-27 21:13:56,098:INFO:SubProcess create_model() end ==================================
2024-05-27 21:13:56,099:INFO:Creating metrics dataframe
2024-05-27 21:13:56,120:INFO:Initializing Gradient Boosting Regressor
2024-05-27 21:13:56,120:INFO:Total runtime is 0.5661660353342692 minutes
2024-05-27 21:13:56,129:INFO:SubProcess create_model() called ==================================
2024-05-27 21:13:56,130:INFO:Initializing create_model()
2024-05-27 21:13:56,130:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B13150D110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 21:13:56,131:INFO:Checking exceptions
2024-05-27 21:13:56,131:INFO:Importing libraries
2024-05-27 21:13:56,131:INFO:Copying training dataset
2024-05-27 21:13:56,146:INFO:Defining folds
2024-05-27 21:13:56,146:INFO:Declaring metric variables
2024-05-27 21:13:56,153:INFO:Importing untrained model
2024-05-27 21:13:56,164:INFO:Gradient Boosting Regressor Imported successfully
2024-05-27 21:13:56,174:INFO:Starting cross validation
2024-05-27 21:13:56,179:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 21:13:58,190:INFO:Calculating mean and std
2024-05-27 21:13:58,193:INFO:Creating metrics dataframe
2024-05-27 21:13:58,195:INFO:Uploading results into container
2024-05-27 21:13:58,196:INFO:Uploading model into container now
2024-05-27 21:13:58,197:INFO:_master_model_container: 16
2024-05-27 21:13:58,197:INFO:_display_container: 2
2024-05-27 21:13:58,198:INFO:GradientBoostingRegressor(random_state=42)
2024-05-27 21:13:58,198:INFO:create_model() successfully completed......................................
2024-05-27 21:13:58,391:INFO:SubProcess create_model() end ==================================
2024-05-27 21:13:58,391:INFO:Creating metrics dataframe
2024-05-27 21:13:58,409:INFO:Initializing Light Gradient Boosting Machine
2024-05-27 21:13:58,409:INFO:Total runtime is 0.6043103535970052 minutes
2024-05-27 21:13:58,414:INFO:SubProcess create_model() called ==================================
2024-05-27 21:13:58,416:INFO:Initializing create_model()
2024-05-27 21:13:58,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B13150D110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 21:13:58,416:INFO:Checking exceptions
2024-05-27 21:13:58,416:INFO:Importing libraries
2024-05-27 21:13:58,416:INFO:Copying training dataset
2024-05-27 21:13:58,422:INFO:Defining folds
2024-05-27 21:13:58,423:INFO:Declaring metric variables
2024-05-27 21:13:58,428:INFO:Importing untrained model
2024-05-27 21:13:58,432:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 21:13:58,441:INFO:Starting cross validation
2024-05-27 21:13:58,442:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 21:14:00,927:INFO:Calculating mean and std
2024-05-27 21:14:00,929:INFO:Creating metrics dataframe
2024-05-27 21:14:00,935:INFO:Uploading results into container
2024-05-27 21:14:00,936:INFO:Uploading model into container now
2024-05-27 21:14:00,937:INFO:_master_model_container: 17
2024-05-27 21:14:00,937:INFO:_display_container: 2
2024-05-27 21:14:00,938:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 21:14:00,939:INFO:create_model() successfully completed......................................
2024-05-27 21:14:01,163:INFO:SubProcess create_model() end ==================================
2024-05-27 21:14:01,163:INFO:Creating metrics dataframe
2024-05-27 21:14:01,179:INFO:Initializing Dummy Regressor
2024-05-27 21:14:01,179:INFO:Total runtime is 0.6504742781321208 minutes
2024-05-27 21:14:01,183:INFO:SubProcess create_model() called ==================================
2024-05-27 21:14:01,184:INFO:Initializing create_model()
2024-05-27 21:14:01,184:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B13150D110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 21:14:01,184:INFO:Checking exceptions
2024-05-27 21:14:01,184:INFO:Importing libraries
2024-05-27 21:14:01,184:INFO:Copying training dataset
2024-05-27 21:14:01,194:INFO:Defining folds
2024-05-27 21:14:01,194:INFO:Declaring metric variables
2024-05-27 21:14:01,198:INFO:Importing untrained model
2024-05-27 21:14:01,204:INFO:Dummy Regressor Imported successfully
2024-05-27 21:14:01,215:INFO:Starting cross validation
2024-05-27 21:14:01,217:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 21:14:02,020:INFO:Calculating mean and std
2024-05-27 21:14:02,021:INFO:Creating metrics dataframe
2024-05-27 21:14:02,023:INFO:Uploading results into container
2024-05-27 21:14:02,024:INFO:Uploading model into container now
2024-05-27 21:14:02,024:INFO:_master_model_container: 18
2024-05-27 21:14:02,025:INFO:_display_container: 2
2024-05-27 21:14:02,025:INFO:DummyRegressor()
2024-05-27 21:14:02,026:INFO:create_model() successfully completed......................................
2024-05-27 21:14:02,219:INFO:SubProcess create_model() end ==================================
2024-05-27 21:14:02,220:INFO:Creating metrics dataframe
2024-05-27 21:14:02,254:INFO:Initializing create_model()
2024-05-27 21:14:02,255:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 21:14:02,255:INFO:Checking exceptions
2024-05-27 21:14:02,257:INFO:Importing libraries
2024-05-27 21:14:02,257:INFO:Copying training dataset
2024-05-27 21:14:02,265:INFO:Defining folds
2024-05-27 21:14:02,265:INFO:Declaring metric variables
2024-05-27 21:14:02,265:INFO:Importing untrained model
2024-05-27 21:14:02,265:INFO:Declaring custom model
2024-05-27 21:14:02,266:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 21:14:02,267:INFO:Cross validation set to False
2024-05-27 21:14:02,267:INFO:Fitting Model
2024-05-27 21:14:02,688:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000497 seconds.
2024-05-27 21:14:02,688:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-27 21:14:02,689:INFO:[LightGBM] [Info] Total Bins 1660
2024-05-27 21:14:02,690:INFO:[LightGBM] [Info] Number of data points in the train set: 910, number of used features: 15
2024-05-27 21:14:02,691:INFO:[LightGBM] [Info] Start training from score -0.029448
2024-05-27 21:14:02,806:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 21:14:02,807:INFO:create_model() successfully completed......................................
2024-05-27 21:14:03,098:INFO:_master_model_container: 18
2024-05-27 21:14:03,098:INFO:_display_container: 2
2024-05-27 21:14:03,099:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 21:14:03,099:INFO:compare_models() successfully completed......................................
2024-05-27 21:14:03,164:INFO:Initializing plot_model()
2024-05-27 21:14:03,164:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 21:14:03,164:INFO:Checking exceptions
2024-05-27 21:14:03,170:INFO:Preloading libraries
2024-05-27 21:14:03,183:INFO:Copying training dataset
2024-05-27 21:14:03,184:INFO:Plot type: feature
2024-05-27 21:14:03,185:WARNING:No coef_ found. Trying feature_importances_
2024-05-27 21:14:03,455:INFO:Visual Rendered Successfully
2024-05-27 21:14:03,644:INFO:plot_model() successfully completed......................................
2024-05-27 21:14:03,646:INFO:Initializing plot_model()
2024-05-27 21:14:03,646:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=error, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 21:14:03,646:INFO:Checking exceptions
2024-05-27 21:14:03,655:INFO:Preloading libraries
2024-05-27 21:14:03,669:INFO:Copying training dataset
2024-05-27 21:14:03,670:INFO:Plot type: error
2024-05-27 21:14:03,838:INFO:Fitting Model
2024-05-27 21:14:03,838:INFO:Scoring test/hold-out set
2024-05-27 21:14:04,189:INFO:Visual Rendered Successfully
2024-05-27 21:14:04,387:INFO:plot_model() successfully completed......................................
2024-05-27 21:14:04,388:INFO:Initializing plot_model()
2024-05-27 21:14:04,388:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=residuals, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 21:14:04,388:INFO:Checking exceptions
2024-05-27 21:14:04,398:INFO:Preloading libraries
2024-05-27 21:14:04,412:INFO:Copying training dataset
2024-05-27 21:14:04,412:INFO:Plot type: residuals
2024-05-27 21:14:04,611:INFO:Fitting Model
2024-05-27 21:14:04,689:INFO:Scoring test/hold-out set
2024-05-27 21:14:05,189:INFO:Visual Rendered Successfully
2024-05-27 21:14:05,390:INFO:plot_model() successfully completed......................................
2024-05-27 21:14:05,486:INFO:Initializing evaluate_model()
2024-05-27 21:14:05,487:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-27 21:14:05,509:INFO:Initializing plot_model()
2024-05-27 21:14:05,510:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-27 21:14:05,510:INFO:Checking exceptions
2024-05-27 21:14:05,518:INFO:Preloading libraries
2024-05-27 21:14:05,569:INFO:Copying training dataset
2024-05-27 21:14:05,569:INFO:Plot type: pipeline
2024-05-27 21:14:05,829:INFO:Visual Rendered Successfully
2024-05-27 21:14:06,030:INFO:plot_model() successfully completed......................................
2024-05-27 21:14:06,111:INFO:Initializing tune_model()
2024-05-27 21:14:06,111:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-05-27 21:14:06,112:INFO:Checking exceptions
2024-05-27 21:14:06,135:INFO:Copying training dataset
2024-05-27 21:14:06,141:INFO:Checking base model
2024-05-27 21:14:06,142:INFO:Base model : Light Gradient Boosting Machine
2024-05-27 21:14:06,150:INFO:Declaring metric variables
2024-05-27 21:14:06,157:INFO:Defining Hyperparameters
2024-05-27 21:14:06,490:INFO:Tuning with n_jobs=-1
2024-05-27 21:14:06,491:INFO:Initializing RandomizedSearchCV
2024-05-27 21:14:24,159:INFO:best_params: {'actual_estimator__reg_lambda': 5, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 100, 'actual_estimator__min_split_gain': 0.6, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.8}
2024-05-27 21:14:24,161:INFO:Hyperparameter search completed
2024-05-27 21:14:24,161:INFO:SubProcess create_model() called ==================================
2024-05-27 21:14:24,162:INFO:Initializing create_model()
2024-05-27 21:14:24,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B11A1A9850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 5, 'reg_alpha': 0.001, 'num_leaves': 30, 'n_estimators': 100, 'min_split_gain': 0.6, 'min_child_samples': 6, 'learning_rate': 0.2, 'feature_fraction': 0.8, 'bagging_freq': 3, 'bagging_fraction': 0.8})
2024-05-27 21:14:24,163:INFO:Checking exceptions
2024-05-27 21:14:24,163:INFO:Importing libraries
2024-05-27 21:14:24,164:INFO:Copying training dataset
2024-05-27 21:14:24,178:INFO:Defining folds
2024-05-27 21:14:24,178:INFO:Declaring metric variables
2024-05-27 21:14:24,185:INFO:Importing untrained model
2024-05-27 21:14:24,185:INFO:Declaring custom model
2024-05-27 21:14:24,196:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 21:14:24,212:INFO:Starting cross validation
2024-05-27 21:14:24,214:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 21:14:25,808:INFO:Calculating mean and std
2024-05-27 21:14:25,811:INFO:Creating metrics dataframe
2024-05-27 21:14:25,821:INFO:Finalizing model
2024-05-27 21:14:26,154:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-05-27 21:14:26,154:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-05-27 21:14:26,154:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-05-27 21:14:26,159:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-05-27 21:14:26,159:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-05-27 21:14:26,159:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-05-27 21:14:26,160:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000451 seconds.
2024-05-27 21:14:26,160:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-27 21:14:26,160:INFO:[LightGBM] [Info] Total Bins 1660
2024-05-27 21:14:26,160:INFO:[LightGBM] [Info] Number of data points in the train set: 910, number of used features: 15
2024-05-27 21:14:26,161:INFO:[LightGBM] [Info] Start training from score -0.029448
2024-05-27 21:14:26,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,182:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,188:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,188:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,188:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,198:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,198:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,200:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,200:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,200:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,201:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,201:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,202:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,202:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,205:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,205:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,205:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,206:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,206:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,206:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,207:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,207:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,208:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,208:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,208:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,209:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,209:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,211:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,221:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,221:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,222:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-27 21:14:26,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-27 21:14:26,237:INFO:Uploading results into container
2024-05-27 21:14:26,239:INFO:Uploading model into container now
2024-05-27 21:14:26,241:INFO:_master_model_container: 19
2024-05-27 21:14:26,241:INFO:_display_container: 2
2024-05-27 21:14:26,244:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=3, feature_fraction=0.8,
              learning_rate=0.2, min_child_samples=6, min_split_gain=0.6,
              n_jobs=-1, num_leaves=30, random_state=42, reg_alpha=0.001,
              reg_lambda=5)
2024-05-27 21:14:26,244:INFO:create_model() successfully completed......................................
2024-05-27 21:14:26,485:INFO:SubProcess create_model() end ==================================
2024-05-27 21:14:26,485:INFO:choose_better activated
2024-05-27 21:14:26,490:INFO:SubProcess create_model() called ==================================
2024-05-27 21:14:26,490:INFO:Initializing create_model()
2024-05-27 21:14:26,490:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 21:14:26,492:INFO:Checking exceptions
2024-05-27 21:14:26,495:INFO:Importing libraries
2024-05-27 21:14:26,495:INFO:Copying training dataset
2024-05-27 21:14:26,509:INFO:Defining folds
2024-05-27 21:14:26,509:INFO:Declaring metric variables
2024-05-27 21:14:26,510:INFO:Importing untrained model
2024-05-27 21:14:26,510:INFO:Declaring custom model
2024-05-27 21:14:26,513:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 21:14:26,514:INFO:Starting cross validation
2024-05-27 21:14:26,515:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 21:14:29,101:INFO:Calculating mean and std
2024-05-27 21:14:29,102:INFO:Creating metrics dataframe
2024-05-27 21:14:29,105:INFO:Finalizing model
2024-05-27 21:14:29,414:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.
2024-05-27 21:14:29,414:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-27 21:14:29,414:INFO:[LightGBM] [Info] Total Bins 1660
2024-05-27 21:14:29,415:INFO:[LightGBM] [Info] Number of data points in the train set: 910, number of used features: 15
2024-05-27 21:14:29,416:INFO:[LightGBM] [Info] Start training from score -0.029448
2024-05-27 21:14:29,562:INFO:Uploading results into container
2024-05-27 21:14:29,563:INFO:Uploading model into container now
2024-05-27 21:14:29,564:INFO:_master_model_container: 20
2024-05-27 21:14:29,564:INFO:_display_container: 3
2024-05-27 21:14:29,565:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 21:14:29,565:INFO:create_model() successfully completed......................................
2024-05-27 21:14:29,784:INFO:SubProcess create_model() end ==================================
2024-05-27 21:14:29,785:INFO:LGBMRegressor(n_jobs=-1, random_state=42) result for R2 is 0.8022
2024-05-27 21:14:29,786:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=3, feature_fraction=0.8,
              learning_rate=0.2, min_child_samples=6, min_split_gain=0.6,
              n_jobs=-1, num_leaves=30, random_state=42, reg_alpha=0.001,
              reg_lambda=5) result for R2 is 0.7718
2024-05-27 21:14:29,786:INFO:LGBMRegressor(n_jobs=-1, random_state=42) is best model
2024-05-27 21:14:29,787:INFO:choose_better completed
2024-05-27 21:14:29,788:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-27 21:14:29,806:INFO:_master_model_container: 20
2024-05-27 21:14:29,807:INFO:_display_container: 2
2024-05-27 21:14:29,807:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-05-27 21:14:29,808:INFO:tune_model() successfully completed......................................
2024-05-27 21:14:30,130:INFO:Initializing plot_model()
2024-05-27 21:14:30,130:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 21:14:30,130:INFO:Checking exceptions
2024-05-27 21:14:30,138:INFO:Preloading libraries
2024-05-27 21:14:30,152:INFO:Copying training dataset
2024-05-27 21:14:30,152:INFO:Plot type: feature
2024-05-27 21:14:30,153:WARNING:No coef_ found. Trying feature_importances_
2024-05-27 21:14:30,502:INFO:Visual Rendered Successfully
2024-05-27 21:14:30,699:INFO:plot_model() successfully completed......................................
2024-05-27 21:14:30,702:INFO:Initializing plot_model()
2024-05-27 21:14:30,702:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=error, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 21:14:30,702:INFO:Checking exceptions
2024-05-27 21:14:30,710:INFO:Preloading libraries
2024-05-27 21:14:30,725:INFO:Copying training dataset
2024-05-27 21:14:30,725:INFO:Plot type: error
2024-05-27 21:14:30,932:INFO:Fitting Model
2024-05-27 21:14:30,932:INFO:Scoring test/hold-out set
2024-05-27 21:14:31,310:INFO:Visual Rendered Successfully
2024-05-27 21:14:31,511:INFO:plot_model() successfully completed......................................
2024-05-27 21:14:31,512:INFO:Initializing plot_model()
2024-05-27 21:14:31,512:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=residuals, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-27 21:14:31,512:INFO:Checking exceptions
2024-05-27 21:14:31,520:INFO:Preloading libraries
2024-05-27 21:14:31,531:INFO:Copying training dataset
2024-05-27 21:14:31,533:INFO:Plot type: residuals
2024-05-27 21:14:31,733:INFO:Fitting Model
2024-05-27 21:14:31,807:INFO:Scoring test/hold-out set
2024-05-27 21:14:32,288:INFO:Visual Rendered Successfully
2024-05-27 21:14:32,485:INFO:plot_model() successfully completed......................................
2024-05-27 21:14:32,518:INFO:Initializing evaluate_model()
2024-05-27 21:14:32,520:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-27 21:14:32,533:INFO:Initializing plot_model()
2024-05-27 21:14:32,533:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B11A2931D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=42), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-27 21:14:32,533:INFO:Checking exceptions
2024-05-27 21:14:32,537:INFO:Preloading libraries
2024-05-27 21:14:32,548:INFO:Copying training dataset
2024-05-27 21:14:32,548:INFO:Plot type: pipeline
2024-05-27 21:14:32,913:INFO:Visual Rendered Successfully
2024-05-27 21:14:33,115:INFO:plot_model() successfully completed......................................
